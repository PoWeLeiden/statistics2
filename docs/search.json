[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical analysis and presentation using R",
    "section": "",
    "text": "Preface\nThis book presents the R materials related to the course Statistics II.\nWe have divided the book into the following parts:\nThese three sections introduce the syntax used to perform the core methods of analysis in the class. We will break down the contents of this syntax and explain its logic when the different commands that we will use. In addition, we will often times annotate the syntax via comments (either presented in grayed out text or in bubbles that you can examine by hovering over them with your computer mouse) to further call your attention to aspects of the syntax. Here is an example:\n# Packages\nlibrary(tidyverse)   #Used for data management and plotting\n\n# A linear regression model\n1model1 &lt;- lm(mpg ~ drat, data = mtcars)\n\n\n1\n\nWe may put annotations in these little bubbles particularly if they are a little longer in nature or if we are repeating a point you have seen before.\nThese sections also provide general guidelines on how to present and correctly report the output from these statistical analyses. You will find the output from the statistical software as well as additional information:\nThe final part of the book provide three Appendices with some supplementary information. Appendix A provides an overview of some Common Errors that you may encounter when performing these analyses and when attempting to knit your R assignment files into an html for submission. Appendix B provides an overview of the R libraries (and associated functions) that we will use in this course, the week they are introduced, and a script that will enable you to install them on your personal computer all in one go. Appendix C provides relevant formulas related to the types of analysis that we’ll examine in Statistics II.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#statistics-i-book",
    "href": "index.html#statistics-i-book",
    "title": "Statistical analysis and presentation using R",
    "section": "Statistics I Book",
    "text": "Statistics I Book\nThe contents of this book build on what you learned in Statistics I particularly when it comes to data management processes (e.g,. how to import data, filter it, summarize it, etc.). If you need a refresher on these processes, then please consult the Statistics I book. We will occasionally link to sections of particular relevance from that book in the discussions to come.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#overview-per-week",
    "href": "index.html#overview-per-week",
    "title": "Statistical analysis and presentation using R",
    "section": "Overview per week",
    "text": "Overview per week\nFor each week in the course, you need to read relevant chapters …. In 2024-2025, this is:\n\n\n\n\n\n\n\n\nWeek\nSection\nChapters\n\n\n\n\n1\nLinear Models\n1  Investigating Relationships between Continuous Variables ; 8  Reporting and Presenting Results (8.1 & 8.2)\n\n\n2\nLinear Models\n2  Bivariate Regression with Binary & Categorical Predictors ; 3  Statistical Significance ; 5  Predicted & Residual Values (5.1 & 5.2) ; 8  Reporting and Presenting Results (8.3)\n\n\n3\nLinear Models\n4  Multiple Linear Regression ; 5  Predicted & Residual Values (5.3) ; 6  Model Fit ; 8  Reporting and Presenting Results (8.3 - 8.6)\n\n\n4\nLinear Models\n7  OLS Assumptions\n\n\n5\nLogistic Regression\n9  Logistic Regression & Odds Ratios ; 10  Marginal Effects ; 11  Predicted Probabilities ; 14  Reporting & Presenting Logistic Regressions\n\n\n6\nLogistic Regression\n12  Model Fit and Comparisons ; 13  Logistic Regression Assumptions\n\n\n7\nInteractions\n15  Including an Interaction Term in a Regression Model ; 16  Marginal Effects in Interaction Models ; 17  Predicted Values from Interaction Models",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "part_linear.html",
    "href": "part_linear.html",
    "title": "Linear Statistical Models",
    "section": "",
    "text": "This section of the materials focuses on linear statistical models. You will learn how to…\n\nInvestigate the correlation between two continuous variables\nPerform and interpret a linear regression model where a continuous dependent variable is predicted by continuous and/or categorical independent variables\nExamine the assumptions of these models",
    "crumbs": [
      "Linear Statistical Models"
    ]
  },
  {
    "objectID": "linear_01.html",
    "href": "linear_01.html",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "",
    "text": "1.1 Recall: Peeking Inside Data Objects\nWe have loaded a data file…but what’s inside it? Datasets often come with codebooks that provide information about the variables in the dataset. We can also look into our data object in R to learn more about its contents as well. We can do this in a few ways.\nFor instance, we can enter the name of the object in the Console:\ndemdata\n\n# A tibble: 179 × 41\n   country_name  year v2x_polyarchy v2x_libdem v2x_egaldem v2cacamps v2caviol\n   &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Mexico        2020         0.647      0.412       0.369     1.53     0.023\n 2 Suriname      2020         0.761      0.627       0.56      0.12    -0.813\n 3 Sweden        2020         0.908      0.879       0.83     -2.08    -2.37 \n 4 Switzerland   2020         0.894      0.851       0.832    -1.70    -2.66 \n 5 Ghana         2020         0.72       0.614       0.534    -0.441   -0.008\n 6 South Africa  2020         0.703      0.578       0.477     0.092    0.395\n 7 Japan         2020         0.832      0.743       0.75     -1.54    -1.95 \n 8 Myanmar       2020         0.436      0.271       0.253     0.886    1.28 \n 9 Russia        2020         0.262      0.103       0.203     0.558    0.195\n10 Albania       2020         0.485      0.409       0.358    -0.501   -0.119\n# ℹ 169 more rows\n# ℹ 34 more variables: e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;,\n#   e_regionpol_6C &lt;dbl&gt;, v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;,\n#   bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;, dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;,\n#   TypeSoc2005 &lt;dbl&gt;, TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;,\n#   TYPEDEMO1984 &lt;dbl&gt;, TYPEDEMO2007 &lt;dbl&gt;, Fragile2006 &lt;dbl&gt;,\n#   Typeregime2006 &lt;dbl&gt;, TYPEGOV2007 &lt;dbl&gt;, CPI8085 &lt;dbl&gt;, …\nIf our dataset is a tibble (like here), then we will see a nice overview of the first few variables (columns) and observations (rows) in the dataset.\nWe may want to see a list of the variables in our dataset and some of their attributes. You learned how to do this using the str() function in Statistics I (see here). A simpler overview of a data object is provided by glimpse() and is particularly useful when one wants to quickly see the names of columns in an object. We do so here for a shorter version of the dataset so that we do not make the output unnecessarily long for what we want to show you.\n#Smaller version of the dataset for display purposes\ndemdata_sub &lt;- demdata |&gt; \n  select(v2x_egaldem, TypeSoc2005, HDI2005, TYPEDEMO1984, gini_2019)\n\nglimpse(demdata_sub)\n\nRows: 179\nColumns: 5\n$ v2x_egaldem  &lt;dbl&gt; 0.369, 0.560, 0.830, 0.832, 0.534, 0.477, 0.750, 0.253, 0…\n$ TypeSoc2005  &lt;dbl&gt; 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, …\n$ HDI2005      &lt;dbl&gt; 0.829, 0.774, 0.956, 0.955, 0.553, 0.674, 0.953, 0.583, 0…\n$ TYPEDEMO1984 &lt;dbl&gt; 2, 1, 2, 2, 1, 1, 2, 1, NA, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1,…\n$ gini_2019    &lt;dbl&gt; NA, NA, 26.5, 30.1, NA, NA, NA, NA, 32.5, 37.5, NA, NA, 4…\nFinally, one can use the view_df() function from the sjPlot library to see the names of the columns in the object alongside labels for the variables (if any) and information about the values that the variable can take on. This information will be provided in the Viewer pane. You can then use the click on the “Show in new window” button to view the full list in an open browser tab.\n1view_df(demdata_sub)\n\n\n1\n\nThe sjPlot library was loaded at the beginning of the document. You need to load it first before using this command.\n\n\n\n\n\n\nData frame: demdata_sub\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nv2x_egaldem\n\nrange: 0.0-0.9\n\n\n2\nTypeSoc2005\nType of human development, (3-cat, classified from\nHDI) (UNDP 2008)\n1\n2\n3\nLow human development\nMedium human development\nHigh human development\n\n\n3\nHDI2005\nHuman Development Index (HDI), 2005 100-pt scale\n(UNDP 2007)\nrange: 0.3-1.0\n\n\n4\nTYPEDEMO1984\nType of democracy, 1984\n1\n2\nAutocracies\nDemocracies\n\n\n5\ngini_2019\n\nrange: 22.6-48.0",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "href": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "",
    "text": "Output Explanation\n\n\n\nview_df() creates output with the following columns:\n\nName: This provides the variable name\nLabel: This provides the label of the variable if there is one. This is a short description of what the variable is supposed to measure.\nValues: If the variable is a continuous variable, then this will likely show “range: X-X”. For instance, the v2x_egaldem variable ranges from 0 to 0.9. If the variable only contains a few discrete values, then those will be shown instead (as with the variable TypeSoc2005).\nValue Labels: It is sometimes the case that variables will have labels that tell you what each specific value on the variable means. For instance, observations will have a 1 on the TYPEDEMO1984 variable if they were “Autocracies” in 1984, but a 2 if they were “Democracies”.\n\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nview_df() is a very nice way of getting an overview of a data file for yourself. However, we ask that you do not include it in the final version of your R assignments. The data files that we will use often have many columns (variables), so leaving view_df(data) in your .rmd file when knitting the final project is likely to produce a huge table that increases the difficulty of reading through your assignments. It is seldom a good idea to make it harder to evaluate your work! Use it when you load the data and are working on your assignment, but remove that bit of syntax before producing the final knitted output.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "href": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "1.2 Visualizing Bivariate Relationships with a Scatterplot",
    "text": "1.2 Visualizing Bivariate Relationships with a Scatterplot\nOur initial example concerns the relationship between a country’s level of economic inequality and its level of electoral democracy.\nThe variable gini_2019 contains data on a country’s level of economic inequality and can take on values continuously between 0-100 (higher values = more inequality).1 The variable v2x_polyarchy, meanwhile, contains data on the level of electoral democracy in a country as of the year 2020. This measure ranges continuously between 0 and 1 with higher values indicating a more democratic political system.\nWe can obtain a sense of the relationship between two continuous variables with a scatterplot. See Chapter 8 in the Statistics I book for more on the use of ggplot(), including additional options for creating nice looking scatterplots.\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  labs(title = \"Economic Inequality and Electoral Democracy\", \n       x = \"Gini Coefficient (2019)\", \n       y = \"Electoral Democracy (2020)\") + \n  scale_x_continuous(breaks = seq(from = 25, to = 45, by = 5)) \n\nWarning: Removed 109 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe output above includes a “warning”: “Warning: Removed 109 rows containing missing values (`geom_point()`).”. This occurs because there are observations in the dataset that do not contain data on either or both of the variables being plotted.\nIn general, warnings in R are often non-critical issues that occur when R encounters something unusual but not severe enough to stop execution. The code continues to run after issuing the warning. Warnings can sometimes be safely ignored, but it is important to investigate and understand them to ensure that a more serious issue is not occurring.\n\n\nHere is how to read the syntax above:\n\nggplot(\n\nThis tells R that we wish to plot data using the ggplot2 package from the tidyverse library.\n\ndemdata,\n\nThis is the name of the data object that contains the variables we wish to plot. Replace this with the name of your data frame.\n\naes(x = gini_2019, y = v2x_polyarchy))\n\nThis provides R with basic details about how the figure should look (its “aesthetic mapping”). Here, we tell R that we want gini_2019 to be plotted on the x-axis and v2x_polyarchy to be plotted on the y-axis. We typically put the variable we consider the dependent variable on the y-axis of a scatterplot and the independent variable on the x-axis.\n\ngeom_point()\n\nThis tells R what type of plot that we want, in this case a scatterplot. Each point is a different observation in our data. The position of each point is determined by the values associated with the observation for the variables on the x- and y-axes.\n\nlabs(…)\n\nThe information in this parenthesis tells R how we wish to label the axes and what title to provide to the plot.\n\nscale_x_continuous(breaks = seq(from = 25, to = 45, by = 5))\n\nThis line tells R that the x-axis should feature breaks every five spaces between the values of 25 and 45.2\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nWe changed the number of breaks on the x-axis in this example to make it easier to locate the different points along the x-axis in this particular figure. You may not need to do this in your own examples - the default output is oftentimes just fine. If you are using the syntax that we provide as a starting point for your own analyses, then stop and think about what needs to be updated to produce sensible output. For instance, if you simply used the syntax above and the x-variable you were trying to plot instead ranged from 0 to 10, then the plot may not include all of the data in your dataset or may omit the breaks entirely or produce some other error. Copy, paste, and update.\n\n\nSee Section 8.1 for additional instructions on how to create effective scatterplots and guidelines for discussing their contents in reports.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#covariance",
    "href": "linear_01.html#covariance",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "1.3 Covariance",
    "text": "1.3 Covariance\nA scatterplot provides a graphical overview of the relationship between two variables. When we look at countries with a Gini coefficient value below 30, then we tend to see markers in the upper-left hand corner of the figure. However, the markers tend to drift downward on the y-axis when we move left to right on the x-axis. This implies that inequality is negatively related to democracy (inequality goes up, democracy goes down).\nWe can use the covariance statistic to more formally describe the statistical relationship between the two variables and double-check our interpretation of the figure. We can obtain the covariance between two variables using the cov() function in R. We do not need to load any packages to use this command.\n\ncov(x = demdata$gini_2019, \n    y = demdata$v2x_polyarchy,\n    use = \"complete.obs\")   \n\n[1] -0.560385\n\n\nHere is how to read this syntax:\n\ncov(\n\nThis indicates the name of the command.\n\nx = demdata$gini_2019,\n\nThis tells R that we wish to use the variable gini_2019 from the data object demdata as our x-variable. You would replace demdata with the name of your data object and gini_2019 with the name of the x variable you are interested in.\n\ny = demdata$v2x_polyarchy,\n\nThis tells R that we wish to use the variable v2x_polyarchy from the data object demdata as our y-variable. We typically specify the variable we think of as the independent variable as “x” and the variable considered the dependent variable as “y”. However, it does not matter which variable we label as X and which we label as Y in this command - we would obtain the same results either way.\n\nuse= \"complete.obs\")\n\nThis tells R that we wish to use observations only if they have full (non-missing) data on both variables.\n\n\nThe covariance statistic is -0.56. This is consistent with our earlier reaction to the scatterplot as a negative covariance statistic means that higher values of one variable (gini_2019) tend to go with lower values of the other variable (v2x_polyarchy).",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-correlation-coefficients",
    "href": "linear_01.html#sec-correlation-coefficients",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "1.4 Correlation Coefficients",
    "text": "1.4 Correlation Coefficients\nWe can also use a correlation coefficient to describe the relationship between two continuous variables. Unlike the covariance statistic, correlations provide a standardized measure of association so that we can compare correlations with one another.\nThere are a variety of correlation coefficients that one can use. The most appropriate one for interval/ratio (continuous) data is the Pearson correlation coefficient (often referenced with an italicized letter r: \\(r\\)). We can obtain this statistic using the cor.test() command. This command is built-in to R and does not require you to load an additional package.3\n\ncor.test(x = demdata$gini_2019, \n         y = demdata$v2x_polyarchy, \n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nHere is how to read this syntax:\n\ncor.test(\n\nThis is the name of the command.\n\nx = demdata$gini_2019\n\nHere we specify that we want to use the variable gini_2019 from the demdata object as one of the variables in the correlation.\n\ny = demdata$v2x_polyarchy\n\nHere we specify the other variable in the correlation. Much as with the cov() function, it is conventional to treat our IV as “x” and our DV as “y” in this command even though the results would not change if we flipped things around.\n\nmethod = \"pearson\")\n\nThis tells R which type of correlation coefficient to calculate, in this case the Pearson correlation coefficient. Sometimes the assumptions that underlie the Pearson correlation are not met and we will need to ask R to estimate a different type of correlation coefficient. We would do so by changing this line of syntax. For instance, we would change this to method = spearman to calculate a Spearman correlation.\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nIn R, the output shows:\n\n‘t =’: the t-value or t-statistic for the correlation\n‘df =’: the degrees of freedom\n‘p-value =’: the p-value for the correlation (i.e., the probability of observing a t-value of that size or larger assuming the null hypothesis of no correlation & model assumptions are correct)\n‘95 percent confidence interval:’: the 95% confidence interval for the correlation coefficient\n‘cor’: the correlation coefficient\n\n\n\nThe correlation coefficient in this instance is -0.35 (rounding to two digits). How can we interpret this number?\n\n\n\n\n\n\nInterpretation\n\n\n\nCorrelation coefficients range from -1 to +1 where:\n\n-1 = a perfect negative linear relationship. In such cases, all observations would fall on a negatively sloped line.\n0 = no linear relationship\n+1 = a perfect positive linear relationship. In such cases, all observations would fall on a positively sloped line.\n\nA positive correlation thus indicates that we expect one variable to increase in size when the other variable increases in size. A negative correlation indicates that we expect one variable to decrease in size when the other variable increases in size.\nCorrelation coefficients provide a standardized measure of the magnitude and direction of the relationship between two variables. Is -0.35 a big or large relationship? One commonly used guideline for interpreting the magnitude of correlation coefficients comes from Cohen (1988):\n\n\\(r \\leq\\) |0.1|: Very small relationship\n|0.1| \\(\\leq\\) |0.3|: Small relationship\n|0.3| \\(\\leq\\) |0.5|: Moderate relationship\n\\(r \\geq\\) |0.5|: Large relationship\n\nIn this example, then, we would say that the relationship between the two variables is moderately sized.\nA final note: This is the rule of thumb that we will use in class. However, it is not the only one. Ultimately, what constitutes a “substantively important” or meaningful relationship may be context dependent. Thus, while the rule of thumb shown above is sufficient for discussions in Statistics II, discussions in reports/papers should also take into account the broader context of the study.\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Erlbaum Associates.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#bivariate-linear-regression",
    "href": "linear_01.html#bivariate-linear-regression",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "1.5 Bivariate Linear Regression",
    "text": "1.5 Bivariate Linear Regression\nThe final way of summarizing a bivariate relationship where both variables are continuous (interval/ratio) is via a bivariate regression model.4 In the example below we will fit a bivariate linear regression to summarize the relationship between inequality and electoral democracy.\n\n1.5.1 Performing and obtaining results\n\nm1 &lt;- lm(v2x_polyarchy ~ gini_2019, data = demdata)\n\nThe syntax above performs the desired linear regression. Here is how to read the syntax:\n\nm1 &lt;-\n\nThis portion of the command tells R to create a new object called “m1” and to assign to it the results of the ensuing analysis. This is not necessary to run the regression, but is traditional to do because we will very often be working with the results of a regression model using other commands that require such an object. You would change the name of the object as needed in your own reports.\n\nlm(\n\nThis is the name of the command: lm = linear (regression) model.\n\nv2x_polyarchy ~ gini_2019,\n\nThis is how we specify the variables in a regression. The variable name to the left of the tilde (“~”) is the dependent variable. The variable name to the right of the tilde represents an independent variable. See the Warning box below.\n\ndata = demdata)\n\nThe command concludes by specifying the data object that contains the variables to be used in the model. This always comes at the end of the command.\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nThere is an important difference between cor.test()/cov() and lm(). The order of variables in the former two commands does not matter. cov(x = demdata$gini_2019, y = demdata$v2x_polyarchy,…) and cov(x = demdata$v2x_polyarchy, y = demdata$gini_2019,…) will produce the same output. But, lm(v2x_polyarchy ~ gini_2019,…) and lm(gini_2019 ~ v2x_polyarchy,…) will not!. The dependent variable in a linear regression (the variable that we are trying to predict or explain) must always be on the left side of the tilde. A first thing to figure out when fitting a regression model is which variable is supposed to be the dependent variable.\n\n\nHow can we see the results from our regression when we store it to an object like in the syntax above? One way is to call the object that we just created by typing its name in the Console and hitting enter.\n\nm1\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nCoefficients:\n(Intercept)    gini_2019  \n    1.06031     -0.01186  \n\n\nThis default output only shows the coefficient values for the Intercept term and the slope for the independent variable(s) in the model, inequality in this instance.5 It is thus more customary to use the summary() command as this provides more information about the results of our model:\n\nsummary(m1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5389 -0.1502  0.0903  0.1668  0.3965 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.060311   0.136512   7.767  5.8e-11 ***\ngini_2019   -0.011859   0.003897  -3.043  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2225 on 68 degrees of freedom\n  (109 observations deleted due to missingness)\nMultiple R-squared:  0.1199,    Adjusted R-squared:  0.1069 \nF-statistic: 9.262 on 1 and 68 DF,  p-value: 0.003325\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nIn R, the output shows:\n\n“Call”: The regression model being fit.\n“Residuals”: This provides information about the model residuals. We will examine residuals in further depth in later chapters.\n“Coefficients”: This provides coefficients from the model, including…\n\nEstimate: The coefficient values for each term in the model. We can see a coefficient value for our Intercept term (“(Intercept)” = 1.060311) and for the independent variable (“gini_2019” = -0.0118)\nStd. Error: The standard error of the coefficient\nt value: The t-statistic or t-value for the coefficient\nPr(&gt;|t|): The p-value associated with the t-statistic. t- and p-values will be discussed in Chapter 3\n\nThe bottom portion of the output displays statistics relating to the “fit” of the model, which will be discussed further in Chapter 6 .\n\n\n\nThe coefficient for economic inequality is negative much as was the covariance and correlation; this is because they are each different ways of summarizing the linear association between the two variables.\n\n\n\n\n\n\nInterpretation\n\n\n\nThe Estimate column provides the coefficient values from our regression model.\n\n(Intercept): What is the average value of the DV we expect to observe based on this model if the independent variable = 0. Here: if we could observe countries with a score of 0 on the inequality variable, then we’d expect the average democracy score among them to be 1.06. This is seldom of direct interest and especially so when our IV(s) do not or cannot take on a value of 0.\nCoefficients for Continuous Independent Variables (e.g., gini_2019): The coefficient for a continuous independent variable is interpreted as the change in the expected mean of Y given a one unit increase in X (i.e., as the slope of a straight line). Here, our model tells us to expect the level of electoral democracy to decrease by approximately -0.01 scale points, on average, with each one unit increase on the inequality variable. See Section 8.3 on how to report this information in class assignments and in papers.\n\nThe coefficient for gini_2019 is -0.01. How “big” of a relationship is this? Regression coefficients are not standardized so we generally cannot directly assess the magnitude of an effect implied by a regression coefficient simply from its size. We will discuss some tools that researchers use to help them communicate effect sizes in later sections (e.g., standardized coefficients in Section 4.2 and predicted values in Chapter 5). Ultimately, discussions of the substantive significance of a regression coefficient requires thinking about what a meaningful effect would be in the particular context of the regression that you are performing.\n\n\n\n\n1.5.2 Adding a regression line to a scatterplot\nWe can incorporate information from our regression model into visual displays in a variety of ways. One common way of doing so is to add a regression line to a scatterplot of the two variables.\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Economic Inequality and Electoral Democracy\", \n       x = \"Gini Coefficient (2019)\", \n       y = \"Electoral Democracy (2020)\") + \n  scale_x_continuous(breaks = seq(from = 25, to = 45, by = 5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 109 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 109 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis syntax is identical to what was shown at the beginning of the document except for one crucial difference. We added the following line:\n\ngeom_smooth(method = \"lm\") +\n\nHere, we ask R to plot a “smoothed” line to our data to summarize the relationship between the two variables (hence, geom_smooth). The information within the parenthesis (method = \"lm\") indicates what type of line: a linear regression model (“lm”) line. This line has the same properties as the one estimated in the regression above. The grey area around the line, meanwhile, provides the confidence interval for the estimate. We will discuss confidence intervals in a future chapter and week of the class.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_01.html#footnotes",
    "href": "linear_01.html#footnotes",
    "title": "1  Investigating Relationships between Continuous Variables",
    "section": "",
    "text": "This measure of inequality can in theory take on any value from 0 to 100. However, we only observe countries in this dataset with values between 22.6 and 48.↩︎\nYou can learn more about the seq() by typing ?seq into your R consult and hitting enter. That goes for any other function as well.↩︎\nIf you would like to perform multiple bivariate correlations at once, then the correlation library may be of interest. However, that package is not needed for this course.↩︎\nAs we will see in future sections, we can also use a linear regression model to predict a continuous outcome variable with binary/categorical independent variables as well.↩︎\nWe can also obtain the model’s coefficients via the coef() function. For instance: coef(m1) would return just the coefficients from the model. We will use another tool for displaying the output of a regression model in coming classes: the tidy() function from the broom package.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Investigating Relationships between Continuous Variables</span>"
    ]
  },
  {
    "objectID": "linear_02.html",
    "href": "linear_02.html",
    "title": "2  Bivariate Regression with Binary & Categorical Predictors",
    "section": "",
    "text": "2.1 Data Preparation: Converting to factor variable\nOne advantage of linear regression models is that we can predict a dependent variable with different types of predictor variable, including binary and categorical independent variables.\nIn order to use binary and categorical variables as predictors in a regression model we need to include them as a dichotomous or “dummy” variable. One dummy variable is used when the variable is binary while multiple dummies are included when the variable is categorical.1 R automatically creates dummies for factor variables, so we will always convert our binary/categorical variables to factor variables before including them in a regression.2\nWe can see how to do this in the following example which focuses on the variable TYPEDEMO1984. This binary variable records whether a country was considered an autocracy or a democracy in the year 1984. Autocratic countries in 1984 have a score of 1 while democratic countries have a score of 2.\n#Information about what type of variable this is: \nclass(demdata$TYPEDEMO1984)\n\n[1] \"numeric\"\n\n#Simple tabulation\ntable(demdata$TYPEDEMO1984)\n\n\n 1  2 \n86 57\nWe will first convert this variable into a factor variable before including it in our regression model. We can do this either by using the built in factor() command (see Statistics I, 1.6.3) or by using the factorize() function that comes from the rio package. The factorize() function can be used as a quick way of creating a factor variable when the variable in question has value labels associated with it in the dataset. factor() needs to be used in situations where the variable does not have value labels because factorize() won’t produce the right type of outcome in that scenario; see Section A.2 for more on when to use which command and an example that uses factor() to create a factor variable.\nYou can investigate whether a variable has value labels associated with it in two ways. First, you can use the view_df() function from the sjPlot library to obtain an overall view of the variables in the dataset as shown in Section 1.1. Second, you can use the built in attributes() command to investigate a specific variable as below. We are looking for whether there is any information at all and, specifically, any information in the “$labels” area.\nattributes(demdata$TYPEDEMO1984)\n\n$label\n[1] \"Type of democracy, 1984\"\n\n$format.stata\n[1] \"%10.0g\"\n\n$labels\nAutocracies Democracies \n          1           2\nOur variable does indeed have value labels. Countries with a value of 1 were “Autocracies” in 1984, while countries with a value of 2 were “Democracies”. We can thus proceed to create our factor variable using factorize() and then check our work to make sure the results are what we expected.\n#Step 1: Convert to factor variable\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984)) \n\n#Double check your work! \nlevels(demdata$TYPEDEMO1984) # to check levels of factor variable\n\n[1] \"Autocracies\" \"Democracies\"\n\ntable(demdata$TYPEDEMO1984)  # simple tabulation\n\n\nAutocracies Democracies \n         86          57\nHere is how to read the factorize() syntax:\nThe same procedure is used for categorical variables with more than two categories. For instance, the variable Typeregime2006 provides information as to whether a country was considered a liberal democracy (=1), an electoral democracy (=2), or an autocracy (=3) in the year 2006. This variable also has value labels, so we can use factorize() to convert it into being a factor variable:\n#convert variable to a factor variable\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006 = factorize(Typeregime2006))\n\n#Double check your work!\nlevels(demdata$Typeregime2006)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\ntable(demdata$Typeregime2006)\n\n\n  Liberal democracy Electoral democracy           Autocracy \n                 71                  53                  41",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regression with Binary & Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "linear_02.html#data-preparation-converting-to-factor-variable",
    "href": "linear_02.html#data-preparation-converting-to-factor-variable",
    "title": "2  Bivariate Regression with Binary & Categorical Predictors",
    "section": "",
    "text": "factorize(\n\nThis is the name of the function\n\nTYPEDEMO1984\n\nWe then provide the name of the variable that we want to convert into a factor. The lowest numbered level on the variable will be used as the first level and, consequently, as the reference group when including this variable in our regression model. Here, autocracies will be treated as if they have a value of 0, and democracies as if it had a value of 1, in the regression model.\n\n\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nWe recommend creating new variables when recoding or factorizing an existing variable in a dataset (e.g., mutate(regime_type84 = factorize(TYPEDEMO1984))) even though we did not do this above. Creating a new variable when recoding/factorizing makes it easier to correct any mistakes we may inadvertently make when performing data management operations.\n\n\n\n2.1.1 Relevelling\nfactorize() uses the first numeric value as the “reference” group when making a factor variable. We can change what category of a factor variable is used as the reference group via the relevel() function. The example below does this for the Typeregime2006 categorical variable by changing the reference group from “Liberal Democracy” to “Electoral Democracy”.\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_relevel = relevel(Typeregime2006, \"Electoral democracy\"))\n\n\nrelevel(\n\nThe name of the function\n\nTyperegime2006,\n\nThis tells R that we want to work with the variable named Typeregime2006.\n\n\"Electoral Democracy\")\n\nWe then provide the name of the category we want as the reference group. We put “Electoral Democracy” in quotation marks because the variable we are relevelling here is already a factor variable so we must use the label for the category rather than its underlying numeric value.\n\n\nIt is always a good idea to check your efforts at data cleaning before performing analysis so that you can catch mistakes early on:\n\n#Checking our work\nlevels(demdata$Typeregime2006)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\nlevels(demdata$Typeregime2006_relevel)\n\n[1] \"Electoral democracy\" \"Liberal democracy\"   \"Autocracy\"",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regression with Binary & Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "linear_02.html#including-in-a-model-and-interpreting-coefficients",
    "href": "linear_02.html#including-in-a-model-and-interpreting-coefficients",
    "title": "2  Bivariate Regression with Binary & Categorical Predictors",
    "section": "2.2 Including in a Model and Interpreting Coefficients",
    "text": "2.2 Including in a Model and Interpreting Coefficients\nWe include binary/categorical variables in a regression model in the same way that we did for a continuous variable. For instance:\n\n# Using the binary variable as a predictor: \nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984, data=demdata)\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984Democracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\n\n# Using the categorical variable as a predictor: \nmodel_categorical &lt;- lm(v2x_polyarchy ~ Typeregime2006, data=demdata)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ Typeregime2006, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40104 -0.09898  0.00196  0.10773  0.47773 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                        0.75404    0.01734   43.48   &lt;2e-16 ***\nTyperegime2006Electoral democracy -0.32106    0.02653  -12.10   &lt;2e-16 ***\nTyperegime2006Autocracy           -0.50577    0.02866  -17.64   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1461 on 162 degrees of freedom\n  (14 observations deleted due to missingness)\nMultiple R-squared:  0.6789,    Adjusted R-squared:  0.6749 \nF-statistic: 171.2 on 2 and 162 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe output from a model with a binary/categorical variable is the same as when the predictor is continuous with one exception: R will format the variable names differently in the Coefficients area depending on whether the variable is a factor variable or not. If the variable is not a factor variable, then R will simply show the variable name (e.g., “gini_2019”). If the variable is a factor, then the display is formatted as so: “variableCategory”. For instance: “TypeDemo1984Democracies” or “Typeregime2006Autocracy.”\n\n\nThere are some subtle differences in how we interpret the coefficients of a model that (only) includes a factor variable as a predictor variable:\n\n\n\n\n\n\nInterpretation\n\n\n\nThe Estimate column provides the coefficient values from our regression model.\nThe “(Intercept)” row gives you the coefficient for the Intercept: What is the average value of the DV we expect to observe based on this model if all of the included IVs = 0. If the only predictor variable in the model is a factor variable, then the (Intercept) value = the mean of the dependent variable among observations in the initial level of the factor variable, what we often call the “reference group”.\nHere, for instance, is the mean value of v2x_polyarchy among countries with a value of “Autocracies” on the TYPEDEMO1984 variable; it is identical to the (Intercept) value above.\n\ndemdata |&gt; \n1  filter(TYPEDEMO1984 == \"Autocracies\") |&gt;\n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n2  as.data.frame()\n\n\n1\n\nThis removes all observations that do not have the value of “Autocracies” on our factor variable\n\n2\n\nThis option is used to force R to show you all the digits of the mean value so you can compare it to the Intercept value reported in the summary output\n\n\n\n\n  mean_democracy\n1      0.4175698\n\n\nThe coefficient for a continuous predictor variable is interpreted as the slope of a line (e.g., how much does Y change, on average, with each one unit change in X?). The coefficient(s) for a factor variable, on the other hand, are best discussed as telling us the difference in the mean value of the DV between the category named in the output and the reference group. The coefficient for “TYPEDEMO1984Democracies”, for instance, is 0.2726758.3 We would interpret this as telling us that the average value of the dependent variable among countries with a “Democracies” values on TYPEDEMO1984 is 0.2726758 scale points greater than the average value among countries with a value of “Autocracies’ level (our reference group) on that variable.\nWe can again see this by looking at the underlying average values:\n\n# The averages\ndemdata |&gt; \n  group_by(TYPEDEMO1984) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm = T)) |&gt;\n  as.data.frame() \n\n  TYPEDEMO1984 mean_democracy\n1  Autocracies      0.4175698\n2  Democracies      0.6902456\n3         &lt;NA&gt;      0.4638056\n\n# Avg. in Democracies - Avg. in Autocracies\n 0.6902456 - 0.4175698\n\n[1] 0.2726758\n\n\nThe same goes for models with categorical factor variables. The “(Intercept)” value in model_categorical above tells us the average value of the DV among observations in the reference group of the factor variable (there: “Liberal Democracy”) while the coefficients for the factor variable tell us the difference from this average score. The average 2020 democracy score among countries that are coded as an “Electoral Democracy” in 2006 is -0.32 scale points lower than the average 2020 democracy score among the “Liberal Democracy” reference group countries, for instance.\n\ndemdata |&gt; \n  group_by(Typeregime2006) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n  as.data.frame() \n\n       Typeregime2006 mean_democracy\n1   Liberal democracy      0.7540423\n2 Electoral democracy      0.4329811\n3           Autocracy      0.2482683\n4                &lt;NA&gt;      0.3777143\n\n# Avg. in Elec Democracy - Avg. in Lib Democracy\n0.4329811 - 0.7540423\n\n[1] -0.3210612\n\n# Avg. in Autocracy - Avg. in Lib Democracy\n0.2482683 - 0.7540423\n\n[1] -0.505774\n\n\nSee Section 8.3 for how to report these values in our assignments and in formal papers.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regression with Binary & Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "linear_02.html#footnotes",
    "href": "linear_02.html#footnotes",
    "title": "2  Bivariate Regression with Binary & Categorical Predictors",
    "section": "",
    "text": "Specifically, we include k-1 dummies, where k = the number of categories. If the categorical variable has four categories (for instance: North, West, South, and East), then we include three dummy variables in the model. If it has two categories (i.e., a binary variable), then we include one dummy variable in the model.↩︎\nIn some circumstances the variable may already be stored as factor variable in our dataset enabling us to skip this first step. However, we may need to change what category is used as the reference category, which we can do as shown in a subsequent sub-section of this document.↩︎\nWe would normally round this to 2 or 3 digits, but we show you the whole coefficient here so you can see how it compares to the difference in means.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regression with Binary & Categorical Predictors</span>"
    ]
  },
  {
    "objectID": "linear_03.html",
    "href": "linear_03.html",
    "title": "3  Statistical Significance",
    "section": "",
    "text": "3.1 t- and p-values via summary()\nMost of the relevant information for discussing statistical significance and uncertainty is produced by the summary() command.\n#Store the model to an object of your naming\nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984, data=demdata)\n\n#Use summary() to inspect the object\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984Democracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\nWe typically assess the statistical significance of a coefficient by looking at whether there are any symbols next to the value in the Pr(&gt;|t|) column. See Section Section 8.3 for information on how to include this information in your reports.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical Significance</span>"
    ]
  },
  {
    "objectID": "linear_03.html#t--and-p-values-via-summary",
    "href": "linear_03.html#t--and-p-values-via-summary",
    "title": "3  Statistical Significance",
    "section": "",
    "text": "Output Explanation\n\n\n\nInformation concerning uncertainty in our estimates, and statistical significance, is provided in the Coefficients area via these columns:\n\nStd. Error: The standard error of the coefficient\nt value: The t-statistic or t-value for the coefficient (\\(t = \\frac{\\textrm{Coefficient}}{\\textrm{Std.Error}}\\))\nPr(&gt;|t|): The p-value for the t-statistic - the probability of observing a t-value of that size or larger assuming that the null hypothesis of no effect is true and all model assumptions are correct\nAsterisks and Signif. codes: You may see symbols next to the value under Pr(&gt;|t|). These tell you whether the coefficient is statistically significant and at what level. The “Signif. codes” row provides you with the information needed to interpret these symbols. A single asterisk (*), for instance, means that the p-value is smaller than 0.05 but larger than 0.01 while two asterisks (**) tell you that the p-value is smaller than 0.01 but larger than 0.001.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical Significance</span>"
    ]
  },
  {
    "objectID": "linear_03.html#confidence-intervals-via-tidy",
    "href": "linear_03.html#confidence-intervals-via-tidy",
    "title": "3  Statistical Significance",
    "section": "3.2 Confidence Intervals via tidy()",
    "text": "3.2 Confidence Intervals via tidy()\nOne thing not shown in the output produced by summary() is the 95% confidence interval for the coefficient estimates. We can obtain these values alongside the coefficients from our model by using the tidy() function from the broom package. This package needs to be loaded prior to use (this is done at the start of this chapter).\n\ntidy(model_binary, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.371     0.464\n2 TYPEDEMO1984Democrac…    0.273    0.0369      7.38 1.25e-11    0.200     0.346\n\n\n\ntidy(\n\nThe name of the command.\n\nmodel_binary,\n\nThe name of the model we want to work with.\n\nconf.int = TRUE)\n\nThis controls whether the command reports the confidence interval or not. The default behavior of the command is to not show the confidence interval. We must explicitly tell the command that we want this via this option. We can also write conf.int = T and achieve the same end (“T” acting as shorthand for “TRUE”).\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe tidy() function will produce a dataframe with the following columns:\n\nterm: The names of the “terms” in the model (e.g., the Intercept and independent variables).\nestimate: This provides the coefficients for each term in the model\nstd.error: This provides the standard error for the coefficients\nstatistic: This provides the t-value\np.value: This provides the p-value\nconf.low & conf.high: These provides the lower and upper bounds of the confidence interval respectively\n\n\n\nWe can change the level of the confidence interval displayed by tidy(). For instance, we can obtain the 99% confidence interval by adding conf.level = 0.99 to our command.\n\ntidy(model_binary, conf.int = T, conf.level = 0.99)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.357     0.478\n2 TYPEDEMO1984Democrac…    0.273    0.0369      7.38 1.25e-11    0.176     0.369\n\n\nBoth summary() and tidy() show us the coefficients from our model. One advantage of tidy() is that its output is a “tidy” dataframe which can be manipulated in the same ways that we manipulate dataframes more generally (e.g., renaming columns, recoding variables, and so on). We will use this aspect of tidy() in a subsequent chapter to produce graphical displays of our regression results.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistical Significance</span>"
    ]
  },
  {
    "objectID": "linear_04.html",
    "href": "linear_04.html",
    "title": "4  Multiple Linear Regression",
    "section": "",
    "text": "4.1 Performing a Multiple Linear Regression\nIn this example we will regress a measure of the level of electoral democracy in a country (v2x_polyarchy) on three predictor variables (2 continuous and 1 binary):\nRecall that we include binary/categorical variables in regression models by first converting them into a factor variable.\n#Convert binary variable into a factor\ndemdata &lt;- demdata |&gt; \n1  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984))\n\n\n1\n\nfactorize() can be used here because this variable has value labels. Otherwise, we would need to use factor() and supply the labels ourselves.\nWe fit a multiple linear regression using the same command that we used to perform a bivariate regression: lm(). We add multiple predictor variables to the model via the use of a + sign as in this example:\n#Run and store the model \nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, \n                     data=demdata)\nWe can obtain a summary of our coefficients with the summary() command:\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.187394   0.042634   4.395 2.19e-05 ***\ncpi                      0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984Democracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "href": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "title": "4  Multiple Linear Regression",
    "section": "",
    "text": "cpi: CPI stands for “corruption perception index” and is a measure of the extent of corruption in the country’s public sector; higher values on this variable indicate less corruption\nv2caviol: This is a measure concerning the extent of political violence by non-state actors with higher values associated with higher levels of political violence\nTYPEDEMO1984: A binary variable indicating whether the country was a democracy or an autocracy in 1984.\n\n\n\n\n\n\nmodel_multiple &lt;-\n\nHere we tell R to create a new data object called model_multiple that will store the results from our regression. You would change this to a name of your choosing in your examples.\n\nlm(v2x_polyarchy ~\n\nHere we tell R that we want to perform a linear regression (lm() = the command for a linear model) and that the dependent variable is named v2x_polyarchy. This variable is placed to the left of the tilde (~).\n\ncpi + v2caviol + TYPEDEMO1984,\n\nHere we tell R what independent variables we want to include in the model. We separate each variable with a + sign. Changing the order of the independent variables (e.g., TYPEDEMO1984 + v2caviol + cpi) would produce the same model results.\n\ndata = demdata)\n\nFinally, we tell R the name of the object where our data is stored. This information comes after a ‘,’ after the final independent variable.\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nHow we interpret the coefficients is quite similar to how we did with bivariate models, but we now have to incorporate the fact that there are multiple variables in the model into our understanding.\nThe “(Intercept)” value tells us what value we should expect to observe, on average, when all of the included independent variables = 0. If we could observe countries with a value of 0 on the cpi variable AND a value of 0 on v2caviol AND which were coded as an autocracy in 1984, then we’d expect to observe an average electoral democracy score of 0.19.\nThe coefficients for the independent variables can continue to be interpreted as telling us about the slope of a line (continuous variables) or the difference between categories (factor variables). However, they now tell us about the effect of the independent variable while “holding the effect of the other (predictor) variables constant”. For instance:\n\nv2caviol: Electoral democracy scores are expected to decrease by -0.01 scale points with each one unit increase on the political violence scale, holding the effects of prior regime status and corruption constant.\nTYPEDEMO1984: If we were to compare countries with the same level of political violence and corruption, then we’d expect the average 2020 electoral democracy score to be 0.15 scale points higher in countries coded as “Democracies” in 1984 than those coded as “Autocracies”.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear_04.html#sec-standardized-coefficients",
    "href": "linear_04.html#sec-standardized-coefficients",
    "title": "4  Multiple Linear Regression",
    "section": "4.2 Standardized Coefficients",
    "text": "4.2 Standardized Coefficients\nResearchers sometimes report standardized coefficients rather than the default unstandardized coefficients. We can use the standardize_parameters() function from the parameters package to obtain these results.\n\nmultiple_std &lt;- standardize_parameters(model_multiple, \n                       method = \"refit\")\n\nHere is how to read the syntax above:\n\nmultiple_std &lt;-\n\nThis assigns the results of our command to a new data object called multiple_std.\n\nstandardize_parameters(\n\nThis is the name of the command.\n\nmodel_multiple,\n\nThis is the name of the linear regression model object that we have previously saved and which we want to standardize.\n\nmethod = 'refit')\n\nThis specifies what type of standardization we want. The refit option is the default option. It will, in the background, standardize the DV and IVs in the model and then refit the regression model using the standardized versions of the variables.\n\n\nstandardize_parameters() produces a dataframe with the following columns:\n\nglimpse(multiple_std)\n\nRows: 4\nColumns: 5\n$ Parameter       &lt;chr&gt; \"(Intercept)\", \"cpi\", \"v2caviol\", \"TYPEDEMO1984Democra…\n$ Std_Coefficient &lt;dbl&gt; -0.23661987, 0.49272847, -0.05393177, 0.60000039\n$ CI              &lt;dbl&gt; 0.95, 0.95, 0.95, 0.95\n$ CI_low          &lt;dbl&gt; -0.3957424, 0.3306681, -0.2037814, 0.3287296\n$ CI_high         &lt;dbl&gt; -0.07749731, 0.65478881, 0.09591783, 0.87127121\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nParameter: This provides the name of the terms/variables in the model\nStd_Coefficient: The value of the standardized coefficient associated with each variable\nCI: The level of the confidence interval for the standardized coefficient\nCI_low and CI_high: The lower and upper bounds of the confidence interval. These values will be combined into one cell when we call the results below.\n\n\n\nLet us see the results and how they compare to our original results. We will use tidy() to simplify the output of the original model.\n\n#Original Results\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                    estimate std.error statistic      p.value\n  &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)              0.187     0.0426      4.40  0.0000219   \n2 cpi                      0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984Democracies  0.153     0.0349      4.37  0.0000239   \n\n#Standardized\nmultiple_std\n\n# Standardization method: refit\n\nParameter                  | Std. Coef. |         95% CI\n--------------------------------------------------------\n(Intercept)                |      -0.24 | [-0.40, -0.08]\ncpi                        |       0.49 | [ 0.33,  0.65]\nv2caviol                   |      -0.05 | [-0.20,  0.10]\nTYPEDEMO1984 [Democracies] |       0.60 | [ 0.33,  0.87]\n\n\nThe standardized coefficients for the continuous variables in this example indicate how many standard deviations the DV is expected to change when the continuous predictor changes by 1 standard deviation.1\nstandardize_parameters() produces a standardized difference score for factor predictor variables that is equivalent to dividing the difference in the expected mean value of the DV between the two groups being compared by the standard deviation of the dependent variable.2\n\n\n\n\n\n\nInterpretation\n\n\n\nDemocracy scores are expected to decrease by -0.05 standard deviations given a one standard deviation increase on the political violence scale (holding the effect of corruption and prior regime status constant).\nCountries that were democratic in 1984 are expected to be 0.6 standard deviations more democratic in the year 2020, on average, than countries that were autocratic in 1984 (holding constant the effect of corruption and political violence).\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nYou may have noticed that we did not use summary() or tidy() to look at the standardized coefficients. Those commands are not needed when we are looking at the stored output of standardize_parameters() because that output is already a dataframe.\nUsing summary() would produce summary statistics for each column in the output as seen here:\n\nsummary(multiple_std)\n\n  Parameter         Std_Coefficient         CI           CI_low        \n Length:4           Min.   :-0.2366   Min.   :0.95   Min.   :-0.39574  \n Class :character   1st Qu.:-0.0996   1st Qu.:0.95   1st Qu.:-0.25177  \n Mode  :character   Median : 0.2194   Median :0.95   Median : 0.06247  \n                    Mean   : 0.2005   Mean   :0.95   Mean   : 0.01497  \n                    3rd Qu.: 0.5195   3rd Qu.:0.95   3rd Qu.: 0.32921  \n                    Max.   : 0.6000   Max.   :0.95   Max.   : 0.33067  \n    CI_high        \n Min.   :-0.07750  \n 1st Qu.: 0.05256  \n Median : 0.37535  \n Mean   : 0.38612  \n 3rd Qu.: 0.70891  \n Max.   : 0.87127  \n\n\nUsing tidy() on it would produce an error because tidy() is meant for use with objects created from statistical models:\n\ntidy(multiple_std)\n\nWarning: Data frame tidiers are deprecated and will be removed in an upcoming\nrelease of broom.\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in var(if (is.vector(x) || is.factor(x)) x else as.double(x), na.rm =\nna.rm): NAs introduced by coercion\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nError in x - stats::median(x, na.rm = na.rm): non-numeric argument to binary operator",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear_04.html#footnotes",
    "href": "linear_04.html#footnotes",
    "title": "4  Multiple Linear Regression",
    "section": "",
    "text": "This is true for the “refit” version of standardization used here. We could ask this command to only standardize the predictor variables while leaving the DV on its original scale by including the option “include_response = F” in our command. The standardized continuous predictor would be interpreted as telling us how much the mean of Y (on its original scale) is expected to change given a 1 standard deviation change in X. This would be sensible in cases where the scale of our dependent variable is quite easy to understand and where standardizing the DV complicates interpretations. For instance, if we were predicting the percentage of votes cast for a political party, it is probably easier to interpret “a 1 standard deviation change in X is associated with a gain of 2% more votes for the party” than “a 1 standard deviation change in X is associated with a gain of 0.3 standard deviations in votes”.↩︎\nThis standardized difference is not directly comparable to the standardized coefficients for the continuous variables in an important sense. The standardized difference for a factor variable tells us what happens when X changes by its full range, i.e., when X goes from 0 to 1. The standardized coefficients for the continuous variables tell us what happens when X changes by 1 standard deviation…but that is only part of the range of the variable. We can obtain more directly comparative standardized coefficients by including the option two_sd = TRUE in our command. This scales the continuous variables by two standard deviations rather than one and thus gives a better approximation of what a full change in the continuous X leads to.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "linear_05.html",
    "href": "linear_05.html",
    "title": "5  Predicted & Residual Values",
    "section": "",
    "text": "5.1 Predicted Values and Residuals for Individual Observations\nLinear regression models make predictions about the value of the DV we should expect to observe for each observation used in fitting the model. These unit-level predictions will likely differ from the actual observed value of the DV by some amount; we call the difference between observed and predicted value “residuals” or “prediction errors”.\nWe can use the predictions() command from the marginaleffects package to see what our model predicts, and how wrong those predictions are, for each observation used in fitting the model.1\nmodel_binary_predictions &lt;- predictions(model_binary, newdata = demdata) |&gt; \n  as_tibble() #as_tibble() used for ease of display; see Warning below\nHere is how to read this syntax:\nHere is what the output looks like:\nmodel_binary_predictions\n\n# A tibble: 179 × 49\n   rowid estimate std.error statistic    p.value s.value conf.low conf.high\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 2     2    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 3     3    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 4     4    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 5     5    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 6     6    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 7     7    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 8     8    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 9     9   NA       NA           NA   NA             NA    NA        NA    \n10    10    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n# ℹ 169 more rows\n# ℹ 41 more variables: country_name &lt;chr&gt;, year &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;,\n#   v2x_libdem &lt;dbl&gt;, v2x_egaldem &lt;dbl&gt;, v2cacamps &lt;dbl&gt;, v2caviol &lt;dbl&gt;,\n#   e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;, e_regionpol_6C &lt;dbl&gt;,\n#   v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;, bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;,\n#   dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;, TypeSoc2005 &lt;dbl&gt;,\n#   TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, …\nWe can use this saved data object to calculate the residual value for each observation: the difference between the actual value on the DV and what our model predicts we should observe for the observation by creating a new variable where we subtract “estimate” from our DV.\nmodel_binary_predictions &lt;- model_binary_predictions |&gt; \n  mutate(residual_value = v2x_polyarchy - estimate) #residual = actual - predicted\nWe could then use this newly created variable to investigate the results of our model and consider, for instance, which observations have particularly large residual values. This can be useful when checking the assumptions of our model, which we will learn how to do in Chapter 7 .3\nmodel_binary_predictions |&gt; \n  select(country_name, v2x_polyarchy, estimate, residual_value) \n\n# A tibble: 179 × 4\n   country_name v2x_polyarchy estimate residual_value\n   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Mexico               0.647    0.690        -0.0432\n 2 Suriname             0.761    0.418         0.343 \n 3 Sweden               0.908    0.690         0.218 \n 4 Switzerland          0.894    0.690         0.204 \n 5 Ghana                0.72     0.418         0.302 \n 6 South Africa         0.703    0.418         0.285 \n 7 Japan                0.832    0.690         0.142 \n 8 Myanmar              0.436    0.418         0.0184\n 9 Russia               0.262   NA            NA     \n10 Albania              0.485    0.418         0.0674\n# ℹ 169 more rows",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicted & Residual Values</span>"
    ]
  },
  {
    "objectID": "linear_05.html#predicted-values-and-residuals-for-individual-observations",
    "href": "linear_05.html#predicted-values-and-residuals-for-individual-observations",
    "title": "5  Predicted & Residual Values",
    "section": "",
    "text": "model_binary_predictions\n\nWe are assigning the output of our command to a new object called model_binary_predictions. You would name this whatever you wish in your examples.\n\npredictions(model_binary,\n\nThe name of the command is predictions. We place within the parentheses the name of the data object where we have stored our model results. You should change this name to whatever you have named the model you want to make predictions from.\n\nnewdata = demdata)\n\nHere we tell the command where the data originally comes from. This has a specific purpose: it tells the command that the output it creates should include both the predicted values for each observation in the original dataset and all of the other variables in the original dataset for these observations. This can be useful for investigating the characteristics of observations that have particularly sizable residual values. Omitting newdata = demdata, on the other hand, would produce an object that contains predicted values for each observation used in fitting the model as well as their observed values on the variables using in the model but not other variables from the original dataset. You would change demdata to the name of the data object used when fitting your regression model.\n\n\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nestimate: This is the predicted value of the DV for the observation based on the regression model\nstd.error, statistic, p.value, conf.low, conf.high: These report the standard error, test statistic, p-value, and the lower and upper bounds of the 95% confidence interval for the estimate. They tell us about the uncertainty around the prediction. The s.value column provides another way of thinking about uncertainty, but one we won’t cover; it is non-examinable.2\nThe ensuing columns in the data frame are the variables from the original dataset and are noted at the bottom of the output (“41 more variables: country_name &lt;chr&gt;, …”).",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicted & Residual Values</span>"
    ]
  },
  {
    "objectID": "linear_05.html#predicted-values-at-specific-values-of-the-iv-bivariate-model",
    "href": "linear_05.html#predicted-values-at-specific-values-of-the-iv-bivariate-model",
    "title": "5  Predicted & Residual Values",
    "section": "5.2 Predicted Values at Specific Values of the IV (Bivariate Model)",
    "text": "5.2 Predicted Values at Specific Values of the IV (Bivariate Model)\nWe just saw how to obtain model predictions for each individual observation used in creating the model. We may also want to know what we should expect to see, on average, for observations with some specific value of an independent variable. For instance, what is the democracy score we should expect to observe among countries that were autocracies in 1984? Or, what is the democracy score we should expect to observe (based on our model) for countries with a very low level of inequality (say, 25 on our scale)? We can also use the predictions() function to realize this end.\nAs a first example, we will use predictions() to calculate the average predicted value among countries that were either an autocracy in 1984 or a democracy in 1984 based on our bivariate model (model_binary).\n\npredictions(model_binary, \n            by = \"TYPEDEMO1984\") |&gt; \n1  as_tibble()\n\n\n1\n\nSee the Warning box below for why we include the as_tibble() line of syntax here\n\n\n\n\n# A tibble: 2 × 10\n  rowid TYPEDEMO1984 estimate std.error statistic   p.value s.value conf.low\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Democracies     0.690    0.0287      24.1 3.16e-128    424.    0.634\n2     2 Autocracies     0.418    0.0233      17.9 1.16e- 71    236.    0.372\n# ℹ 2 more variables: conf.high &lt;dbl&gt;, rowid_dedup &lt;int&gt;\n\n\n\npredictions(model_binary,\n\nWe first specify the name of the command and then the model from which we want to make predictions.\n\nby = \"TYPEDEMO1984\")\n\nThis tells the command that we want to make predictions “by level of” the variable listed in the parentheses. In this case, we get a prediction for each of category of this variable. We can note two things here. First, we use by= option with factor variables and a different method for continuous variables (see below). Second, we do not specify newdata= here because we want output with average predictions for both categories rather than output that contains data on all individual observations.\n\n\nWe can also do this in situations where the predictor variable is continuous in nature. For instance, we might predict the v2x_polyarchy score with a measure of economic inequality (gini_2019) and then wonder: what is the democracy score we expect to observe for a country with a rather low level of inequality (25) versus one with a rather high level of inequality (45)?\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,45))) |&gt; \n1  as_tibble()\n\n\n1\n\nSee the Warning box below for why we include the as_tibble() line of syntax here\n\n\n\n\n# A tibble: 2 × 10\n  rowid estimate std.error statistic  p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e-64   211.     0.675     0.852\n2     2    0.527    0.0493      10.7 1.10e-26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\nnewdata = datagrid(gini_2019 = c(25,45))\n\nThis is how we obtain predictions for specific values of a continuous variable for which we want a prediction. newdata = datagrid( can remain the same in your examples. You would then change gini_2019 to the name of the continuous variable of interest to you. The contents of c() (here: c(25,45)) dictate what values of the specified variable predictions() will make a prediction for; in this case, for the values of 25 and 45. gini_2019 is a numeric variable, so we can provide the numeric values of interest to us without parentheses. We can also use newdata = datagrid() with factor variables, although this is slightly more effort than simply using by = and would require us to provide the name of each category in parentheses.\n\n\nWe can naturally expand this so that we look at predictions for other values of this variable by including additional options in c():\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,30,35,40,45))) |&gt; \n1  as_tibble()\n\n\n1\n\nSee the Warning box below for why we include the as_tibble() line of syntax here\n\n\n\n\n# A tibble: 5 × 10\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e- 64   211.     0.675     0.852\n2     2    0.705    0.0316      22.3 2.20e-110   364.     0.643     0.766\n3     3    0.645    0.0267      24.2 6.30e-129   426.     0.593     0.698\n4     4    0.586    0.0345      17.0 1.04e- 64   213.     0.518     0.654\n5     5    0.527    0.0493      10.7 1.10e- 26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nWe ended our predictions() commands above with another line that specified as_tibble(). This last step is not necessary for the command to work. Here is an example from above but without that final line:\n\npredictions(model_binary, by = \"TYPEDEMO1984\")\n\n\n TYPEDEMO1984 Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  Democracies    0.690     0.0287 24.1   &lt;0.001 423.5 0.634  0.746\n  Autocracies    0.418     0.0233 17.9   &lt;0.001 235.6 0.372  0.463\n\nColumns: rowid, TYPEDEMO1984, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rowid_dedup \nType:  response \n\n\nThe key difference here is in how the output is displayed in R: the default output of predictions() in the Console shows different names for the columns (e.g., Estimate rather than estimate, 2.5% rather than conf.low) to make things look a bit neater (you can see the actual names of the columns in the dataframe that predictions() produces in the final row of the output). We used the as_tibble() option above so that you could see the underlying data and variable names. We will use the output of this command in later chapters to produce plots of our data. The main warning here is to make sure you use the correct variable names (e.g., estimate rather than Estimate).",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicted & Residual Values</span>"
    ]
  },
  {
    "objectID": "linear_05.html#predicted-values-multiple-linear-models",
    "href": "linear_05.html#predicted-values-multiple-linear-models",
    "title": "5  Predicted & Residual Values",
    "section": "5.3 Predicted Values (Multiple Linear Models)",
    "text": "5.3 Predicted Values (Multiple Linear Models)\nWe can naturally use these commands to obtain the residuals and predicted values from a model with multiple predictors. The process for finding the residuals of a multiple linear regression model is the same as above so we do not show it again. The process for calculating average predicted values is also highly similar, but with one important difference when the predictor is a factor variable.\n\n5.3.1 Predictions for a Continuous Predictor Variable\nHere are the results from our multiple linear regression model:\n\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                    estimate std.error statistic      p.value\n  &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)              0.187     0.0426      4.40  0.0000219   \n2 cpi                      0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984Democracies  0.153     0.0349      4.37  0.0000239   \n\n\ncpi is a measure of perceived corruption in a country. It can theoretically range from 0-100 (with higher values indicating less perceived corruption), although it only ranges between 12 and 88 among countries in our model.\n\n1predictions(model_multiple) |&gt;\n2  select(cpi) |&gt;\n3  summary()\n\n\n1\n\nUsed to filter out any observations in our dataset that are not in the model due to missingness on one or more of the variables in the model\n\n2\n\nSelects just the the cpi variable\n\n3\n\nFind its summary statistics\n\n\n\n\n      cpi       \n Min.   :12.00  \n 1st Qu.:28.00  \n Median :39.50  \n Mean   :43.37  \n 3rd Qu.:56.75  \n Max.   :88.00  \n\n\nWe might ask ourselves this question: what is the level of democracy we should expect to observe based on our model for countries with different levels of cpi but representative values on the other predictor variables? The coefficient for cpi indicates that the predicted value of democracy should increase with each one unit increase in cpi…but do democracy scores change by a little, or a lot, when we move across the range of the corruption variable? Here is how we would use predictions() to obtain the expected democracy score when cpi takes on values between 20 and 80 in 10pt. increments in order to answer that question:\n\npreds1 &lt;- predictions(model_multiple, \n            newdata = datagrid(cpi = c(20,30,40,50,60,70,80))) |&gt; \n  as_tibble()\n\n\npreds1 &lt;-\n\nWe save our results as a new data object so that we can use it again later. We name it preds1 here, while you would give it a name of your choosing.\n\npredictions(model_multiple,\n\nWe then specify the name of our command and the name of the model we want to make predictions from.\n\nnewdata = datagrid(cpi = c(20,30,40,50,60,70,80))\n\nWe then specify what IV, and what specific values of this IV, we want to make predictions for. We use the newdata = datagrid() option because “cpi” is a continuous variable. We do not need to put the values in quotation marks because it is a numerical variable.\n\n\nHere are the predictions.\n\npreds1\n\n# A tibble: 7 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.318    0.0278      11.4 2.41e- 30    98.4    0.264     0.373\n2     2    0.382    0.0217      17.6 3.30e- 69   227.     0.339     0.424\n3     3    0.445    0.0199      22.4 2.59e-111   367.     0.406     0.484\n4     4    0.509    0.0233      21.9 6.10e-106   350.     0.463     0.555\n5     5    0.573    0.0302      18.9 4.92e- 80   263.     0.513     0.632\n6     6    0.636    0.0389      16.4 2.78e- 60   198.     0.560     0.713\n7     7    0.700    0.0483      14.5 1.17e- 47   156.     0.605     0.795\n# ℹ 4 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, cpi &lt;dbl&gt;,\n#   v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nestimate: The predicted value\nstd.error through conf.high: Uncertainty estimates relating to the prediction (e.g., its standard error, the p-value, and confidence intervals).\n“4 more variables”: This row tells us what other columns are in our “tidied” dataframe (with the number 4 here likely to be different in examples where the model has a different number of predictor variables than in this example). The names refer to the variables in our model and would be different in your own examples. The columns for the IVs (here: v2caviol, TYPEDEMO1984, and cpi) will list the values of these variables used in producing the prediction.\n\n\n\nIn the example above, predictions() has automatically held our two control variables (v2caviol and TYPEDEMO1984) “constant” at the same value when calculating each predicted value. predictions() will hold continuous controls constant at their mean value, and factor variables at their mode, when newdata = datagrid() is used in this way. We can see this by looking at the columns for our independent variables in the output created by predictions():\n\npreds1 |&gt; \n  select(estimate, cpi, v2caviol, TYPEDEMO1984)\n\n# A tibble: 7 × 4\n  estimate   cpi v2caviol TYPEDEMO1984\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;       \n1    0.318    20   -0.394 Autocracies \n2    0.382    30   -0.394 Autocracies \n3    0.445    40   -0.394 Autocracies \n4    0.509    50   -0.394 Autocracies \n5    0.573    60   -0.394 Autocracies \n6    0.636    70   -0.394 Autocracies \n7    0.700    80   -0.394 Autocracies \n\n\n\n\n5.3.2 Predictions for a Factor Predictor Variable\nWe can use the same procedure as above to obtain predicted value for each category of a binary or categorical factor variable. Recall that we do this by using by= rather than newdata = datagrid().4 However, we do need to take one additional step here that we don’t have to perform in the previous example.\n\npreds2 &lt;- predictions(model_multiple, by= \"TYPEDEMO1984\", \n                      newdata = \"mean\") |&gt; \n  as_tibble()\n\n\nby = \"TYPEDEMO1984\"\n\nThis tells the command that we want predicted values for each category of our factor variable.\n\nnewdata = \"mean\")\n\nThis tells the command that we want to hold the other variables in the model constant at their mean (if a continuous variable) or mode (if a factor variable). This is done automatically in the earlier example, but must be specified here due to the use of the by = option.\n\n\nHere are the predictions:\n\npreds2\n\n# A tibble: 2 × 12\n  rowid TYPEDEMO1984 estimate std.error statistic   p.value s.value conf.low\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Democracies     0.620    0.0260      23.8 2.47e-125    414.    0.569\n2     2 Autocracies     0.467    0.0205      22.8 4.94e-115    380.    0.427\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, cpi &lt;dbl&gt;, v2caviol &lt;dbl&gt;,\n#   v2x_polyarchy &lt;dbl&gt;\n\n\nWe can again see that predictions() is holding the other predictor variables “constant” when making these predictions:\n\npreds2 |&gt; \n  select(estimate, TYPEDEMO1984, cpi, v2caviol)\n\n# A tibble: 2 × 4\n  estimate TYPEDEMO1984   cpi v2caviol\n     &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1    0.620 Democracies   43.4   -0.394\n2    0.467 Autocracies   43.4   -0.394\n\n\n\n\n5.3.3 Predictions for specific combinations of the predictor variables\nThe first set of predictions we made above were predictions for each observation used in fitting the model based on the specific values of the independent variables associated with the observation. The second set of predictions we made focused on the average value of the DV our model tells us we should expect to see if one of the IVs equals a specific value and the other IVs are held constant at their mean or mode. We can also use predictions() to calculate predicted values for specific hypothetical cases. In this example, for instance, we use predictions() to estimate the democracy score in a country that was a democracy in 1984, has a corruption score equal to the maximum value that we observe in our data (88), and has the minimum level of political violence observed in the data (-3.429). We do this by including all predictors in the newdata = datagrid() portion of the syntax. If we left one of the variables out, then it would be held constant at its mean or mode depending on what type of variable it is.\n\npredictions(model_multiple, \n            newdata = datagrid(cpi = c(88), \n                               v2caviol = c(-3.429), \n                               TYPEDEMO1984 = c(\"Democracies\"))) |&gt; \n  as_tibble()\n\n# A tibble: 1 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high   cpi\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1    0.930    0.0392      23.7 1.89e-124    411.    0.853      1.01    88\n# ℹ 3 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984 &lt;fct&gt;, v2x_polyarchy &lt;dbl&gt;",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicted & Residual Values</span>"
    ]
  },
  {
    "objectID": "linear_05.html#footnotes",
    "href": "linear_05.html#footnotes",
    "title": "5  Predicted & Residual Values",
    "section": "",
    "text": "We will introduce the augment() function from the broom package in a subsequent chapter as an alternative way of observing the residuals from a model. We use the predictions() command here because it is easier to create a dataframe that contains the model’s predictions, residuals, and all of the data from the original dataset with this command than it is with augment().↩︎\nThe s-value is an attempt to translate the p-value into a measure that some feel is easier to interpret. Specifically, it tells us “How many consecutive”heads” tosses would provide the same amount of evidence (or “surprise”) against the null hypothesis that the coin is fair?” As an example, a p-value of 0.05 would have a corresponding s-value of 4.3 or so. We might then say that a p-value of 0.05 is about as surprising as flipping a fair coin four times and seeing the coin land on heads all four times. Would you be comfortable making a statement that the coin is weighted rather than fair based on that string of coin flips? In the context of the output of produced by predictions() (and by the slopes() command that we will see in later chapters), higher S-values would indicate that we should be increasingly surprised to see our results if the value of the thing we’re estimating is actually 0. This statistic is not all that useful for our predicted values but could be more useful for understanding how surprising a coefficient or “marginal effect” estimate happens to be. If you like, you can read a deep dive on what p-values are, some of the complications researcher’s run into when interpreting them, and a discussion of what s-values are and how they may help matters in this blog post. The s-value is not examinable however.↩︎\nRussia has an NA value for estimate and residual_value because it has a missing value on the TYPEDEMO1984 variable and hence was not included in the regression model.↩︎\nWe could technically use newdata = datagrid() but we’d then need to type out the factor levels (e.g., newdata = datagrid(TYPEDEMO1984 = c(\"Autocracies', \"Democracies\")) . The by = option is thus a bit easier to use.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Predicted & Residual Values</span>"
    ]
  },
  {
    "objectID": "linear_06.html",
    "href": "linear_06.html",
    "title": "6  Model Fit",
    "section": "",
    "text": "6.1 R2, Adjusted R2, and the Model F-Test\nOur initial example focuses on a linear regression model in which we predict a country’s electoral democracy score in 2020 (v2x_polyarchy) based on the country’s level of perceived corruption (cpi), political violence (v2caviol), and the country’s regime status in 1984 (TYPEDEMO1984).\nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data=demdata)\nWe can obtain the most commonly used “model fit” statistics for linear regression models via the summary() command:\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              0.187394   0.042634   4.395 2.19e-05 ***\ncpi                      0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984Democracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16\nMuch as the tidy() command simplifies the output from summary(), the broom package provides a command that can show us the model fit statistics in a nice table: glance():\nglance(model_multiple)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.507         0.496 0.181      47.3 4.46e-21     3   43.5 -77.0 -62.3\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\nThe relevant statistics are provided in the r.squared (R2), adj.r.squared (Adjusted R2), statistic (F-statistic), and p.value (p-value for the F-statistic) columns. nobs provides the number of observations in the model:\nglance(model_multiple) |&gt; \n  select(nobs)\n\n# A tibble: 1 × 1\n   nobs\n  &lt;int&gt;\n1   142",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit</span>"
    ]
  },
  {
    "objectID": "linear_06.html#r2-adjusted-r2-and-the-model-f-test",
    "href": "linear_06.html#r2-adjusted-r2-and-the-model-f-test",
    "title": "6  Model Fit",
    "section": "",
    "text": "Output Explanation\n\n\n\nThe relevant information is shown at the bottom of the output:\n\nMultiple R-squared: The R2 statistic, which is commonly interpreted as the % of variance in the DV that our model can “explain”\nAdjusted R-squared: The adjusted R2 statistic, which adjusts the R2 statistic by accounting for the number of independent variables in the model.\nF-statistic…: The first number provides the F-statistic for the model (47.26) in the example above. The number after “p-value:” is the p-value for this statistic. The null hypothesis of this test is that none of the independent variables (here, cpi, v2caviol, TYPEDEMO1984) are statistically significant. A statistically significant F-statistic thus indicates that at least one of the IVs is statistically significant although it does not tell us which coefficient is statistically significant.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit</span>"
    ]
  },
  {
    "objectID": "linear_06.html#sec-linear-comparing-models",
    "href": "linear_06.html#sec-linear-comparing-models",
    "title": "6  Model Fit",
    "section": "6.2 Comparing Models",
    "text": "6.2 Comparing Models\nThe F-statistic we just saw compares the fit of our model against the fit of a “null” model wherein predictions are made using only the mean of the dependent variable. It provides us with a way of testing whether at least one of our independent variables is statistically significant.\nWe might also want to compare the fit of two (or more) nested models against one another to talk about which one “fits” the best. “Nested” models refer to models that have the same observations and the variables included in one model are a subset of the variables used in another. In this example, we will compare models with: just cpi, cpi and v2caviol, and then one with all predictor variables to see how to do this.\nWe need to take a preliminary step to accomplish this task. We want to make sure that we are comparing models that have the same observations in them so that we can be sure that differences in model fit statistics between the models are not being driven by having models conducted using different observations. This initial syntax removes all observations with a missing value on at least one of the four variables in our fully specified regression model.\n\ndemdata_complete &lt;- demdata |&gt; \n  filter(complete.cases(v2x_polyarchy, cpi, v2caviol, TYPEDEMO1984))\n\nNext we will perform each of our regressions. We begin with the “null” model for demonstration purposes and then fit models with predictor variables:\n\n#Null model\nmodel1 &lt;- lm(v2x_polyarchy ~ 1, data = demdata_complete)\n\n#Model with just cpi\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata_complete)\n\n#Model with cpi & v2caviol\nmodel3 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol, data = demdata_complete)\n\n#Model with all predictors\nmodel4 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata_complete)\n\nWe can compare the R2/Adj. R-Squared of the models to get an initial sense of which one “fits” better. Here is an overview of those statistics:\n\n\n\n\n\n\n\n\nModel\nR2\nAdj. R2\n\n\n\n\nModel 1\n0\n0\n\n\nModel 2\n0.437\n0.433\n\n\nModel 3\n0.438\n0.43\n\n\nModel 4\n0.507\n0.496\n\n\n\nIt looks like Model 4 fits the best. However, we should formally test whether the difference in these statistics are statistically significant before jumping to this conclusion. We can do this through the anova() command. This command does not require you to load a new library.\n\nanova(model1, model2, model3, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi\nModel 3: v2x_polyarchy ~ cpi + v2caviol\nModel 4: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq        F    Pr(&gt;F)    \n1    141 9.1323                                    \n2    140 5.1436  1    3.9887 122.2045 &lt; 2.2e-16 ***\n3    139 5.1285  1    0.0151   0.4614    0.4981    \n4    138 4.5043  1    0.6243  19.1269 2.392e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nanova() is the name of the command. We place the names of the models we want to compare with one another within the parentheses.\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe top half of the output provides a review of the models being compared to one another. The remainder of the output can be read as so:\n\nRes.Df: The residual degrees of freedom of the model\nRSS: This stands for “residual sum of squares”. RSS measures the variation in the model’s residuals. RSS = \\(\\sum(y_{i} - \\hat{y}_{i})^2\\), where \\(\\sum\\) stands for “sum up”, \\(y_{i}\\) is the observed value of the DV for an observation in the model, and \\(\\hat{y}_{i}\\) is the predicted value for that observation based on the model.1 RSS tells us how much of the variation in the DV a model can’t “explain” or predict. If we are comparing a model in a given row with the one in the preceding row, then the one with the smaller value fits the data better although the difference between models may not be statistically significant (i.e., we might not be able to rule out the null hypothesis that the two models fit the data equivalently well).\nDF: The number of independent variable coefficients that have been added in the model relative to the preceding model in the sequence. This equals 1 here because each model adds one term.2\nSum of Sq: The model or “regression” sum of squares is given by this formula: \\(\\sum(\\hat{y}_{i} - \\bar{y})^2\\), where \\(\\hat{y}_{i}\\) is the predicted value for a given observation and \\(\\bar{y}\\) is the mean of the dependent variable among all observations in the model.3 In essence, the model sum of squares measures the variability of the dependent variable that is connected to the independent variables in the model. The specific value under Sum Sq in the anova() output focuses on the change in the Sum of Sq that we get by adding the extra variable(s) to the model (e.g., the increase in the Sum of Sq. we get when moving from a model with just cpi to one with cpi and v2caviol = 0.0151). The Sum of Sq value in a given row is equal to the difference between the RSS value in the preceding row and the RSS value in the focal row (e.g., Sum of Sq in Row 2 = 9.1323 - 5.1436 = 3.9887). If we are comparing a model in a given row with the one in the preceding row, then the one with the larger value is likely to fit better although the difference may not be statistically significant.\nF & Pr(&gt;F): The F-statistic and its associated p-value for the test. The null hypothesis this is testing is whether a model in a given row fits better than the model in the preceding row. In essence, it is testing whether any of the variables added in the second model in the comparison are statistically significant or not. If statistically significant, then we conclude that the more complex model “fits better”.\n\n\n\nWe make formal judgments about whether a model “fits” better than another one by focusing on the F-statistic and whether it is statistically significant. We read the results for a given row in relation to the preceding one (e.g., the results in row four compare Model 4 against Model 3). In this case, Model 2 fits better than Model 1 (p &lt; 0.001); Model 3 does not fit better than Model 2 (p = 0.50); and Model 4 fits better than Model 3 (p &lt; 0.001). This implies that Model 4 fits better than all of the other models, which we could more directly test by only including Model 4 and one of the other models in the command.\n\n#Model 4 vs. Model 2\nanova(model2, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    140 5.1436                                  \n2    138 4.5043  2   0.63935 9.7941 0.0001053 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Model 4 vs. Model 1\nanova(model1, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    141 9.1323                                  \n2    138 4.5043  3     4.628 47.264 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nanova() compares models sequentially. The order of the models in the anova() command matters as a result. As an example:\n\nanova(model4, model1, model2, model3)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984\nModel 2: v2x_polyarchy ~ 1\nModel 3: v2x_polyarchy ~ cpi\nModel 4: v2x_polyarchy ~ cpi + v2caviol\n  Res.Df    RSS Df Sum of Sq        F Pr(&gt;F)    \n1    138 4.5043                                 \n2    141 9.1323 -3   -4.6280  47.2642 &lt;2e-16 ***\n3    140 5.1436  1    3.9887 122.2045 &lt;2e-16 ***\n4    139 5.1285  1    0.0151   0.4614 0.4981    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEach row in our output still compares the fit of the more complex model in the comparison against the simpler model.\nThe second row of results compares our null model (model1) against our most complex model (model4). We get a negative value for “DF” and “Sum of Sq” here because Model 1 has fewer terms and fits worse than Model 4. The difference is statistically significant although we would interpret that as telling us that Model 1 fits worse than Model 4 (or, conversely, that Model 4 fits better than Model 1). The third row, meanwhile, compares model2 (just cpi as a predictor) against model1 (the null model). Notice how the results in this row match those above. Finally, the results in the final row compare model3 against model2, again with the same results as above.\nWe could perhaps work our way from these results to a claim about which model “fits the best”, but it would be much more complicated than in the example above. If you are comparing nested models against one another, then you should list the models in terms of increasing complexity as above.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit</span>"
    ]
  },
  {
    "objectID": "linear_06.html#footnotes",
    "href": "linear_06.html#footnotes",
    "title": "6  Model Fit",
    "section": "",
    "text": "The equation is non-examinable.↩︎\nThe DF column is not indicating how many extra independent variables were added but how many terms/coefficients are added. This distinction is mainly relevant when we are adding factor variables (and, especially, factor variables with more than two categories) to the model. Recall that a categorical variable with more than two levels will be represented by k - 1 coefficients in a model. If we added a factorized categorical variable with four levels (North, East, South, West) to a model, then we’d be adding three independent variable coefficients/terms to our model. In that case, DF would equal 3 rather than 1.↩︎\nThis equation is non-examinable.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit</span>"
    ]
  },
  {
    "objectID": "linear_07.html",
    "href": "linear_07.html",
    "title": "7  OLS Assumptions",
    "section": "",
    "text": "7.1 Independent errors and the Durbin-Watson test\nThe assumption of independent errors relates to the condition that observations are independently selected from each other. This condition is not met when there is a time relation between observations or when there is geographical clustering (e.g. when multistage sampling is used for a survey).\nThe Durbin-Watson test can be used to check whether a time relation leads to too much correlation between the errors. It cannot be used when there is no time relation (e.g. a cross-sectional survey). In addition, the dataset needs to be ordered on the time dimension (old-to-new or new-to-old).\nThe example dataset “gdp-dem, time order.csv” adheres to these conditions. It records the gdp and democracy scores for a single country over time. The dataset is fictitious. There is no missing data, but the below code can also be used for datasets with missing values (‘NA’).\ndta &lt;- import(\"gdp-dem, time order.csv\")\nhead(dta, n = 10L) #So we just see the first ten rows\nyear  gdp democracy\n1  1990 8400        50\n2  1991 8500        55\n3  1992 8800        60\n4  1993 8700        60\n5  1994 8600        60\n6  1995 8800        65\n7  1996 9200        65\n8  1997 9300        65\n9  1998 9500        70\n10 1999 9700        70\nThis data is properly sorted by time. We can use the arrange function from the dplyr package (part of tidyverse) in situations where the dataset is not properly sorted.\n#sort ascending\ndta &lt;- dta |&gt;\n  arrange(year)\n\n#sort descending\ndta &lt;- dta |&gt;\n  arrange(desc(year))\nWe run a simple bivariate regression with gdp as the independent variable and democracy as the dependent variable:\n#Run model\ntime_model &lt;- lm(democracy ~ gdp, data = dta)\n\n#Examine coefficients\ntidy(time_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept) -36.2     13.9         -2.61 0.0143      \n2 gdp           0.0111   0.00148      7.50 0.0000000291\nWe use the Durbin-Watson test through the car package to assess whether we have an issue with serial autocorrelation.\ndurbinWatsonTest(time_model) \n\n lag Autocorrelation D-W Statistic p-value\n   1       0.5124721     0.8369625       0\n Alternative hypothesis: rho != 0\nThe D-W statistic for this model is 0.84 , which indicates that we have a problem with autocorrelation.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#independent-errors-and-the-durbin-watson-test",
    "href": "linear_07.html#independent-errors-and-the-durbin-watson-test",
    "title": "7  OLS Assumptions",
    "section": "",
    "text": "dta &lt;- dta\n\nThis code specifies that we want the ordered dataset to replace the original. We could also create a new dataset which is ordered, but that is generally not needed.\n\narrange(year)\n\nThis function asks R to sort (‘arrange’) the dataset based on the variable year. This sorts the dataset from old to new. We can sort on multiple variables by separating them with a comma.\n\narrange(desc(year))\n\nThis function sorts the dataset on the descending order of the variable(s) specified in brackets.\n\n\n\n\n\n\n\ndurbinWatsonTest(modelname)\n\nUses the Durbin-Watson test on a model, the name of which is specified in brackets.\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nAutocorrelation: Degree of correlation between errors\nD-W Statistic: The Durbin-Watson statistic. Values below 1 or above 3 indicate too much autocorrelation.\np-value: The p-value for a hypothesis test wherein the null hypothesis is that the autocorrelation is not significantly different from 0.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "href": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "title": "7  OLS Assumptions",
    "section": "7.2 No excessive multicollinearity",
    "text": "7.2 No excessive multicollinearity\nWe will use a different dataset, one without the problem of autocorrelation, for our other assumption tests. We use the democracy dataset (demadata.rds) and run a multiple regression model predicting V-Dem polyarchy scores based on inequality (gini_2019), history of democracy (TYPEDEMO1984, factorized), and past gross domestic product per capita (GDP2006).\n\n#Load Data\ndemdata &lt;- import(\"demdata.rds\") |&gt; \n  as_tibble()\n\n#Factorize our binary variable\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984))\n\n#Run and store a model and then look at the output\nmodel_multiple &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + GDP2006, data = demdata)\n\nsummary(model_multiple)\n\n\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             6.78e-1   2.02e-1      3.36 0.00153  2.72e-1 1.08     \n2 gini_2019              -4.99e-3   4.98e-3     -1.00 0.322   -1.50e-2 0.00502  \n3 TYPEDEMO1984Democraci…  7.00e-2   5.95e-2      1.18 0.246   -4.97e-2 0.190    \n4 GDP2006                 8.58e-6   2.70e-6      3.17 0.00261  3.14e-6 0.0000140\n\n\nThe coefficients for gini_2019 (p = 0.322) and TYPEDEMO1984 (p = 0.246) are statistically insignificant. Is that because of too much multicollinearity? We can again rely on the car package to answer this question via its vif() function.\n\nvif(model_multiple)\n\n   gini_2019 TYPEDEMO1984      GDP2006 \n    1.811074     1.171946     2.039059 \n\n\n\nvif(multiple)\n\nUses the vif function on a model specified in brackets.\n\n\nThe output provides the VIF statistics underneath each variable name. No statistic is above 5, which indicates that we do not have a problem with excessive multicollinearity.\n\n\n\n\n\n\nWarning!\n\n\n\nThe output of this command will look different if you have a categorical variable in the model, as in this example:\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006 = factorize(Typeregime2006))\n\nvif_example &lt;- lm(v2x_polyarchy ~ gini_2019 + GDP2006 + Typeregime2006, data = demdata) \n\nvif(vif_example)\n\n                   GVIF Df GVIF^(1/(2*Df))\ngini_2019      1.385354  1        1.177011\nGDP2006        1.448928  1        1.203714\nTyperegime2006 1.346530  2        1.077219\n\n\nvif() reports versions of the VIF statistic called GVIF and GVIF^(1/(2*DF)) that adjust for the fact the categorical variable has multiple coefficients and hence degrees of freedom. You can assess multicollinearity in these instances by squaring the GVIF^(1/(2*DF)) and using the same rules of thumb as for VIF. In essence, we are looking for whether this statistic is around 2.23 or larger. We do not have a problem in this example.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#linearity-and-additivity",
    "href": "linear_07.html#linearity-and-additivity",
    "title": "7  OLS Assumptions",
    "section": "7.3 Linearity and additivity",
    "text": "7.3 Linearity and additivity\nA linear regression model relies on the assumption that the relationship between the predictors and the dependent variable can be captured in a linear equation. To check this we can investigate a plot of the model’s residuals against the model’s fitted (predicted) values via the resid_panel() command from the ggResidpanel package.\nWe first check whether a simplified polyarchy model with only economic inequality (gini_2019) as a predictor violates the linearity and additivity assumption.\n\nbivar_model &lt;- lm(v2x_polyarchy ~ gini_2019, data=demdata)\n\nresid_panel(bivar_model, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nIdeally, the dots will look randomly distributed rather than showing some type of non-linear pattern. The results above do not suggest a violation of this assumption.\n\n7.3.1 Logged relationships\nWe do not always get a residual plot with just random dots. Let us take a look at the plot for the more extended model of polyarchy (model_multiple).\n\nresid_panel(model_multiple, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nThe residuals plot suggests a non-linear relationship. However, it cannot tell us which independent variable in the model might be at fault. We can investigate this question via the avPlots() function from the car package.\n\navPlots(model_multiple)\n\n\n\n\n\n\n\n\nEach plot is a partial regression plot or “added-variable plot”. It shows the relationship between a given IV and the DV that is “residual” of the other predictors (i.e., the relationship between the IV in the sub-plot and the DV after accounting for the relationship between the other predictors in the model and these variables).\nWe are only interested in partial regression plots for continuous predictors. We can thus ignore the plot for TYPEDEMO1984.\nTurning to the GDP2006 predictor, we find a steep regression line (the coefficient was significant), but the dots are not evenly distributed around the line. In contrast, it looks like the relationship could be better described as a degressive curve rather than as a linear relationship.\nWe can account for this by transforming GDP2006 using the natural logarithm, including that variable in our model rather than the original GDP2006 variable, and then re-checking our diagnostic plots. We can use the log() function to take the natural logarithm of GDP2006.\n\ndemdata &lt;- demdata |&gt;\n  mutate(LNGDP2006 = log(GDP2006))\n\nHere, we re-run the model and re-check our diagnostic plots. The plots look better than before.\n\n#Re-running the model \nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006, \n               data=demdata)\n\n#Residual Plot\nresid_panel(multiple_ln, plots = c(\"resid\"))\n\n\n\n\n\n\n\n#Partial Regression Plot\navPlots(multiple_ln)\n\n\n\n\n\n\n\n\n\n\n7.3.2 Quadratic relationships\nAnother non-linear relationship we may encounter is the quadratic or curvilinear one. Our example draws on the ‘more violence in the middle’ theory which holds that there is a quadratic relationship between political violence and democracy scores such that violence will be more prevalent at intermediate levels of democracy.\nOur measure for political violence and instability is pve, which is drawn from the 2021 World Governance Indicators. Higher values on this variable mean less violence. Our predictor variable is the now familiar electoral democracy measure from the Varieties of Democracy Project, v2x_polyarchy.\nIt is generally a wise idea to visually examine the relationship between two variables before progressing to a statistical model. We do so here via a scatterplot:\n\nggplot(demdata, aes(x = v2x_polyarchy, y = pve)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(title = \"Political violence and regime type\", \n       x = \"Electoral democracy (2020)\", \n       y = \"Absence of political violence and instability (2021)\")\n\n\n\n\n\n\n\n\nThe syntax for this plot is similar to what we have seen before for producing a scatterplot (Section 1.2), but with one important difference:\n\ngeom_smooth(method = \"loess\")\n\nWe ask R to plot a “smoothed” line to our data to summarize the relationship between the two variables. The information within the parenthesis (method =) indicates what type of line we want. We have previously used method = \"lm\" to produce a linear regression line. Here, we use method = \"loess\". Loess stands for ‘locally estimated scatterplot smoothing’. Basically, this type of smoothed line follows the data as much as possible thereby enabling a non-linear relationship to be plotted, whereas “lm” makes the assumption that the relationship is linear in nature. The loess method is the default, so if nothing is specified for the method between brackets the loess line will be drawn, i.e. when just writing geom_smooth().\n\n\nThere appears to be some support for a curvillinear, rather than linear, relationship between the two variables. We’ll begin with a linear model:\n\n#Run the model\nViolence_linmodel &lt;- lm(pve ~ v2x_polyarchy, data = demdata)\n\n#Summarize it\ntidy(Violence_linmodel, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term          estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      -1.34     0.135     -9.90 2.36e-18    -1.60     -1.07\n2 v2x_polyarchy     2.19     0.233      9.38 5.75e-17     1.73      2.65\n\n\nThe non-linear nature of the relationship may show up in the residual plot, though this is not obviously the case here:\n\nresid_panel(Violence_linmodel, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nWe can check whether a quadratic relationship is a better fit for the data by adding a quadratic term to our regression model. We first create the quadratic term via mutate() and then add it to the equation alongside the non-squared version of the variable:\n\n#Create the squared term\ndemdata &lt;- demdata |&gt; \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n#Update the model\nViolence_sqmodel &lt;- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n               data=demdata)\n\ntidy(Violence_sqmodel, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -0.589     0.243     -2.42 0.0165      -1.07    -0.109\n2 v2x_polyarchy      -1.73      1.10      -1.58 0.117       -3.90     0.438\n3 v2x_polyarchy_sq    3.83      1.05       3.64 0.000361     1.75     5.90 \n\n\nThe quadratic term is statistically significant (p &lt; 0.001). This indicates that the relationship between v2x_polyarchy and pve is better modeled as non-linear in nature.\nWe can then inspect the residual plot again to re-check our assumptions (see example below).",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#homoskedasticity",
    "href": "linear_07.html#homoskedasticity",
    "title": "7  OLS Assumptions",
    "section": "7.4 Homoskedasticity",
    "text": "7.4 Homoskedasticity\nWe can inspect the residuals vs. fitted values plot again to investigate the assumption of homoskedasticity as well as the assumption of linearity. Here, for instance, is the residuals plot for the quadratic model of political violence that we just fit (Violence_sqmodel):\n\nresid_panel(Violence_sqmodel, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nWe are again looking for a random pattern of dots (homoskedasticity) rather than some type of funnel shape (heteroskedasticity). A funnel shape appears in the plot above, indicating that this assumption is being violated.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#normally-distributed-errors",
    "href": "linear_07.html#normally-distributed-errors",
    "title": "7  OLS Assumptions",
    "section": "7.5 Normally distributed errors",
    "text": "7.5 Normally distributed errors\nWe investigate whether the assumption of normally distributed errors holds by means of two plots from the ggResidpanel package: a histogram and a normal quantile (qq) plot of the model’s residuals.\nThis example checks the assumption of normality for the multiple linear regression model predicting democracy scores with the logged version of GDP included as a predictor variable:\n\nresid_panel(multiple_ln, plots = c(\"hist\", \"qq\"))\n\n\n\n\n\n\n\n\n\nplots = c(\"hist\", \"qq\"))\n\nWe ask for the histogram and qq-plot.\n\n\nNote that we can also add our residuals vs fitted (“resid”) plot in the same code if we want to inspect multiple assumptions quickly. For instance:\n\nresid_panel(multiple_ln, plots = c(\"resid\", \"hist\", \"qq\"))",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_07.html#limited-impact-of-outliers-and-influential-cases",
    "href": "linear_07.html#limited-impact-of-outliers-and-influential-cases",
    "title": "7  OLS Assumptions",
    "section": "7.6 Limited impact of outliers and influential cases",
    "text": "7.6 Limited impact of outliers and influential cases\nWe will use the augment() function from the broom package to investigate whether outliers and influential cases are impacting our results.\nOur example will use the multiple_ln model from earlier wherein we predicted a country’s democracy score based on its level of inequality, prior regime status, and a logged version of GDP.\n\n#Run the command and store results\ndemdata_multln &lt;- augment(multiple_ln)\n\n\ndemdata_multln &lt;-augment(multiple_ln)\n\nThe augment function is used on the model specified in brackets, and the results are saved to a new data object (demdata_multln).\n\n\nHere is what the contents of the data object look like:\n\ndemdata_multln\n\n# A tibble: 53 × 11\n   .rownames v2x_polyarchy gini_2019 TYPEDEMO1984 LNGDP2006 .fitted   .resid\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;            &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 3                 0.908      26.5 Democracies      10.3    0.857  0.0514 \n 2 4                 0.894      30.1 Democracies      10.5    0.881  0.0129 \n 3 10                0.485      37.5 Autocracies       7.38   0.480  0.00510\n 4 13                0.652      48   Democracies       7.75   0.559  0.0925 \n 5 14                0.632      29.3 Autocracies       8.62   0.625  0.00694\n 6 15                0.678      47.6 Democracies       8.31   0.632  0.0464 \n 7 16                0.807      38.7 Democracies      10.5    0.906 -0.0995 \n 8 17                0.882      32.1 Democracies       9.32   0.733  0.149  \n 9 18                0.577      37.3 Democracies       7.68   0.530  0.0466 \n10 20                0.327      40.7 Democracies       6.99   0.447 -0.120  \n# ℹ 43 more rows\n# ℹ 4 more variables: .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\naugment() produces a dataframe with all of the observations used in fitting our model and with the following columns:\n\n.rownames: This provides the row number of the observation in our original dataset\nv2x_polyarchy through LNGDP2006: These are the variables in our model and the value each observation has on the variable. Of course, these columns will take on the names of the variables in your own models when you run them.\n.fitted: “Fitted” estimates from the model. In other words, the value of the dependent variable the model predicts the observation should take on based on its characteristics and the model parameters.\nresid: The residual for each observation, where Residual = Observed - Fitted/Predicted. Here: Residual = v2x_polyarchy - .fitted\n.hat: Diagonal of the hat matrix; this can be ignored.\n.sigma: Estimated residual standard deviation when the observation is dropped from the model; this can be ignored.\n.cooksd: The Cook’s distance statistic for the observation. See below.\n.std.resid: Not shown in the displayed output. This column contains the standardized residuals from the model. See below.\n\n\n\nWe use the standardized residuals (.std.resid) data to look for the presence of “too many outliers” and the Cook’s D values (.cooksd) to examine whether there are any “influential cases”.\n\n7.6.1 Investigating outliers\nWe first investigate the summary statistics of the standardized residuals (saved in the demdata_multln dataset) . Specifically, we look at the minimum and maximum values to see any observations cross the different outlier thresholds that we are interested in (|1.96|, |2.54|, and especially |3.29|).\n\nsummary(demdata_multln$.std.resid)\n\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-3.1281471 -0.2252984  0.2109869 -0.0007828  0.5831831  1.7394397 \n\n\nWe do see some potentially concerning values in the output above. There is at least one value where the absolute value of the standardized residual is greater than 2.58, which we can see from the fact that the minimum value is -3.128. However, this is not necessarily a problem. We must now investigate how many observations cross our threshold values of |1.96| (at least one given the output above), |2.58| (again, at least one), or |3.29| (none based on the above output).\nWe can do this by creating 3 new dummy variables in the dataset we created using augment(): SRE1.96, SRE2.58, SRE3.29. The dummy variables take on the value of ‘1’ if the standardized residual for an observation is higher than the specified threshold value. Otherwise, the variable takes on the value of ‘0’. We use the case_when() function (from dplyr) to do this coding; see Statistics I, 5.1 for a refresher on how this command works.\nThe code below can remain largely unaltered in your own syntax with only the name of the dataset (here: demdata_multln) needing to be altered.\n\ndemdata_multln &lt;- demdata_multln |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n         SRE2.58 = case_when(\n    .std.resid &gt; 2.58 | .std.resid &lt; -2.58  ~ 1,\n    .std.resid &gt; -2.58 & .std.resid &lt; 2.58 ~ 0),\n        SRE3.29 = case_when(\n    .std.resid &gt; 3.29 | .std.resid &lt; -3.29  ~ 1,\n    .std.resid &gt; -3.29 & .std.resid &lt; 3.29 ~ 0\n  ))\n\nHere is how to read the syntax:\n\ndemdata_multln &lt;- demdata_multln |&gt;\n\nThe new variables we create will draw on the demdata_multln dataset (for the .std.resid variable), while the new dummy variables will also be stored in this dataset.\n\nmutate(SRE1.96 = case_when(\n\nWe create a new variable named SRE1.96. The values for this variable will be specified through the case_when function.\n\n.std.resid &gt; 1.96 | .std.resid &lt; -1.96 ~ 1,\n\nHere we specify that when values for .std.resid are higher than 1.96 or (or is signified by the | line) lower than -1.96, our SRE1.96 variable will take on (~) the value of 1. Note that we have to specify the .std.resid variable twice.\n\n.std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n\nHere we specify that when values for .std.resid are higher than -1.96 and (and is signified by the &) lower than 1.96, our SRE1.96 variable will take on (~) the value of 0. We then repeat these steps for the other two thresholds.\n\n\nNow that we have created our threshold variables, we can inspect their frequency statistics. We use the fre() command from the expss package for the frequency tables.\nAgain, this code can remain largely unchanged, only the dataset name (here: demdata_multln) needs to be altered for own applications.\n\nfre(demdata_multln$SRE1.96)\n\n\n\n\n\ndemdata_multln$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n49\n92.5\n92.5\n92.5\n92.5\n\n\n 1 \n4\n7.5\n7.5\n7.5\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\n\nfre(demdata_multln$SRE2.58)\n\n\n\n\n\ndemdata_multln$SRE2.58\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n51\n96.2\n96.2\n96.2\n96.2\n\n\n 1 \n2\n3.8\n3.8\n3.8\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\n\nfre(demdata_multln$SRE3.29)\n\n\n\n\n\ndemdata_multln$SRE3.29\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n53\n100\n100\n100\n100\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0\n\n\n\n\n\n\n\n\nWe have more than 5% of cases with a standardized residual higher than 1.96 in absolute value, more than 1% higher than 2.58, and zero cases higher than 3.29 (we could already see this from the summary statistics above).\nTo investigate whether these outliers influence our results we conduct our linear regression again after filtering out cases with a standardized residual higher than 1.96 in absolute value. We can replace the SRE1.96 variable with the SRE2.58 and SRE3.29 variables to investigate the impact of alternative ways of excluding outliers.\n\nmultiple_ln1.96 &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n                      data = subset(demdata_multln, SRE1.96 == 0))\n\n\ndata = subset(demdata_multln, SRE1.96 == 0))\n\nWith this code we use the demdata_multln dataset created with augment, but subset it to only include cases for which the value for SRE1.96 is zero.\n\n\nWe could then compare the results from these models with those from the original model to check if the model’s coefficeints and standard errors have changed substantially. However, outliers should not be simply excluded in order to improve model fit. Outliers should only be removed from a model if there is a well-motivated theoretical reason for doing so.\n\n\n7.6.2 Investigating influential cases\nWe check whether there are any observations with high Cook’s D values in our dataset in order to see if there are any influential cases in our model. Our rules of thumb are:\n\nvalues above 1 are generally cause of concern;\nvalues higher than 0.5 should be investigated more closely as they can also pose risks;\nvalues that are substantially higher than others in the dataset also require further attention.\n\nWe can investigate the summary statistics for Cook’s D values first.\n\nsummary(demdata_multln$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000036 0.0007700 0.0035030 0.0292621 0.0162039 0.6608136 \n\n\nThe summary overviews shows that we do not have any observations with a value above 1, but that at least one observation in the model has a Cook’s D value much higher than the rest of the observations. The maximum value is 0.66 and this value is substantially higher than others in the data. The 3rd Quantile value is only 0.016, indicating that 75% of the values are lower than 0.016.\nWe can also investigate this graphically by creating a plot of Cook’s D values through the ggResidpanel package:\n\nresid_panel(multiple_ln, plots = c(\"cookd\"))\n\n\n\n\n\n\n\n\n\nplots = c(\"cookd\"))\n\nWe ask for a plot showing the Cook’s D values for the cases in the model on the y-axis, and the row number of the observation on the x-axis.\n\n\nThe plot shows there really is only one case that deviates strongly all the rest. Per the summary output, the Cook’s D value for this observation is 0.66.\nWe can check the results of a linear model without this case included. We run a new model filtering out the high Cook’s D value with the code below.\n\nmultiple_lncook &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n                      data = subset(demdata_multln, .cooksd &lt; 0.65))\n\n\ndata = subset(demdata_multln, .cooksd &lt; 0.65))\n\nWith this code we use the demdata_multln dataset created with augment, but subset it to only include cases for which the value for .cooksd is less than 0.65. Note that we choose the value 0.65 because we know that our 1 case has a value of 0.66, while others are far lower. In principle we could have chosen 0.66, 0.64 etc. as long as the number mathematically divides those observations we aim to exclude from those we aim to keep in. The exact threshold number will need to be adapted for own applications.\n\n\nWe could exclude both outliers and influential cases at the same time by using the ‘&’ sign in our subsetting statement:\n\nmultiple_ln_excl &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006,\n                       data = subset(demdata_multln,\n                                     SRE1.96 == 0 & .cooksd &lt; 0.65))\n\n\n\n7.6.3 Finding specific cases\nWhat we don’t know from the previous analyses is which cases were excluded exactly and what could explain why they stood out. To investigate this, we need to add the standardized residuals and Cook’s D values to the original dataset, where we also have the country name variable.\nWhen missing values are present augment cannot fit the standardized residuals and Cook’s distances to the original dataset. A solution for this is to subset our dataset to only include complete cases, run the regression model again, and then use augment to add the standardized residuals and Cook’s D values to the subsetted dataset.\n\n# create subset of data without NA values\ndemdata_complete &lt;- demdata |&gt;\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984, LNGDP2006))\n\n# run model with new complete cases dataset\nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + LNGDP2006, \n               data=demdata_complete)\n\n# use augment and add to dataset\ndemdata_complete &lt;-augment(multiple_ln, data=demdata_complete)\n\nNow we can inspect specific outliers with the following code:\n\ndemdata_complete |&gt; \n  filter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96) |&gt;\n  select(country_name, .std.resid)\n\n# A tibble: 4 × 2\n  country_name .std.resid\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Thailand          -2.17\n2 Venezuela         -2.68\n3 China             -2.53\n4 Singapore         -3.13\n\n\n\nfilter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96)\n\nhere we specifically want to find outliers, so we filter for cases with a standardized residual higher than 1.96 or lower than 1.96.\n\nselect(country_name.std.resid)\n\nHere we ask R to print the names of the countries that are outliers as well as their specific standardized residual statistics.\n\n\n\ndemdata_complete |&gt; \n  filter(.cooksd &gt; 0.65) |&gt;\n  select(country_name, .cooksd)\n\n# A tibble: 1 × 2\n  country_name .cooksd\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Singapore      0.661",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumptions</span>"
    ]
  },
  {
    "objectID": "linear_08.html",
    "href": "linear_08.html",
    "title": "8  Reporting and Presenting Results",
    "section": "",
    "text": "8.1 Scatterplots\nWe can provide a visual representation of the bivariate relationship between two continuous variables via a scatterplot. Here is an example:\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(x = \"Economic Inequality\", \n       y = \"Electoral Democracy\", \n       title = \"Economic Inequality and Electoral Democracy\")",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-report-scatterplots",
    "href": "linear_08.html#sec-report-scatterplots",
    "title": "8  Reporting and Presenting Results",
    "section": "",
    "text": "8.1.1 Reports\nHere are some general guidelines for describing scatterplots:\n\nDiscuss the observed relationship between the two variables (is there a positive relationship? a negative one?) and the apparent strength of this relationship. Use a correlation coefficient to flesh out these discussions as describing a relationship based on only a plot can be tricky and potentially misleading.\nIf there are any apparent outliers or extreme values, then make a note of them.\n\n\n\n8.1.2 Instructions\n\nProvide informative labels to your x-axis, y-axis, and a title\nOne typically adds a fitted linear regression line to the figure to aid in interpretation. This is controlled via method = \"lm\". This can be changed to method = \"loess\" to instead fit a locally estimated scatterplot smoothing line; this is useful for checking for non-linear patterns in the data. See Section 7.3.2\nBe mindful of the size of the text on your axes: text that is too small (or too large) may be hard to read. The quickest way to change the font size of the figure is by altering the theme of the figure, e.g., adding + theme_grey(14) or + theme_bw(18) to the syntax; the number in parentheses alters the font size for all labels. You can find a list of the built-in ggplot themes here while additional examples are available via the ggthemes package. One can also obtain more fine-grained control over text size (e.g., change just the title font or just the x-axis font) and other elements of figures, via theme(), but that goes beyond the scope of this book.\nThe plot above provides the bivariate linear regression line between the two variables. One could also annotate the figure with the specific parameters of this regression line (the values for the Intercept and the slope coefficient) by using geom_text(). For instance, one might add a + at the end of labs() and then add the following on the next line: geom_text(x = 40, y=0.1, label=\"Dem Score = 1.06 + (-0.012 * Inequality)\"). This would add the text found in the label= portion of the syntax at the coordinates specified by x= and y=. This process may involve some trial and error regarding the x and y-coordinates in order to create the best looking plot. There also exist some specialized R packages that include functions that will facilitate this process (such as this function from the ggpubr package) but their use is beyond the scope of this document.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#correlations",
    "href": "linear_08.html#correlations",
    "title": "8  Reporting and Presenting Results",
    "section": "8.2 Correlations",
    "text": "8.2 Correlations\nThe correlation that we will use for this example focuses on the relationship between a measure of a country’s level of economic inequality in the year 2019 (higher = more unequal; gini_2019) and the country’s level of electoral democracy (higher = more democratic; v2x_polyarchy).\n\ncor1 &lt;- cor.test(x = demdata$gini_2019, \n                 y = demdata$v2x_polyarchy, \n                 method = \"pearson\")\n\ncor1\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nSee Section 1.4 for guidelines on how to interpret correlation coefficients.\n\n8.2.1 Reports\nReports should include:\n\nA discussion of the direction of the relationship on offer (i.e., is it positive or negative) that draws on the coding of the variables in the correlation alongside the specific correlation observed in the analysis.\nA conclusion about the null hypothesis, i.e., statistical significance.\n\nReports are typically made at 95% (p &lt; 0.05), 99% (p &lt; 0.01), and 99.9% (p &lt; 0.001) levels1\nReport at the highest level that is justified by the p-value. For instance:\n\nIf p = 0.04, then p &lt; 0.05 (significant at 95% level)\nIf p = 0.004, then p &lt; 0.01 (significant at 99% level)\nIf p = 0.0000005, then p &lt; 0.001 (significant at 99.9% level)\n\nIt is not common to go above p &lt; 0.001 (e.g., we would typically not say that p &lt; 0.000001, just p &lt; 0.001). We do not write p &lt; 0.000.\n\nA reference to the substantive size of the relationship (see Section 1.4)\n\n\n\n\n\n\n\nReport\n\n\n\nHigher levels of economic inequality are associated with lower levels of electoral democracy (\\(r\\) = -0.35). This association is moderate in size and statistically significant (p \\(&lt;\\) 0.01).\n\n\n\n\n8.2.2 Presentation: Correlation Tables\nWhen we are only discussing two variables then we can simply describe their correlation in the text of our report as shown above. However, when we are writing papers that feature analyses with multiple continuous variables, then it is good practice to include a correlation table showing their inter-relationship either in the main body of the text or in an appendix. We can use the datasummary_correlation() command from the modelsummary package to do so. Here is an example using four variables:\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Elec. Democracy\" = v2x_polyarchy, \n         \"Econ Inequality\" = gini_2019, \n         \"Corruption\" = cpi, \n         \"GDP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relationship between Main Continuous Variables\")\n\n \n\n  \n    \n    \n    tinytable_gw46be6ok96qxr5z7ttl\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Relationship between Main Continuous Variables\n              \n                 \n                Elec. Democracy\n                Econ Inequality\n                Corruption\n                GDP\n              \n        \n        \n        \n                \n                  Elec. Democracy\n                  1   \n                  .   \n                  .  \n                  .\n                \n                \n                  Econ Inequality\n                  -.35\n                  1   \n                  .  \n                  .\n                \n                \n                  Corruption     \n                  .66 \n                  -.53\n                  1  \n                  .\n                \n                \n                  GDP            \n                  .40 \n                  -.52\n                  .79\n                  1\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nEach cell provides the correlation coefficient for a pair of variables. The correlation between Corruption and Economic inequality, for instance, is -0.53, while the correlation between GDP and Corruption is 0.79.\nNote: The title is presented at the bottom of the table in this document, but would print at the top when saving to a Word document (see below), which is the more conventional placement.\n\n\nHere is how to read the syntax above:\n\ndemdata |&gt; select(…)\n\nIn these first two lines of code, we specify which data object has the variables we are interested in (demdata) and then ask R to only select the variables we want to correlate with one another. If we did not have the second line then datasummary_correlation() would try and produce correlations between all of the variables in our dataset.\n\nrename(…)\n\nWe rename the variables we have selected in these lines. The information in parentheses to the left of the equals sign is the name we want the variable to take on after renaming. The information on the right of the equals sign is the variable’s original name. If we did not take this step, then the underlying variable names (gini_2019, etc.) would be used in the table thereby making it harder to understand.\n\ndatasummary_correlation(method = \"pearson\", title = \"...\")\n\nThis line of syntax performs the correlations and provides a nice title for the table. Much as earlier we can control what type of correlation is calculated (Pearson correlation: method = \"pearson\"; Spearman: method = \"spearman\").\n\n\nWe can save this table to a new file that we can open in Microsoft Word so that we can copy and paste it into reports written outside of R Markdown by adding a final line to our syntax (note: the table will not be displayed in R when you specify this option):\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Elec. Democracy\" = v2x_polyarchy, \n         \"Econ Inequality\" = gini_2019, \n         \"Corruption\" = cpi, \n         \"GDP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relationship between Main Continuous Variables\", \n                          output = \"correlation table example.docx\")\n\n\noutput = \"correlation table example.docx\"\n\nThis line controls the saving process. It tells the command that we want to save a new file; that we want it to be called “correlation_table” (we could, of course, name it something else); and that we want it to be a “.docx” file, the default file type for Microsoft Word. We could then open this file in Word and make further changes/edits, or copy and paste it into a report, as needed.2\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nThis command be act a bit temperamental in cases where you save a table to file, open it outside of R in Word (for instance), and then re-run the syntax in R to create the table again while the file is still open in Word. We recommend closing the file in Word before trying to update table output produced via R to avoid complications.\n\n\n\n8.2.2.1 Instructions\n\nWe typically provide the dependent variable first in this type of table. We can do this by having this variable be the first one named in the select() line of the syntax above.\nRename your variables to something easy to understand for your readers (i.e., do not use the variable names in your dataset in the table)\nProvide an informative title to your table to communicate its contents.\nIt is common to add asterisks to these types of tables to communicate statistical significance (e.g.,: *** = p &lt; 0.01, ** = p &lt; 0.01, * = p &lt; 0.05). Unfortunately there is (as of yet) no easy way to directly do this via the datasummary_correlation() command. One can add these symbols manually by first saving the table to a .docx (Word) file and adding them as needed.\nCorrelation (and regression) tables created using the modelsummary suite of commands can be further styled in a variety of ways; see this webpage for some of the possibilities, although these are beyond the scope of this book and not required for your assignments in Statistics II.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-reporting-linear-regression",
    "href": "linear_08.html#sec-reporting-linear-regression",
    "title": "8  Reporting and Presenting Results",
    "section": "8.3 Reporting Linear Regression",
    "text": "8.3 Reporting Linear Regression\nLinear regression (otherwise referred to as least squares or ordinary least squares [OLS] regression) models provide a way of modelling changes in the mean of a dependent variable as a linear function of one or more independent variables. We use example data from the demdata dataset and predict electoral democracy scores in the year 2020 based on economic inequality, the country’s regime status in the year 1984 (democracy or autocracy), and a categorical variable indicating the region of the world in which the country is situated (1 = Europe, 2 = Africa, 3 = Asia, 4 = Americas).\nHere is the example output in R; you would not include this output in your academic papers but would instead create a more formal table (see below) or coefficient plot.\n\n#Factorize categorical variables\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984), \n         region = factor(region, \n                    levels=c(2,3,1,4), #Ref group is listed first\n                    labels=c(\"Africa\", \"Asia\", \"Europe\", \"Americas\")))\n\n#Run and store the model\nexample_model &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n                    data=demdata)\n\n#Results\nsummary(example_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n    data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52522 -0.06736  0.03585  0.09521  0.37555 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)              0.899777   0.271068   3.319  0.00175 **\ngini_2019               -0.013400   0.005693  -2.354  0.02282 * \nTYPEDEMO1984Democracies  0.067402   0.061709   1.092  0.28028   \nregionAsia               0.040365   0.149003   0.271  0.78765   \nregionEurope             0.244037   0.157307   1.551  0.12753   \nregionAmericas           0.253473   0.150635   1.683  0.09907 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1893 on 47 degrees of freedom\n  (126 observations deleted due to missingness)\nMultiple R-squared:  0.4378,    Adjusted R-squared:  0.378 \nF-statistic:  7.32 on 5 and 47 DF,  p-value: 3.842e-05\n\n\nSee earlier chapters for interpretation guidelines (e.g,. Section 4.1).\n\n8.3.1 Reports\nThe correct report includes:\n\nA discussion of the direction of the relationship on offer (i.e., is the relationship between variables positive or negative?) and an interpretation of what this means drawing upon the coding of the variables in the equation.\n\nDiscussions of coefficients from multiple linear regression should indicate that these relationships occur holding the effect of the other variables in the model constant, e.g., “ceteris paribus”.\n\nA conclusion about the null hypothesis with reference to the p-value and/or confidence interval\n\nCoefficients with p-values greater than 0.05 are generally described as not statistically significant or not statistically significant at conventional levels. In such cases, one can indicate that the relationship is not statistically significant and note the p-value.\nReports of statistical significance are typically made at 95% (p &lt; 0.05), 99% (p &lt; 0.01), and 99.9% (p &lt; 0.001) levels.3 Report at the highest level that is justified by the p-value. For instance:\n\nIf p = 0.04, then p &lt; 0.05 (significant at 95% level)\nIf p = 0.004, then p &lt; 0.01 (significant at 99% level)\nIf p = 0.0000005, then p &lt; 0.001 (significant at 99.9% level)\nIt is not common to go above p &lt; 0.001 (e.g., we would typically not say that p &lt; 0.000001, just p &lt; 0.001). We do not write p &lt; 0.000.\n\nThe confidence interval can also be used to assess statistical significance and communicate the uncertainty surrounding regression estimates. If you include the CI in your discussion, then you can place it in parentheses after the coefficient: “The coefficient for economic inequality is -0.01 (95% CI: -0.02, -0.002)”.\nIt is not as common to directly reference the t-statistic in discussions of the statistical significance of regression coefficients, but it is not problematic to do so either. If doing so, then you should generally list it alongside the p-value: “(t = 1.98, p &lt; 0.05)”.\n\n\nHere are examples for gini_2019 (a continuous variable) and TYPEDEMO1984 (a binary variable)\n\n\n\n\n\n\nReport\n\n\n\ngini_2019: We expect the level of electoral democracy to decrease as economic inequality increases holding constant the effects of prior regime status and world region. Based on our model, we expect the level of electoral democracy to decrease by -0.01 scale points on average with each one unit increase in inequality. This association is statistically significant (p &lt; 0.05).\nTYPEDEMO1984: The results of the regression model show that countries recorded as democratic in 1984 are, on average, 0.07 scale points more democratic in 2020 than countries with equivalent levels of inequality and world region but recorded as an autocracy in 1984. This difference is not statistically significant at conventional levels (p = 0.28).\n\n\nAdditional notes for writing up results for formal papers:\n\nThe interpretation above focuses on just the coefficient and its interpretation. A stronger discussion in an academic paper would include a discussion about predicted values to help communicate the potential substantive importance of the relationship on offer. For instance, one could note the predicted value of electoral democracy when economic inequality is “high” vs. when it is “low” based on the model (where “high” and “low” are based on attributes of the variable under investigation). A plot of predicted values may further enrich these discussions. See Section 8.6 for further discussion.\nIf the goal of one’s model is to assess the relationship between a particular independent variable and the dependent variable while adjusting for potential confounding influences, then a discussion of the coefficients for “control” variables is generally not needed.\nDiscussions of regression results in academic papers seldom focus on the Intercept term. The most notable exceptions would be bivariate models where the predictor variable is scaled such that the the value of 0 refers to a particular category of relevance. For instance, if the predictor variable were a binary variable for whether some observations were randomly assigned to an experimental treatment condition (x = 1) or to a control group (x = 0), then the Intercept would tell us the mean of Y for those in the control group, which would be very useful to know!\nBe mindful of the use of “effect” language, e.g., the “effect of variable X”. This brings to mind causal effects (X causes Y), but causal inference requires some strong assumptions to be met. It is typically safest to discuss results as associations.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "href": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "title": "8  Reporting and Presenting Results",
    "section": "8.4 Presenting Linear Regression: Regression Tables",
    "text": "8.4 Presenting Linear Regression: Regression Tables\nThe most common way of reporting regression results in a paper is a regression table. One useful package for creating these tables is called modelsummary. Within this package is the aptly named function modelsummary(), which will create regression tables for us.\n\n8.4.1 Regression Tables with a Single Model\nAs a first example, we will create a regression table using the results from a model wherein electoral democracy in 2020 is regressed on just the level of corruption in the country “cpi”. Here is the default output of the command without specifying any other options:\n\n#Run and store the model\nmodel1 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata)\n\n#The basic command\nmodelsummary(model1)\n\n \n\n  \n    \n    \n    tinytable_fx0iwqxshytqtkde759s\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.140  \n                \n                \n                             \n                  (0.036)\n                \n                \n                  cpi        \n                  0.009  \n                \n                \n                             \n                  (0.001)\n                \n                \n                  Num.Obs.   \n                  174    \n                \n                \n                  R2         \n                  0.438  \n                \n                \n                  R2 Adj.    \n                  0.435  \n                \n                \n                  AIC        \n                  -78.1  \n                \n                \n                  BIC        \n                  -68.6  \n                \n                \n                  Log.Lik.   \n                  42.061 \n                \n                \n                  F          \n                  134.123\n                \n                \n                  RMSE       \n                  0.19   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nmodelsummary(\n\nThis is the name of the command\n\nmodel1\n\nThis is the name of the model that will be presented in the table.\n\n\nThis table can be improved. First, we should communicate something about the statistical significance of the coefficients, e.g., via asterisks or other symbols. Second, we should give more informative labels for our independent variables. Third, the default output shows a variety of model fit statistics that we are not interested in and which we will want to remove from the table. Finally, we should add information to the table such as a title describing its contents and a note at the bottom indicating what the values in the table represent.\nHere is the basic syntax that we will use to produce regression tables:\n\nmodelsummary(model1, \n1             stars = TRUE,\n2             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"cpi\" = \"Corruption Perception Index\"), \n3             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n4             title = \"Predicting Electoral Democracy with Level of Corruption\",\n5             notes = \"OLS coefficients with standard errors in parentheses\")\n\n\n1\n\nThis adds “stars” to signal statistical significance\n\n2\n\nWe rename our variables for better communication via coef_rename()\n\n3\n\nWe select which model fit statistics via gof_map()\n\n4\n\nWe can give a title to the table via title =\n\n5\n\nAnd, finally, provide some notes at the bottom of the table via notes =\n\n\n\n\n \n\n  \n    \n    \n    tinytable_rxhq74rr90lq468tx8nt\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Electoral Democracy with Level of Corruption\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses\n        \n                \n                  Intercept                  \n                  0.140***\n                \n                \n                                             \n                  (0.036) \n                \n                \n                  Corruption Perception Index\n                  0.009***\n                \n                \n                                             \n                  (0.001) \n                \n                \n                  Num.Obs.                   \n                  174     \n                \n                \n                  R2                         \n                  0.438   \n                \n                \n                  R2 Adj.                    \n                  0.435   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nstars = TRUE,\n\nThis adds symbols to communicate information about the statistical significance of a coefficient (e.g., the little stars or asterisks next to some of the coefficients). Information is automatically added to the bottom of the table about what each symbol means/represents. This portion of the command can remain the same when you create your own OLS/linear regression table.\n\ncoef_rename = c(...)\n\nThe modelsummary() command will use the name of the variable by default when creating a table. One way we change these labels is via the coef_rename() option. We begin by noting the name of the term we want renamed (e.g., cpi) and then, after the equals sign, what we want it to be labelled as in the final table (“Corruption Perception Index”). This latter information needs to be in quotation marks. We use double quotation marks here (“word”), but you can also use a single quotation mark (‘word’) - either works as long as you are consistent in your use.\n\ngof_map = c(...)\n\nThe modelsummary() command will show a number of “goodness of fit” statistics by default. For our purposes we wish to only show three of them: the number of observations in the model, the R2, and the Adjusted R2. There are a couple of ways of removing unwanted fit statistics from the table. In gof_map() we provide the names of the statistics we want to include and then the function will filter out everything that doesn’t match these labels.4 Here, we have the command include the number of observations (“nobs”), the R2 statistic (“r.squared”), and the adjusted R2 (“adj.r.squared”). This information can remain the same when you create your own OLS/linear regression table.\n\ntitle = ...\n\nThis specifies a title for the table. The title is presented on the bottom in the output of this document, but would print at the top of the table when exporting to Word (see below.)\n\nnotes = (...)\n\nThis specifies the contents of the notes at the bottom of the table. It is conventional to indicate what is being presented (e.g., “OLS coefficients”) and what the information underneath these values represents (e.g., “with standard errors…”).\n\n\n\n\n8.4.2 Regression Tables with Multiple Models\nWe can also use modelsummary() to produce regression tables that contain multiple models. For instance, we could show the results from the model with just “cpi” and then one additional predictor variables. In order to do this, we must first combine the different models into an R object called a “list” and then use the list in our modelsummary() command. Most of the options in the modelsummary() command can stay the same but the coef_rename() portion for renaming new variables and the title portion should be updated.\n\n#Our second model\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#Creating a list\nmodel_list &lt;- list(model1, model2)\n\n#Using the list in modelsummary()\nmodelsummary(model_list, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"cpi\" = \"Corruption Perception Index\", \n               \"v2caviol\" = \"Political Violence\",  \n               \"regionAsia\" = \"Asia\",\n               \"regionEurope\" = \"Europe\", \n               \"regionAmericas\" = \"Americas\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Predicting Electoral Democracy with Corruption, Political Violence, and Region\", \n             notes = \"OLS coefficients with standard errors in parentheses. Reference group for region = Africa\")\n\n \n\n  \n    \n    \n    tinytable_i58wiw96sl2tvmllo695\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Electoral Democracy with Corruption, Political Violence, and Region\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses. Reference group for region = Africa\n        \n                \n                  Intercept                  \n                  0.140***\n                  0.178***\n                \n                \n                                             \n                  (0.036) \n                  (0.038) \n                \n                \n                  Corruption Perception Index\n                  0.009***\n                  0.007***\n                \n                \n                                             \n                  (0.001) \n                  (0.001) \n                \n                \n                  Political Violence         \n                          \n                  -0.009  \n                \n                \n                                             \n                          \n                  (0.010) \n                \n                \n                  Asia                       \n                          \n                  -0.090**\n                \n                \n                                             \n                          \n                  (0.034) \n                \n                \n                  Europe                     \n                          \n                  0.108*  \n                \n                \n                                             \n                          \n                  (0.042) \n                \n                \n                  Americas                   \n                          \n                  0.145***\n                \n                \n                                             \n                          \n                  (0.041) \n                \n                \n                  Num.Obs.                   \n                  174     \n                  174     \n                \n                \n                  R2                         \n                  0.438   \n                  0.559   \n                \n                \n                  R2 Adj.                    \n                  0.435   \n                  0.546   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nThe default behavior here is to name the first model “Model 1” and the second one “Model 2”. This is typically fine. We we can also specify names for each column when we set combine the models into a list object if we so desired. This is most useful if the models differed in some fundamental way (e.g., the models predict different dependent variables and you need a way to signal that to consumers of your table).\n\n#A list with names\nmodel_list_named &lt;- list(\n  \"Just Corruption\" = model1, \n  \"Full Model\" = model2)\n\n#Create the table\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"cpi\" = \"Corruption Perception Index\", \n               \"v2caviol\" = \"Political Violence\",  \n               \"regionAsia\" = \"Asia\",\n               \"regionEurope\" = \"Europe\", \n               \"regionAmericas\" = \"Americas\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Predicting Electoral Democracy with Corruption, Political Violence, and Region\", \n             notes = \"OLS coefficients with standard errors in parentheses. Reference group for region = Africa\")\n\n \n\n  \n    \n    \n    tinytable_9gk3aojbj59outzuv4e1\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Electoral Democracy with Corruption, Political Violence, and Region\n              \n                 \n                Just Corruption\n                Full Model\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses. Reference group for region = Africa\n        \n                \n                  Intercept                  \n                  0.140***\n                  0.178***\n                \n                \n                                             \n                  (0.036) \n                  (0.038) \n                \n                \n                  Corruption Perception Index\n                  0.009***\n                  0.007***\n                \n                \n                                             \n                  (0.001) \n                  (0.001) \n                \n                \n                  Political Violence         \n                          \n                  -0.009  \n                \n                \n                                             \n                          \n                  (0.010) \n                \n                \n                  Asia                       \n                          \n                  -0.090**\n                \n                \n                                             \n                          \n                  (0.034) \n                \n                \n                  Europe                     \n                          \n                  0.108*  \n                \n                \n                                             \n                          \n                  (0.042) \n                \n                \n                  Americas                   \n                          \n                  0.145***\n                \n                \n                                             \n                          \n                  (0.041) \n                \n                \n                  Num.Obs.                   \n                  174     \n                  174     \n                \n                \n                  R2                         \n                  0.438   \n                  0.559   \n                \n                \n                  R2 Adj.                    \n                  0.435   \n                  0.546   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n8.4.3 Saving to File\nWhile it is becoming more common to use R Markdown to directly write academic papers, many people who use R will want to export results from R for use in a different word processor (e.g., Microsoft Word, Google Docs, etc.) where we can make further edits before adding the table to our reports/papers. We can do this by adding another line of syntax to our modelsummary() command wherein we tell the command to create an output file:\n\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"cpi\" = \"Corruption Perception Index\", \n               \"v2caviol\" = \"Political Violence\",  \n               \"regionAsia\" = \"Asia\",\n               \"regionEurope\" = \"Europe\", \n               \"regionAmericas\" = \"Americas\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Predicting Electoral Democracy with Corruption, Political Violence, and Region\", \n             notes = \"OLS coefficients with standard errors in parentheses. Reference group for region = Africa\", \n             output = \"example_regression_table.docx\") \n\n\noutput = \"example_regression_table.docx\"\n\nThis line controls the saving process. It tells the command that we want to save a new file; that we want it to be called “example_regression_table”; and that we want it to be a “.docx” file, the default file type for Microsoft Word. The file will be saved to our working directory unless we specify a different output location (e.g., “output/example_regression_table.docx”). We could then open this file in Word and copy and paste it into our report as needed. See the Warning above about saving and editing correlation tables as it also applies here.\n\n\n\n\n8.4.4 Instructions\n\nProvide an informative title, variable labels, and a note indicating what is being reported in the table.\nThe coefficients for categorical variables provide estimates of the difference in means between each included category and the omitted reference group (African countries in this example). You can indicate the identity of the reference category in one of three ways. First, you could provide this information in the notes section as shown in the examples above. Second, you can note the reference category in the variable label (e.g,. “Asia (reference group: Africa”). You would do this while renaming the variable (e.g., coef_rename('regionAsia' = 'Asia (ref group: Africa)'). Third, you can add a row to your table with this information. How to do this is described on the modelsummary webpage.\nIt is standard to provide the unstandardized coefficient with standard errors in parentheses underneath the coefficient. This is the default behavior of the modelsummary command. One can also provide the standard error in a column next to the coefficient (see this section of the modelsummary website for how), although this can be problematic if the table includes many models. The command will also generally round the coefficient and standard errors to 3 digits by default, which is generally what we want.\nThe modelsummary function will, by default, provide a numeric label for each model included in the table (e.g,. (1), (2), etc.). It can make sense to provide a specific title of your own in some circumstances. For instance, if one were creating a table with the results from multiple models that have the same IVs but different DVs, then one could use the name of the DV as the name for each column. See above.\nThe modelsummary webpage provides additional insight into how to further customize the appearance of these types of tables by, for instance, changing which table-making package modelsummary() uses when creating the table (see here for more).",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "title": "8  Reporting and Presenting Results",
    "section": "8.5 Presenting Linear Regression: Coefficient Plots",
    "text": "8.5 Presenting Linear Regression: Coefficient Plots\nRegression tables are the most common way of reporting the results of a regression in paper or report. A second way that the results of a regression model may be presented in formal papers and presentations is via a coefficient plot. A coefficient plot provides a graphical overview of the coefficients (with confidence intervals) for the independent variables in a model. The Intercept term is generally omitted from these types of plots.\nAs an example, let us plot the results from a model predicting electoral democracy with corruption, political violence, and regime status in 1984. We first run our model. We then use tidy() to create a data object that has the coefficients from our model and their associated 95% confidence interval.\n\n#Model\nplot_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\n#Store the model results as a tidied data object\n#NEED to ask for the confidence interval\nplot_model_tidied &lt;- tidy(plot_model, conf.int = TRUE)\n\n#here is what it looks like\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 cpi                     0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 v2caviol               -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 TYPEDEMO1984Democraci…  0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nThe tidy() command creates a data object that we can then use as input to a subsequent ggplot() figure. However, we should do some house cleaning first. In particular, we should recode the term variable so that we give informative labels to our variables and hence make the resulting figure easier to understand.5\n\n#recoding term to get nicer names to plot:\nplot_model_tidied &lt;- plot_model_tidied |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruption Perception Index\", \n                       \"v2caviol\" = \"Political Violence\",  \n                       \"TYPEDEMO1984Democracies\" = \"Democracy in 1984?\"))\n\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 Corruption Perception…  0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 Political Violence     -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 Democracy in 1984?      0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nWe then produce our plot:\n\nplot_model_tidied |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  ggplot(aes(x = estimate, y = term)) +  \n  geom_pointrange(aes(xmin = conf.low, \n                      xmax = conf.high)) + \n  labs(title = \"OLS Coefficients Predicting Level of Democracy (2020)\", \n       x = \"OLS Estimate\", \n       y = \"Predictor Variable\") + \n2  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n3  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nRemoves the intercept from our dataframe\n\n2\n\nAdds a vertical reference line at x = 0\n\n3\n\nAdds the (rounded) value of the coefficient estimate to the plot\n\n\n\n\n\n\n\n\n\n\n\n\nplot_model_tidied |&gt; filter(term != \"(Intercept)\") |&gt;\n\nThe first two lines tell R where our data is stored (plot_model_tidied) and then to filter out (remove) the row pertaining to the model’s Intercept term. The Intercept is typically not provided in a coefficient plot.\n\nggplot(aes(x = estimate, y = term)) +\n\nThis tells R that we wish to use the ggplot() function to create a figure and what data should be used for the x- and y-axes. term is a variable in our tidied dataframe that lists the name of the IVs in our model while estimate is the name of the column that contains the coefficient estimates. We could also flip this type of plot such that the estimate is on the y-axis and independent variables are on the x-axis (e.g., aes(x = term, y = estimate)). However, this may lead to a situation where the names of the variables overlap with one another in the figure thereby leading to a difficult to read plot. If we did do this, then we would want to change xmin and xmax in the next line of syntax to ymin and ymax and change geom_vline(xintercept = 0…) to geom_hline(xintercept = 0…) .\n\ngeom_pointrange(aes(xmin = conf.low, xmax = conf.high))\n\nThis portion see us ask for a specific type of plot. geom_pointrange produces a plot with a marker (“point”) surrounded by a line (“range”) as seen in the image above. The xmin and xmax entries tell R what the minimum and maximum values of this range should be.6 The “range” here are the endpoints of the 95% confidence interval around the coefficient. conf.low and conf.high are the names of the variables in the tidied dataset that contain information on the lower and upper bounds of the confidence interval for our coefficients.\n\nlabs(...)\n\nHere we provide informative labels for our plot.\n\ngeom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\")\n\nThis asks R to draw a vertical reference line (hence: “geom_vline”) at the point on the x-axis where x = 0. The inclusion of this line helps communicate whether a coefficient is statistically significant or not at the level of the confidence intervals.\n\ngeom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\nThis line enables us to plot the value of the regression coefficient next to the marker and can generally be kept the same in your examples. geom_text() indicates that we want to add text to our figure. We then specify what this text should be with label =. Here, we wish to show the regression slope, which is contained in a variable in our data named estimate. Moreover, we wish to show a rounded version of this estimate (e.g., -0.01 rather than -0.00872); “2” indicates how many decimals we want the estimate to be rounded by. The final portion is vjust = -0.5, which controls the placement of the label. “vjust” stands for vertical justification; we are telling R to nudge the label vertically along the y-axis so that it does not overlap with the marker. Negative values will nudge the label upwards, while positive values would nudge them downwards. In practice you may have to experiment a little with the specific numeric value to make sure there is enough, but not too much, space between it and the marker.\n\n\n\n\n\n\n\n\nTip 8.1: Warning!\n\n\n\nThe default behavior of ggplot is to order the coefficients by the alphabetical order of the variable that contains the variable names (named term when one is plotting the results of a data frame created using the tidy() function as above). This is often less than ideal as the different categories of a categorical variable may be separated from one another. In addition, we may want to call attention to a particular variable in the model which may be harder to do if it is placed in middle of the plot.\nHere is an example of this problem:\n\n#Model with categorical variable\ncat_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#Tidy and a simplified plot\ntidy(cat_model, conf.int = TRUE) |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruption\", \n                       \"v2caviol\" = \"Pol. Violence\", \n                       \"regionAsia\" = \"Asia\", \n                       \"regionEurope\" = \"Europe\", \n                       \"regionAmericas\" = \"Americas\")) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high))\n\n\n\n\n\n\n\n\nThe coefficients for the categorical variable have been separated from one another. We can avoid this issue by converting the term variable into a factor variable and specifying the order of its levels. This also enables us to skip the recoding portion of the syntax in the earlier examples since we are providing variable names in the levels = c() portion of the syntax.\n\ntidy(cat_model, conf.int = TRUE) |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  mutate(term = factor(term,\n                       levels = c(\"regionEurope\", \"regionAsia\", \n                                  \"regionAmericas\", \"v2caviol\",\n2                                  \"cpi\"),\n                       labels = c(\"Europe\", \"Asia\", \n                                  \"Americas\", \"Pol. Violence\",\n                                  \"Corruption\"))) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high))\n\n\n1\n\nConverting the term variable to a factor should be done after filtering out the Intercept, whether all in one go as in this example or in two separate steps.\n\n2\n\nggplot() will essentially plot upwards through the factor variable, so whatever category is listed first will be placed at the bottom of the plot. This can involve some trial and error to get right.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.1 Instructions\n\nIt is common to place the coefficient estimate on the x-axis and the variable names on the y-axis. One can reverse this (estimates on the y-axis, variable names on the x-axis) in some circumstances without a problem. However, this can lead to situations where the variable names overlap and become difficult to read. The formatting above avoids this type of issue (although very long labels can still be problematic). Other possible remedies to this type of problem are discussed in helpful blog post.\nPlotting the (rounded) coefficient value above or next to the marker helps readers place the coefficient on the axis and hence understand the results better.\n95% confidence intervals are the ones that are conventionally plotted.\nWhen you are placing a figure such as this in the text of a paper/report, then you should include a “Notes” section underneath the figure briefly explaining what is being presented. For instance: “Notes: Markers provide the OLS coefficient for each variable with 95% confidence intervals. See Table A1 for full results.”.\nProviding a reference line at 0 is good practice as this helps readers understand whether a coefficient is statistically significant (at least, at p &lt; 0.05).\nThe default behavior of ggplot is to order the coefficients by the alphabetical order of the variable that contains the variable names (named term when one is plotting the results of a data frame created using the tidy() function as above). This is often less than ideal as the different categories of a categorical variable may be separated from one another. In addition, we may want to call attention to a particular variable in the model which may be harder to do if it is placed in middle of the plot. We can avoid this issue by converting the term variable into a factor variable and specifying the order of its levels. See the example above in the Warning box above.\nGelman and Stern (2006) offers the now famous dictum that “the difference between ‘significant’ and ‘not significant’ is not itself statistically significant”. What this means in the context of a coefficient plot is to be careful in comparing coefficients against one another based on whether their confidence intervals overlap or not. The confidence intervals help you judge whether one can reject the null hypothesis that the coefficient for the variable in question = 0. If the confidence intervals between two coefficients do not overlap with one another, then the difference between those coefficients may also be statistically significant. However, two coefficients can be significantly different from one another even with overlapping confidence intervals.\n\n\nGelman, Andrew, and Hal Stern. 2006. “The Difference Between “Significant” and “Not Significant” Is Not Itself Statistically Significant.” The American Statistician 60 (4): 328331.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "title": "8  Reporting and Presenting Results",
    "section": "8.6 Presenting Linear Regression: Predicted Values Plots",
    "text": "8.6 Presenting Linear Regression: Predicted Values Plots\nRegression tables and coefficient plots communicate the coefficients for variables in a model: the expected average value of the DV when all predictors = 0 (Intercept term) or the expected change in the mean of Y given a one unit change in X (independent variable coefficients). We may use predicted values, and plots of those predicted values, to supplement discussions of these latter coefficients with an eye toward discussing the potential substantive importance of the relationship on offer.\nThe process for creating these types of images will be similar to the process for creating coefficient plots, but we will use the predictions() command as an intermediate step rather than tidy(). See Chapter 5 for background on the use of the predictions() command.\nWhat follows are examples for how to graphically portray predictions for a continuous predictor and for binary/categorical predictors.\n\n8.6.1 Continuous Predictor\nThis example will focus on the regression model named plot_model from above, which predicts democracy scores with corruption, political violence, and prior regime status. Let’s say our interest is in the corruption variable (cpi) and we want to show how our expectations about a country’s democracy level changes as we move from the lower to upper ends of the corruption variable’s scale. For instance, we might use the predictions() command to calculate predicted values from 20 to 80 on cpi in 10pt increments:\n\n#calculate the predictions\ncpi_preds &lt;- predictions(plot_model, \n                         newdata = datagrid(cpi = c(20, 30, 40, 50, 60, 70, 80)))\n\n#let's take a look\ncpi_preds\n\n\n cpi Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % v2caviol TYPEDEMO1984\n  20    0.318     0.0278 11.4   &lt;0.001  98.4 0.264  0.373   -0.394  Autocracies\n  30    0.382     0.0217 17.6   &lt;0.001 227.5 0.339  0.424   -0.394  Autocracies\n  40    0.445     0.0199 22.4   &lt;0.001 367.4 0.406  0.484   -0.394  Autocracies\n  50    0.509     0.0233 21.9   &lt;0.001 349.5 0.463  0.555   -0.394  Autocracies\n  60    0.573     0.0302 18.9   &lt;0.001 263.5 0.513  0.632   -0.394  Autocracies\n  70    0.636     0.0389 16.4   &lt;0.001 197.8 0.560  0.713   -0.394  Autocracies\n  80    0.700     0.0483 14.5   &lt;0.001 155.9 0.605  0.795   -0.394  Autocracies\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, v2caviol, TYPEDEMO1984, cpi, v2x_polyarchy \nType:  response \n\n\nWe can pass the data in this data object to a ggplot() command to produce a nice looking figure conveying these results.\n\n1ggplot(cpi_preds, aes(x = cpi, y = estimate)) +\n2       geom_line () +\n3       geom_ribbon(aes(ymin = conf.low, ymax = conf.high),\n                   alpha = 0.2) +  \n4       labs(title = \"Predicted Level of Electoral Democracy by Corruption Perception Index\",\n            x = \"CPI (Higher = Less Corrupt)\",    \n            y = \"Predicted Value\") +   \n5       scale_y_continuous(limits=c(0,1))\n\n\n1\n\nIndicates what data to use and plot\n\n2\n\nTells R to draw a line connecting each estimate\n\n3\n\nTells R to display the confidence intervals as a ribbon around the line and how dark the ribbon should be\n\n4\n\nAlways a good idea to give a title and nice labels for the axes\n\n5\n\nMakes sure the y-axis ranges from 0-1 (the theoretical range of our DV). Not always needed.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(\n\nThe name of the command for plotting data.\n\ncpi_preds, aes(x = cpi, y = estimate)) +\n\nThis tells the command where are data is located (in the object called cpi_preds) and what variables in that dataset we want to graph on the x- and y-axes respectively. We place the independent variable on the x-axis and the predicted values on the y-axis in this example.\n\ngeom_line() +\n\nThis indicates that we want to plot a line connecting these predicted values. The line will also fill in the spaces between each point. This is a common type of plot when the IV is continuous like this.\n\ngeom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n\nThis indicates how we want the confidence intervals around these predictions to be conveyed. geom_ribbon() asks for the confidence intervals to be drawn as a smooth “ribbon” around the predictions. The information in aes() tells R what variables in our dataset include information on the lower (ymin) and upper (ymax) boundaries of the confidence interval. Finally, alpha = 0.2 controls how darkly shaded the ribbon will be. The higher the value here the darker the ribbon and the more difficult it will be to see the line connecting these points.\n\nlabs(...)\n\nHere, we provide informative labels for our plot.\n\nscale_y_continuous(limits = c(0,1))\n\nThis sets the length of the y-axis so that it runs from the theoretical minimum (0) to maximum (1) of our dependent variable. We always want to avoid misleading the consumers of our graphics. The scaling of our axes is one culprit in bad or misleading graphics. Figures might exaggerate small differences, for instance, by restricting the scale of the y-axis to a very small range. Alternatively, one could make important changes disappear by extending the scale of the y-axis as well. See this webpage for some examples of both sins. We are trying to avoid these issues here by using the full range of the variable. Ultimately, these decisions are context dependent and should be done reflectively and in consultation with others.7\n\n\n\n\n8.6.2 Binary/Categorical Predictor Variable\nThe process for displaying predictions for binary and categorical variable variables is quite similar to the above. We first use predictions() to calculate predicted values for each level of the variable and then feed that output into ggplot().\nHere is an example focused on the prior regime status variable (TYPEDEMO1984) included in the plot_example model. We first use predictions() to obtain predicted values:\n\n#Obtain predicted values\ndemo_preds &lt;- predictions(plot_model, \n                          by = \"TYPEDEMO1984\", \n1                          newdata = \"mean\")\n\n#Let's take a look: \ndemo_preds\n\n\n1\n\nHolds the other covariates in the model constant at their mean or mode when making predictions\n\n\n\n\n\n TYPEDEMO1984 Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  cpi\n  Democracies    0.620     0.0260 23.8   &lt;0.001 413.9 0.569  0.671 43.4\n  Autocracies    0.467     0.0205 22.8   &lt;0.001 379.7 0.427  0.507 43.4\n v2caviol\n   -0.394\n   -0.394\n\nColumns: rowid, TYPEDEMO1984, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cpi, v2caviol, v2x_polyarchy \nType:  response \n\n\nWe would then pass this object, and the data inside it, to a ggplot() command. Here we use geom_pointrange() instead of geom_line() as we are trying to convey the difference between two categories rather than levels of a scale:\n\nggplot(demo_preds, aes(x = TYPEDEMO1984, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Predicted Level of Democracy by 1984 Regime Type\",\n       y = \"Predicted Value\", \n       x = \"Regime Type in 1984\") + \n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\n\n\n\nOne further bit of information we might want to add on figures like this is the actual value of the prediction. This can make it easier to read the graph in many (but not necessarily all) instances. For instance, we would not typically add the value of the predicted values to a prediction plot of a continuous predictor variable because there may be a larger number of predicted values making it difficult to read/interpret the plot.\nHere is how we would add the values of the predicted values to the plot:\n\nggplot(demo_preds, aes(x = TYPEDEMO1984, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Predicted Level of Democracy by 1984 Regime Type\",\n       y = \"Predicted Value\", \n       x = \"Regime Type in 1984\") + \n  scale_y_continuous(limits = c(0,1)) + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25)\n\n\n\n\n\n\n\n\n\ngeom_text(aes(label = round(estimate, 2)), hjust = -0.25)\n\nThis added line controls the display of the predicted value and can generally be kept the same in your examples. The only difference from the example above is that we now use “hjust” rather than “vjust” given the orientation of this figure (i.e., the estimates are provided on the y-axis rather than the x-axis and so we want to move to nudge the labels horizontally rather than vertically).\n\n\n\n\n8.6.3 Instructions\n\nWhich values should one input into the predictions() command and hence plot?\n\nIf the variable is binary/categorical, then you should focus on all of the (relevant) categories to the discussion at hand.\nIf the variable is continuous, then one can input the minimum and maximum of the variable with reasonable increments between them to produce a plot showing changes across the range of X. However, there is an important note on this front: If your data has missing values on one or more variables in the model, then the min and max of a variable in the model may not correspond to what you would find if you simply used the summary() function to summarize the variable’s distribution in the full dataset. This can be problematic if leads you to make predictions for values of a variable that are not observed in the model as these types of extrapolations may be uncertain and faulty. You can avoid this problem by creating a dataset that only includes observations in the model and then finding the min/max (and other intermediate values). This can be done, for instance, by using the predictions() command as shown in Section 5.3.1 .\n\nThe continuous variable example above plots the predicted values as a line with a ribbon showing the 95% confidence interval around the predictions. This is a conventional choice when one is plotting predictions for a continuous independent variable. If the independent variable is binary/categorical, then one would typically use something like geom_pointrange() or geom_errorbar().\nThe scale of the y-axis is something to consider when creating a plot such as this. The examples above uses scale_y_continuous() to make sure that the y-axis stretches from the min to the max value of the DV. This can help avoid situations where ggplot() shows only a truncated stretch of the y-axis thereby potentially giving a false impression of the magnitude of the change in Y across the range of X. This type of rescaling is not always needed, and can sometimes create its own problems, but it is something to reflect on before communicating statistical results. The sociologist Kieran Healy provides a further discussion of these competing considerations in his book on data visualization.",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "linear_08.html#footnotes",
    "href": "linear_08.html#footnotes",
    "title": "8  Reporting and Presenting Results",
    "section": "",
    "text": "Using a 90% significance test may be acceptable if the model has a small N.↩︎\nOne thing we might want to add to the table for a final research report are asterisks or “stars” that communicate the statistical significance of the correlations shown in the table. There is unfortunately no native way to do this in the R syntax for this command (although the website for the package does describe one method for doing so).↩︎\nUsing a 90% significance test may be acceptable if the model has a small N.↩︎\nThe alternative is gof_omit() where we provide the names of the statistic we want to, well, omit.↩︎\nWe might take other steps here as well before creating the figure. For instance, we could convert the term variable into a factor variable before making the plot in order to control the order in which variables are arranged on the figure.↩︎\nIf we put the coefficient estimates on the y-axis instead, then we would use “ymin” and “ymax” instead.↩︎\nThe sociologist Kieran Healy provides a good discussion of how and why to “look at data” via graphics in his book “Data Visualization”, which can be freely accessed via this link. See, in particular, Section 6 in Chapter 1, “Problems of honesty and good judgment”.↩︎",
    "crumbs": [
      "Linear Statistical Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Reporting and Presenting Results</span>"
    ]
  },
  {
    "objectID": "part_logistic.html",
    "href": "part_logistic.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "This section of the materials focuses on logistic models, which we use to predict binary dependent variables. You will learn how to…\n\nPerform such a model\nCalculate marginal effects, predicted probabilities, and odds ratios to interpret the model\nExamine the assumptions of these models",
    "crumbs": [
      "Logistic Regression"
    ]
  },
  {
    "objectID": "logit_01.html",
    "href": "logit_01.html",
    "title": "9  Logistic Regression & Odds Ratios",
    "section": "",
    "text": "9.1 Performing a Logistic Regression",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#performing-a-logistic-regression",
    "href": "logit_01.html#performing-a-logistic-regression",
    "title": "9  Logistic Regression & Odds Ratios",
    "section": "",
    "text": "9.1.1 Data Preparation\nOur example will investigate the relationship between self-reported gender (gndr) and voter turnout (i.e., did the person report voting in an election or not; vote). Our goal here is to predict whether a person reported voting in the most recent election.\nFirst, let us take a look at the variables so we can figure out if we need to take any preliminary data management steps:\n\n#Variable attributes\nESS9NL |&gt; \n  select(gndr, vote) |&gt; \n  view_df()\n\n\n\nData frame: select(ESS9NL, gndr, vote)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ngndr\nGender\n1\n2\n9\nMale\nFemale\nNo answer\n\n\n2\nvote\nVoted last national election\n1\n2\n3\n7\n8\n9\nYes\nNo\nNot eligible to vote\nRefusal\nDon't know\nNo answer\n\n\n\n\n\n#Tabulation\ntable(ESS9NL$gndr)\n\n\n  1   2 \n833 840 \n\ntable(ESS9NL$vote)\n\n\n   1    2    3 \n1291  247  130 \n\n\nOur predictor variable only has two categories, so we will need to factorize it before using it in the model. Our DV has three categories with observations in them (Yes, No, Not Eligible). We need to make this into a binary factor variable prior to analysis. We can do this by converting the “Not Eligible” category to NA. Here is one way that we can accomplish these ends:\n\n#Factorize variables\nESS9NL &lt;- ESS9NL |&gt;\n1  mutate(gndr = factorize(gndr),\n2         vote = factorize(vote))\n\n#Drop the not eligible category\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(vote = na_if(vote,\"Not eligible to vote\"))\n\n\n1\n\nThis will use the lowest numbered category as the “reference” or “baseline” category. In these examples, male respondents (gndr = 1) and those that say they voted in the last election (vote = 1).\n\n2\n\nWe are not creating a new variable when recoding things here (e.g., we overwrite the original gndr and vote variables). This is not usually a good idea - a mistake here would mean that we need to reload our data and walk our data cleaning steps in order to fix our mistake. It is generally a much better idea to create new variables when recoding/factorizing. We are not doing so out of pure hubris and tempting fate that we are not making a mistake here due to our surely flawless understanding of the data.\n\n\n\n\nLet’s check our work in regards to the vote variable:\n\nlevels(ESS9NL$vote)\n\n[1] \"Yes\"                  \"No\"                   \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\ntable(ESS9NL$vote)\n\n\n                 Yes                   No Not eligible to vote \n                1291                  247                    0 \n             Refusal           Don't know            No answer \n                   0                    0                    0 \n\n\nThe vote variable is now a factor variable where the the first (or base) level of the factor is “Yes” because factorize() will use the first numerical category as the reference group. This is a problem for us because we want to predict whether a person is in the “Yes, voted” category and the regression command we will use below predicts whether a person is in the higher level of a factor. In other words, if we leave this variable alone our model would predict whether a person did not vote. We thus need to relevel the variable to flip the order of the categories (see Section 2.1.1).1\n\n#Relevel the variable\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(vote = relevel(vote, \"No\"))\n\n#Let's check our work\nlevels(ESS9NL$vote)\n\n[1] \"No\"                   \"Yes\"                  \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\n\n\nmutate(vote = relevel(vote, \"No\"))\n\nWe use the relevel() command on the vote variable. We do not create a new variable here but overwrite the original one. You could also chose to make a new variable, which is usually a better idea when you are recoding/factorizing a variable. The category provided in quotation marks will become the reference category. It is important to note this variable was factorized first so we use the label “No” and not the numeric value for “No” originally stored in the dataset, which was 2.\n\n\nLet’s check our work for the gndr variable:\n\ntable(ESS9NL$gndr)\n\n\n     Male    Female No answer \n      833       840         0 \n\nlevels(ESS9NL$gndr)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\n\n“Male” has been used as the reference category. The two categories have a roughly equal number of observations, so the automatic behavior of factorize() is not an issue here. There is a third label here “No Answer” with 0 observations on it. This is fine for now - R will exclude this category from the analysis below.\nWe will change the reference group to “Female” as a further example of the relevel() syntax:\n\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(gndr = relevel(gndr, \"Female\"))\n\n#check your work!\nlevels(ESS9NL$gndr)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nThe DV in a logistic regression should be a (factorized) binary variable. Make sure you are creating the factor variable such that the higher level of the variable is the category you are trying to predict. Otherwise, your interpretations might end up being wrong by accident.\n\n\n\n\n9.1.2 Performing a Logistic Regression\nPerforming logistic regression in R is very similar to linear regression. However, instead of the lm() function, we rely on the glm() function, which stands for generalized linear model.\n\n#Run the model\nVote_model &lt;- glm(vote ~ gndr, \n                  data = ESS9NL, family = \"binomial\")\n\n\nVote_model &lt;-\n\nWe assign the results of our estimation to a new object.\n\nglm(vote ~ gndr,\n\nWe perform glm with vote as our dependent variable, predicted (~) by our only independent variable here: gndr. If we want to add more variables, we connect them with a ‘+’ sign.\n\ndata = ESS9NL,\n\nWe specify the dataset to be used.\n\nfamily = \"binomial\")\n\nWe specify the family for the generalized linear model. For logistic regression this is “binomial”. This part of the code remains unchanged. See the Common Errors appendix ( Section A.3) for an error that could arise if you did not specify the model’s family.\n\n\nLet’s take a look at the output using the built in summary() command:\n\nsummary(Vote_model)\n\n\nCall:\nglm(formula = vote ~ gndr, family = \"binomial\", data = ESS9NL)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.9539   0.5665   0.5665   0.6163   0.6163  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.56485    0.09535  16.412   &lt;2e-16 ***\ngndrMale     0.18359    0.13925   1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe structure of this output is highly similar to what we saw with the output of an lm() model.\n\nCall: The model being fit\nDeviance Residuals: This provides some summary data about the model’s residuals.\nCoefficients: This provides the coefficients from the model (Estimate) as well as the coefficient’s standard error (Std. Error), a test-statistic (z-value; the Z-Statistic as given by \\(\\frac{\\textrm{Coefficient}}{\\textrm{Std. Error}}\\)), and the p-value for the test statistic (Pr(&gt;|z|)). Symbols pertaining to statistical significance may be provided to the right of the p-value with a line indicating how to interpret these symbols provided at the bottom of the Coefficients output (“Signif. Codes:”).\n(Dispersion parameter…): This can be ignored.\nArea that begins with Null deviance: This area relates to the fit of the model, which will be discussed in a subsequent chapter.\nNumber of Fisher Scoring Iterations: This can be ignored.\n\n\n\nWe can add multiple predictors to the model in a way similar to the linear regression syntax, by adding them with a + symbol. Here add age (agea), trust in politicians (trstplt), and left-right ideology (lrscale). We did not need to take any data management steps with these variables because they are continuous variables and missing data is already coded as NA.\n\n#Run the model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                     data = ESS9NL, family = \"binomial\")\n\n#Check the output\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3923   0.4100   0.5029   0.5905   1.0239  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nLogistic regression coefficients are on the log of the odds scale. The coefficient for gndrMale in the vote_model_mp model tells us the difference in the log of the odds of voting between male and female respondents, while the agea coefficient tell us how the log of the odds of voting change with each one unit increase in respondent age.\nYou can use the direction (positive, negative) and statistical significance of a logistic regression coefficient to talk about the general relationship between the predictor variable and the DV. However, it is not really possible to directly and clearly communicate what a logistic coefficient tells us about the magnitude of the relationship between an IV and the DV because of this log of the odds scaling. You should instead focus on odds ratios (see below), average marginal effects (Chapter 10), or predicted probabilities (Chapter 11) to give more specific meaning to your discussion.\nIn this example:\n\nVoter turnout is more likely among men than women, but the difference is not statistically significant (p = 0.28) so we cannot rule out the possibility of no difference in voter turnout between the two groups.\nVoter turnout becomes more likely with age (i.e., older respondents are more likely to vote than younger ones) and this association is statistically significant (p &lt; 0.001).\nVoter turnout becomes more likely as trust in politicians increases and this relationship is statistically significant (p &lt; 0.001).\nVoter turnout grows more likely as we move from left to right on the ideology scale, but the effect is not statistically significant (p = 0.74) so we cannot rule out the possibility that a one unit change in ideology actually does not lead to any change in the chances of turning out to vote.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#odds-ratios",
    "href": "logit_01.html#odds-ratios",
    "title": "9  Logistic Regression & Odds Ratios",
    "section": "9.2 Odds Ratios",
    "text": "9.2 Odds Ratios\nOdds ratios are one way that we can translate logistic regression coefficients into something easier to interpret and communicate.\nWe can use the tidy() command from the broom package to toggle between output expressed in the log of the odds scale (our logistic coefficients from above) and odds ratios.\n\n#tidy with logistic regression and confidence intervals\ntidy(Vote_model_mp, conf.int = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -0.284    0.380      -0.747 0.455       -1.03       0.463 \n2 gndrMale      0.0433   0.154       0.281 0.779       -0.259      0.346 \n3 agea          0.0183   0.00450     4.07  0.0000461    0.00958    0.0272\n4 trstplt       0.195    0.0387      5.04  0.000000469  0.119      0.271 \n5 lrscale       0.0293   0.0393      0.744 0.457       -0.0480     0.106 \n\n#tidy with odds ratios and confidence intervals\ntidy(Vote_model_mp, conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    0.753   0.380      -0.747 0.455          0.357      1.59\n2 gndrMale       1.04    0.154       0.281 0.779          0.772      1.41\n3 agea           1.02    0.00450     4.07  0.0000461      1.01       1.03\n4 trstplt        1.22    0.0387      5.04  0.000000469    1.13       1.31\n5 lrscale        1.03    0.0393      0.744 0.457          0.953      1.11\n\n\nHere is how to read the syntax for the latter command:\n\ntidy(Vote_model_mp\n\nWe apply the tidy function on the model specified in brackets.\n\nconf.int = TRUE\n\nWe ask for the confidence intervals for the logistic regression coefficients or odds ratios. We can write ‘FALSE’ or leave out this statement if confidence intervals are not needed.\n\nexponentiate = TRUE)\n\nWe ask for the exponentiated logistic regression coefficients, which are the odds ratios. We can shorten this to exp = TRUE and obtain the same results. We can write ‘FALSE’ or leave out this statement if we want the logistic regression coefficients.\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThere are three important things to keep in mind when interpreting odds ratios.\nFirst, odds ratios tell us about the relative odds of seeing Y = 1 (e.g., seeing a person report turning out to vote). This is different than the coefficients from a logistic model which tell us about the log of those odds.\nSecond, we interpret odds ratios in relation to the number 1 rather than 0. Positive effects for X are seen when the odds ratio is greater than 1 (that is: an odds ratio &gt; 1 tells you that it becomes more likely to see Y = 1 when the independent variable increases by one unit). Negative effects for X are seen when the odds ratio is smaller than 1 (i.e., Y = 1 becomes less likely to be observed when X increases by one unit). A confidence interval for an odds ratio that includes 1 in its range (as occurs for gndrMale and lrscale above) indicates a statistically insignificant relationship, while an odds ratio that does not include 1 in its range (as occurs for agea and trstplt) indicates a statistically significant relationship.\nThird, we interpret odds ratios using multiplication language. For instance, our model indicates that the odds of voting are 1.04 times greater among male respondents than female respondents when holding the effects of age, ideology, and trust constant (although this difference is not statistically significant). Or: the odds of turning out to vote increase by 1.02 times for each one year increase in age (holding constant the other predictor variables).",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#footnotes",
    "href": "logit_01.html#footnotes",
    "title": "9  Logistic Regression & Odds Ratios",
    "section": "",
    "text": "We could alternatively use factor() and specify the order of the levels from the start. For instance, we could have done this: mutate(vote_binary = factor(vote, levels = c(2, 1), labels = c(\"Did not vote\", \"Voted\")) . This would also avoid an issue we discuss in the next chapter and in the Common Errors appendix.↩︎",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_02.html",
    "href": "logit_02.html",
    "title": "10  Marginal Effects",
    "section": "",
    "text": "10.1 Data Preparation, Example Model, and an Issue with factorize()\nWe will examine the same model that we ended last chapter on - one where we predicted whether a survey respondent said that they had voted in the most recent election based on their gender, age, trust in politicians, and ideology. Here are the data management steps we took last chapter to prepare our data for analysis as well as our model:\n#Data Preparation\nESS9NL &lt;- ESS9NL |&gt;\n  #Factorize our IVs\n1  mutate(gndr = factorize(gndr),\n         vote = factorize(vote))  |&gt; \n  #Remove Not Eligible to Vote Category from vote\n  mutate(vote = na_if(vote,\"Not eligible to vote\")) |&gt; \n  #Relevel our variables like we did last time\n  mutate(vote = relevel(vote, \"No\"), \n         gndr = relevel(gndr, \"Female\"))\n\n#Our model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Check the output\nsummary(Vote_model_mp)\n\n\n1\n\nWe could combine these three mutate() commands into one single mutate() command if we wanted, but we keep them separate here to more clearly lay out the steps that we are taking.\n\n\n\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3923   0.4100   0.5029   0.5905   1.0239  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\nWe need to take one additional step before calculating the marginal effects in this particular example due to a quirk in the factorize() command. Let us take a look at our gndr variable again:\nlevels(ESS9NL$gndr)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\ntable(ESS9NL$gndr)\n\n\n   Female      Male No answer \n      840       833         0\nThere are three labels/levels on the gndr variable: “Female”, “Male”, and “No Answer”. However, 0 respondents fall under the “No Answer” category. In situations like these, the command we will use below to obtain our marginal effects estimate will return an error because it thinks there is a third category (“No Answer”) in the model but finds zero observations in it.\nOne way we can preempt this error is by using the droplevels() command to remove the empty category from our gndr variable as shown below. Another way is to use factor() to create the factorized version of gndr. Section A.4 in the Common Errors Appendix for a more thorough discussion of this issue.\n#Drop levels: will drop any category with 0 observations associated with it\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(gndr = droplevels(gndr))\n\n#Let's take a look at our work\nlevels(ESS9NL$gndr)\n\n[1] \"Female\" \"Male\"  \n\ntable(ESS9NL$gndr)\n\n\nFemale   Male \n   840    833",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginal Effects</span>"
    ]
  },
  {
    "objectID": "logit_02.html#average-marginal-effects-ame",
    "href": "logit_02.html#average-marginal-effects-ame",
    "title": "10  Marginal Effects",
    "section": "10.2 Average Marginal Effects (AME)",
    "text": "10.2 Average Marginal Effects (AME)\nThe first type of marginal effect we’ll calculate is the Average Marginal Effect (AME) using the avg_slopes() command from the marginaleffects library. The AME shows us the average change in the probability that Y = 1 when a predictor increases by one unit. avg_slopes() does this by first calculating a predicted probability for each observation in the model based on the model’s coefficients and the observation’s unique combination of values on the predictor variables before averaging those predictions together and finding the difference. Here is an image that summarize this process (image from Heiss (2022)):\n\nHeiss, Andrew. 2022. “Marginalia: A Guide to Figuring Out What the Heck Marginal Effects, Marginal Slopes, Average Marginal Effects, Marginal Effects at the Mean, and All These Other Marginal Things Are.” May 20, 2022. https://doi.org/10.59350/40xaj-4e562.\n\n\n\nHow avg_slopes calculates the AME\n\n\nLet us take a look at the AMEs from our model:\n\n#Run the model and store the results\nAME &lt;- avg_slopes(Vote_model_mp,\n                  conf_level = 0.95)\n\nHere is how you can read this syntax:\n\nAME &lt;- avg_slopes(Vote_model_mp,\n\nPerforms the function avg_slopes on the specified model in brackets. Results are stored in a new data object (AME).\n\nconf_level = 0.95)\n\nThe default confidence level used is 95%, so this code could be left out if this is the desired confidence level. To use a different confidence level, the indicated value can be changed.\n\n\nHere are the results:\n\n1tibble(AME)\n\n\n1\n\nWe could just type AME rather than tibble(AME) here. The default output would look a little different (e.g,. it’d show “Estimate” rather than “estimate” and “2.5%” rather than “conf.low”). We use tibble() so you see the underlying dataset. See the Warning in Chapter 5.\n\n\n\n\n# A tibble: 4 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 agea  dY/dX     0.00220  0.000538     4.08  4.47e-5  14.4    0.00114   0.00325\n2 gndr  Male - …  0.00518  0.0185       0.281 7.79e-1   0.360 -0.0310    0.0414 \n3 lrsc… dY/dX     0.00350  0.00470      0.744 4.57e-1   1.13  -0.00572   0.0127 \n4 trst… dY/dX     0.0233   0.00460      5.07  3.92e-7  21.3    0.0143    0.0323 \n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nterm: This lists the variable name (e.g., agea, gndr, etc.).\ncontrast: This indicates the comparison being made. You may see two values: (1) “dY/dX”, which indicates that the variable is a continuous variable or (2) the specific categories being compared will be listed for factor variables (e.g., “Male - Female”)\nestimate: The AME\nstd.error through conf.high: Information about the uncertainty surrounding this estimate.\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe AME tells us the average change in the probability that Y = 1 when the predictor increases by one unit. The AME is natively reported on a 0-1 probability scale. We can discuss percentage point changes by multiplying the AME estimate by 100. For instance:\n\nThe probability of voting among male respondents is 0.5 percentage points greater, on average, than the probability of voting among female respondents\nThe probability of voting is expected to increase by 2.3 percentage points, on average, with each one unit increase on the trust in politicians measure (trstplt)",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginal Effects</span>"
    ]
  },
  {
    "objectID": "logit_02.html#marginal-effects-at-the-mean-mem",
    "href": "logit_02.html#marginal-effects-at-the-mean-mem",
    "title": "10  Marginal Effects",
    "section": "10.3 Marginal Effects at the Mean (MEM)",
    "text": "10.3 Marginal Effects at the Mean (MEM)\nWe recommend using the AME when discussing the marginal effects of variables in a logistic regression. However, it is also quite common to see researchers report what we might call the “marginal effect at the mean” or MEM. The main difference is that the MEM for a variable (lrscale, for instance) is calculated while holding the other variables in the model constant at their mean or mode. Here is an image summarizing how avg_slopes() calculates the MEM:\n\n\n\nHow avg_slopes calculates the MEM\n\n\nWe can calculate the MEM with a small change to our syntax;\n\nMEM &lt;- slopes(Vote_model_mp, \n              conf_level = 0.95,\n              newdata = datagrid()\n              )\n\n\nnewdata = datagrid()\n\nCreates a new dataset for our calculation with all variables held at their mean or mode (for categorical variables).\n\n\nLet’s take a look:\n\ntibble(MEM)\n\n# A tibble: 4 × 18\n  rowid term    contrast   estimate std.error statistic p.value s.value conf.low\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 agea    dY/dX       0.00210  0.000519     4.06  4.94e-5  14.3    0.00109\n2     1 gndr    Male - Fe…  0.00504  0.0180       0.281 7.79e-1   0.360 -0.0302 \n3     1 lrscale dY/dX       0.00336  0.00453      0.741 4.59e-1   1.12  -0.00552\n4     1 trstplt dY/dX       0.0224   0.00446      5.02  5.19e-7  20.9    0.0136 \n# ℹ 9 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;, gndr &lt;fct&gt;, agea &lt;dbl&gt;, trstplt &lt;dbl&gt;, lrscale &lt;dbl&gt;,\n#   vote &lt;fct&gt;\n\n\nThe output is very similar to what we saw above (e.g., term provides the variable name, estimate provides the marginal effect, etc.) although the MEM dataset also stores the mean and modal values of the predictors that were used when calculating the different MEM estimates.\n\nMEM |&gt; \n  select(gndr, agea, trstplt, lrscale) |&gt; \n  as_tibble()\n\n# A tibble: 4 × 4\n  gndr   agea trstplt lrscale\n  &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Male   50.7    5.34    5.15\n2 Male   50.7    5.34    5.15\n3 Male   50.7    5.34    5.15\n4 Male   50.7    5.34    5.15\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe interpretation of MEMs is very similar to the interpretation of the AME: they tell us how the probability that Y = 1 is expected to change given a one unit change in X. We can express this on a percentage point scale by multiplying by 100. However, we should make note that we held the control variables constant in our discussions. For instance: Male respondents were .2 percentage points more likely to vote, on average, than female respondents holding age, ideology, and trust in politicians constant at their means.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginal Effects</span>"
    ]
  },
  {
    "objectID": "logit_03.html",
    "href": "logit_03.html",
    "title": "11  Predicted Probabilities",
    "section": "",
    "text": "11.1 Predictions for Individual Observations\nOur logistic model makes a prediction for each observation in the model: what is the probability that the dependent variable = 1 (here: that people voted) based on the parameters of the model (the coefficients) and the observation’s combination of values on the independent variables. We can use the predictions() function to obtain these estimates.\n#Store the results as a new object\nVote_pred &lt;- predictions(Vote_model_mp,\n                         conf_level = 0.95, \n                         newdata = ESS9NL)\n\n#We can use tibble() to get a nice tabular overview\ntibble(Vote_pred)\n\n# A tibble: 1,673 × 578\n   rowid estimate   p.value s.value conf.low conf.high name    essround edition\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  \n 1     1    0.835  6.13e-35   114.     0.796     0.867 ESS9e03        9 3      \n 2     2    0.910  1.71e-56   185.     0.884     0.931 ESS9e03        9 3      \n 3     3    0.904  4.26e-45   147.     0.874     0.928 ESS9e03        9 3      \n 4     4   NA     NA           NA     NA        NA     ESS9e03        9 3      \n 5     5    0.864  9.71e-39   126.     0.828     0.894 ESS9e03        9 3      \n 6     6    0.912  7.81e-53   173.     0.884     0.933 ESS9e03        9 3      \n 7     7    0.800  1.32e-12    39.5    0.731     0.854 ESS9e03        9 3      \n 8     8    0.914  9.43e-31    99.7    0.877     0.941 ESS9e03        9 3      \n 9     9    0.877  1.88e-47   155.     0.845     0.903 ESS9e03        9 3      \n10    10    0.944  2.64e-39   128.     0.917     0.963 ESS9e03        9 3      \n# ℹ 1,663 more rows\n# ℹ 569 more variables: proddate &lt;chr&gt;, idno &lt;dbl&gt;, cntry &lt;chr&gt;, nwspol &lt;dbl&gt;,\n#   netusoft &lt;dbl&gt;, netustm &lt;dbl&gt;, ppltrst &lt;dbl&gt;, pplfair &lt;dbl&gt;, pplhlp &lt;dbl&gt;,\n#   polintr &lt;dbl&gt;, psppsgva &lt;dbl&gt;, actrolga &lt;dbl&gt;, psppipla &lt;dbl&gt;,\n#   cptppola &lt;dbl&gt;, trstprl &lt;dbl&gt;, trstlgl &lt;dbl&gt;, trstplc &lt;dbl&gt;, trstplt &lt;dbl&gt;,\n#   trstprt &lt;dbl&gt;, trstep &lt;dbl&gt;, trstun &lt;dbl&gt;, vote &lt;fct&gt;, prtvtcat &lt;dbl&gt;,\n#   prtvtdbe &lt;dbl&gt;, prtvtdbg &lt;dbl&gt;, prtvtgch &lt;dbl&gt;, prtvtbcy &lt;dbl&gt;, …\nHere is how to read this syntax:",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicted Probabilities</span>"
    ]
  },
  {
    "objectID": "logit_03.html#predictions-for-individual-observations",
    "href": "logit_03.html#predictions-for-individual-observations",
    "title": "11  Predicted Probabilities",
    "section": "",
    "text": "Vote_pred &lt;-\n\nStore results in a new data object. The results should always be saved to a new dataset, which we give a name of our choosing.\n\npredictions(Vote_model_mp,\n\nApply the function predictions on the model specified in brackets.\n\nconf_level = 0.95,\n\nThis is the default confidence interval. This can be safely omitted from the syntax if you want the 95% confidence interval. Alternatively, if you wanted to generate some other confidence interval (e.g., the 90% or 99%) then you would include this and change the numeric value (e.g., conf_level = 0.99).\n\nnewdata = ESS9NL)\n\nThe inclusion of this bit of syntax makes predictions() copy over all other variables from the original dataset. This part can thus be omitted from the syntax if including the other variables is not needed.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicted Probabilities</span>"
    ]
  },
  {
    "objectID": "logit_03.html#average-predicted-values-for-specific-ivs",
    "href": "logit_03.html#average-predicted-values-for-specific-ivs",
    "title": "11  Predicted Probabilities",
    "section": "11.2 Average Predicted Values for Specific IVs",
    "text": "11.2 Average Predicted Values for Specific IVs\nWe can also use the predictions() function to obtain the average probability that the dependent variable = 1 at specific values of an independent variable based on our model. For instance, we might want to see the expected probability of a person voting if they are 20 years old vs. if they are 60 years old to help communicate the meaning of our results. These types of predictions may then be presented in a figure of predicted probabilities as shown in Section 14.5 .\n\n11.2.1 Continuous Predictor Variable\nHere, we use predictions() to show us the predicted probability of voting based on the trust in politicians variable (trstplt). This variable is scaled from 0 to 10 in 1 point increments (missing value categories are shown here but coded as NA in our dataset):\n\nESS9NL |&gt; \n  select(trstplt) |&gt; \n  view_df()\n\n\n\nData frame: select(ESS9NL, trstplt)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ntrstplt\nTrust in politicians\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n77\n88\n99\nNo trust at all\n1\n2\n3\n4\n5\n6\n7\n8\n9\nComplete trust\nRefusal\nDon't know\nNo answer\n\n\n\n\n\ntable(ESS9NL$trstplt)\n\n\n  0   1   2   3   4   5   6   7   8   9  10 \n 43  41  68  90 173 292 457 375  87  16   8 \n\n\nWe will ask predictions() to calculate predicted values from 0 to 10 in 2pt increments in this example. An alternative would be to calculate probabilities for all increments of the variable, although this would produce an overload of output if the variable could take on many different values. An alternative in those scenarios would be use to the values at the minimum, 1st quartile, median, 3rd quartile, and maximum of the variable (with these values obtainable via the same process shown Section 5.3.1).\n\n#Store the predictions as a new object\nPred_conts &lt;- predictions(Vote_model_mp,\n                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2))) \n\n\nnewdata = datagrid(trstplt\n\nAll predictors in the model will be held at the mean/mode, except for those specified between brackets.\n\n= seq(from = 0, to = 10, by = 2)))\n\nWe ask for predictions at several values for a specific sequence (seq) of numbers: from defines the minimum, to the maximum, and by the increment. We could alternatively have written these numbers out (e.g., trstplt = c(0,2,4,6,8,10)) - this may be more or less labor for us depending on the scale of the variable.\n\n\nLet’s take a look at the predictions:\n\n1tibble(Pred_conts)\n\n\n1\n\ntibble() is used only to give you a glimpse of the underlying data that the command creates.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr   agea lrscale trstplt\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male   50.7    5.15       0\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male   50.7    5.15       2\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male   50.7    5.15       4\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male   50.7    5.15       6\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male   50.7    5.15       8\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male   50.7    5.15      10\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nThe layout of this output is the same as we saw when making predictions from a linear regression model (see Chapter 5):\n\nThe estimate column provides the predicted probability.\nThe p.value through conf.high columns provide uncertainty estimates.\nWe can then see columns for the other independent variables in the model (gndr, agea, lrscale) . These columns tell us the value that these variables have been held constant at when making predictions from the model. The predictions() command will automatically hold continuous variables constant at their mean, and factor variables at their mode, when newdata = datagrid() is used in the manner shown above.\nThe final two columns are trstplt, which shows the value of the trust in politicians measure used in making the prediction, and a column (not shown) for our DV (vote) that indicates which category is being predicted.\n\n\n\n\n\n11.2.2 Factor Predictor Variable\nThe code for categorical variables is slightly different as we use the by = statement. Here, we calculate the average predicted probability to vote for men and women, with all other predictors held at representative values (the mean for continuous or the mode for factor variables).\n\n#Obtain predictions and store as new object\nPred_cat &lt;- predictions(Vote_model_mp,\n                        by = \"gndr\", \n                        newdata = \"mean\") \n\n#Call the object in a nice tabular view\ntibble(Pred_cat)\n\n# A tibble: 2 × 11\n  rowid gndr  estimate  p.value s.value conf.low conf.high  agea trstplt lrscale\n  &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Fema…    0.863 1.35e-60    199.    0.835     0.887  50.7    5.34    5.15\n2     2 Male     0.868 1.44e-64    212.    0.841     0.891  50.7    5.34    5.15\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\n\nby = \"gndr\"\n\nThis tells the command that we want predicted values for each category of our factor variable.\n\nnewdata = \"mean\"\n\nThis tells the command that we want to hold the other variables in the model constant at their mean (if a continuous variable) or mode (if a factor variable). This must be specified here due to the use of the by = option.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicted Probabilities</span>"
    ]
  },
  {
    "objectID": "logit_03.html#predictions-for-specific-combinations-of-the-predictor-variables",
    "href": "logit_03.html#predictions-for-specific-combinations-of-the-predictor-variables",
    "title": "11  Predicted Probabilities",
    "section": "11.3 Predictions for specific combinations of the predictor variables",
    "text": "11.3 Predictions for specific combinations of the predictor variables\nFinally, we can estimate what the predicted probability would be for an observation with specific values for each of the predictors in the model.\nHere, we estimate the probability for a man (gndr), aged 33 (agea), with a score of 2 for trust in politicians (trstplt), and a score of 8 for left-right position (lrscale). To do so we need to specify the values for all variables between brackets after newdata = datagrid().\n\n#Calculate and store\nPred_specific &lt;- predictions(Vote_model_mp,\n1                             newdata = datagrid(gndr = c(\"Male\"),\n                                                agea = c(33),   \n                                                trstplt = c(2), \n                                                lrscale = c(8)))\n\nPred_specific\n\n\n1\n\nWe need to use parentheses with this variable because it is a (labelled) factor variable.\n\n\n\n\n\n gndr agea trstplt lrscale Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n Male   33       2       8    0.729   &lt;0.001 20.2 0.645  0.799\n\nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, gndr, agea, trstplt, lrscale, vote \nType:  invlink(link)",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicted Probabilities</span>"
    ]
  },
  {
    "objectID": "logit_04.html",
    "href": "logit_04.html",
    "title": "12  Model Fit and Comparisons",
    "section": "",
    "text": "12.1 Fit Statistics in summary()\nLet’s take another look at the model that we have been working with thus far, one wherein we predict whether a person reports voting based on their gender, age, ideology, and trust in politicians.\n#Data Preparation\nESS9NL &lt;- ESS9NL |&gt;\n  #Factorize our IVs\n  mutate(gndr = factorize(gndr), \n         vote = factorize(vote))  |&gt; \n  #Remove Not Eligible to Vote Category from vote\n  mutate(vote = na_if(vote, \"Not eligible to vote\")) |&gt;  \n  #Relevel our variables like we did last time\n  mutate(vote = relevel(vote, \"No\"), \n         gndr = relevel(gndr, \"Female\"))\n\n#Our model\nVote_model_mp &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Check the output\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote ~ gndr + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3923   0.4100   0.5029   0.5905   1.0239  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndrMale     0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit and Comparisons</span>"
    ]
  },
  {
    "objectID": "logit_04.html#fit-statistics-in-summary",
    "href": "logit_04.html#fit-statistics-in-summary",
    "title": "12  Model Fit and Comparisons",
    "section": "",
    "text": "Output Explanation\n\n\n\nMuch as with a linear model (lm), the summary() command will report some fit-related statistics at the bottom of its output after fitting a logistic model. Specifically, it will report the “Null” and “Residual Deviance” statistics. The Residual Deviance statistic indicates the difference (“deviance”) of the fitted model from a “perfect” model, i.e., one that perfectly fits the data. The Null Deviance statistic does the same but for a “Null” model, i.e., one that only includes an Intercept.\nSmaller Residual Deviance values would thus indicate “better” fitting models. However, we do not typically directly interpret the deviance statistic to make claims about model fit because it is on a difficult to interpret scale that has no theoretical maximum value. Instead, we will rely on other statistics and tests that make use of the deviance value as we show in sections below.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit and Comparisons</span>"
    ]
  },
  {
    "objectID": "logit_04.html#comparing-models-likelihood-ratio",
    "href": "logit_04.html#comparing-models-likelihood-ratio",
    "title": "12  Model Fit and Comparisons",
    "section": "12.2 Comparing Models: Likelihood Ratio",
    "text": "12.2 Comparing Models: Likelihood Ratio\nWe can use a likelihood ratio test to compare logistic regression models against one another. A likelihood ratio test will examine the ratio between the deviance statistics of two models and whether it indicates a statistically significant relationship (i.e., a difference in model fit) or not.\nIf we want to compare multiple logistic regression models with one another, then we must first ensure that observations are the same in all models much as we did when comparing linear regression models (see Section 6.2). We can do this by first creating a new data object with complete cases on all of the variables in our most elaborate model. For instance:\n\nESS9NL_glm &lt;- ESS9NL |&gt;\n  filter(complete.cases(vote, gndr, agea, trstplt, lrscale))\n\nWe next estimate our models. In this example, we will fit a series of models using our filtered dataset with each model containing one more variable than the one before. We will also fit a “null” model that does not contain any predictor variables. This is done by specifying the number 1 (a constant) on the right side of the tilde. We do this so that we have a baseline against which we can compare our first model.\n\n#Null model\nVote_model0 &lt;- glm(vote ~ 1,\n                   data = ESS9NL_glm, family = \"binomial\")\n# + gndr\nVote_model1 &lt;- glm(vote ~ gndr , \n                data = ESS9NL_glm, family = \"binomial\")\n# + agea\nVote_model2 &lt;- glm(vote ~ gndr + agea , \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + trst\nVote_model3 &lt;- glm(vote ~ gndr + agea + trstplt, \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + lrscale\nVote_model4 &lt;- glm(vote ~ gndr + agea + trstplt + lrscale, \n                data = ESS9NL_glm, family = \"binomial\")\n\nWe can now compare the fit of these models against one another using the test_likelihoodratio() command from the performance package. The test takes the ratio between the deviance statistics of two models and uses a Chi2 (\\(\\chi^2\\)) test to examine statistical significance. The null hypothesis of this test is that of zero difference in model fit between the models.\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model1,\n                     Vote_model2,\n                     Vote_model3,\n                     Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model1 |   glm |  2 |       1 |  0.11 |  0.744\nVote_model2 |   glm |  3 |       1 | 13.59 | &lt; .001\nVote_model3 |   glm |  4 |       1 | 24.38 | &lt; .001\nVote_model4 |   glm |  5 |       1 |  0.55 |  0.457\n\n\n\ntest_likelihoodratio(\n\nPerforms the likelihood ratio test for the models specified in brackets. At least 2 models need to be specified and the order matters for the comparison made (see below).\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\nHere is how to read this output:\n\nName: This provides the name of the model object\nModel: This provides the type of model; it can be ignored\ndf: This indicates how many terms are in the model. Vote_model0 has a df of 1 because only a single term is included in the model (the Intercept). Vote_model4 has a df of 5 because it has 5 terms (intercept + coefficients for each independent variable).\ndf_diff: This indicates the change in the number of terms between the model in the row and the preceding row. This equals 1 in our example because we have only added one term to each model.\nChi2 & p: This is the Chi2 test statistic and its associated p-value. This tests whether the fit of the model in that row is significantly different from the fit of the model in the preceding row. If statistically significant, then we would conclude that the more fully specified model (the one with more predictors) “fits better”.\n\n\n\nIn this example:\n\nModel 1 does not fit significantly better than the Null model (vote_model0)\nModel 2 fits significantly better than Model 1\nModel 3 fits significantly better than Model 2\nModel 4 does not fit significantly better than Model 3.\n\nWe might thus conclude that Model 3 (vote_model3) is the most parsimonious model (i.e., explains the most with the least number of predictors).\nMuch as with anova(), we could use this command to compare specific subsets of models:\n\n#Does Model 4 fit better than Model 1?: Yes!\ntest_likelihoodratio(Vote_model1, Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model1 |   glm |  2 |         |       |       \nVote_model4 |   glm |  5 |       3 | 38.53 | &lt; .001\n\n#Does Model 3 fit better than the Null model?: Yes!\ntest_likelihoodratio(Vote_model0, Vote_model3)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model3 |   glm |  4 |       3 | 38.08 | &lt; .001\n\n\n\n\n\n\n\n\nWarning!\n\n\n\nThe order in which we specify the models in our test_likelihoodratio() command matters much as it did when comparing model fit using an anova() with linear regressions ( Section 6.2). We will get an error if we include multiple nested models in the command in an incorrect order (where “correct order” means less complex model to more complex model):\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model4,\n                     Vote_model2,\n                     Vote_model1,\n                     Vote_model3)\n\nError: The models are not nested, which is a prerequisite for\n  `test_likelihoodratio()`.\n  See the 'Details' section.\n  You may try `test_vuong()` instead.\n\n\nIf we only include two models in command but specify them in reverse order (i.e,. more complicated model and then less complicated model), then we’ll get the same Chi2 and p-value, but the df_diff entry will simply take on the opposite sign (-3 rather than +3 in this example). That is not technically a problem, but you should specify models in the correct order to avoid potential errors in interpretation.\n\ntest_likelihoodratio(Vote_model4, Vote_model1)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model4 |   glm |  5 |         |       |       \nVote_model1 |   glm |  2 |      -3 | 38.53 | &lt; .001",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit and Comparisons</span>"
    ]
  },
  {
    "objectID": "logit_04.html#pseudo-r2",
    "href": "logit_04.html#pseudo-r2",
    "title": "12  Model Fit and Comparisons",
    "section": "12.3 Pseudo R2",
    "text": "12.3 Pseudo R2\nThe fit of a linear regression model is often interpreted in relation to its R2 value. The parameters of a logistic regression model are calculated in a different manner than those of a linear regression model. Consequently, there is no native R2 statistic for logistic regression. A variety of so-called or pseudo R2 statistics have been developed to provide an intuitive idea of how much explanatory power a logistic model has, however. The calculation of these values are based on the deviance statistic. Of these, we use the Nagelkerke R2. Its values lie between 0 and 1 with higher values indicating more explanatory power.\nWe can use the r2_nagelkerke() command from the performance library to obtain the Nagelkerke R2 statistic:\n\n# Nagelkerke R2: Model 3\nr2_nagelkerke(Vote_model3)\n\nNagelkerke's R2 \n     0.04698189 \n\n# Nagelkerke R2: Model 4\nr2_nagelkerke(Vote_model4)\n\nNagelkerke's R2 \n     0.04765513 \n\n\n\nr2_nagelkerke(\n\nEstimates the Nagelkerke R² for the model specified in brackets. Only one model can be specified.\n\n\nThe Nagelkerke R2 is higher for Model 4 than Model 3. However, we just saw that the likelihood ratio test comparing these models was statistically insignificant meaning that we cannot reject the possibility that the two models have equivalent fit. This is an example of why we need to use formal tests to compare models rather than relying on R2 statistics.\n\n\n\n\n\n\nWarning!\n\n\n\nThere are a variety of pseudo R2 statistics for interpreting logistic regression. However, none of them can be directly interpreted as telling us ’the proportion of variance explained by a model.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit and Comparisons</span>"
    ]
  },
  {
    "objectID": "logit_05.html",
    "href": "logit_05.html",
    "title": "13  Logistic Regression Assumptions",
    "section": "",
    "text": "13.1 No excessive multicollinearity\nWe can check for excessive multicollinearity using the vif() command from the car package, much as we did with linear regression models ( Section 7.2). The same interpretative rules of thumb are used here as well.\nvif(Vote_model4)\n\n    gndr     agea  trstplt  lrscale \n1.013505 1.018080 1.019284 1.013647\nThe statistics above indicate that we do not have a problem with excessive multicollinearity.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Logistic Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "logit_05.html#linearity-of-the-logit",
    "href": "logit_05.html#linearity-of-the-logit",
    "title": "13  Logistic Regression Assumptions",
    "section": "13.2 Linearity of the logit",
    "text": "13.2 Linearity of the logit\nLogistic regression models make the assumption that changes in the log of the odds (the logit) that Y = 1 are linear. We can examine this assumption using the augment() command from the broom package. This command will create a data object with the variables in our model as well as some important assumption-related statistics. Here is a preview:\n\naugment(Vote_model4)\n\n# A tibble: 1,425 × 11\n   vote  gndr    agea trstplt lrscale .fitted .resid    .hat .sigma   .cooksd\n   &lt;fct&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes   Female    32       6       5    1.62  0.601 0.00238  0.894 0.0000947\n 2 No    Male      57       7       5    2.32 -2.20  0.00175  0.893 0.00356  \n 3 Yes   Female    45       8       5    2.25  0.448 0.00220  0.894 0.0000467\n 4 Yes   Female    34       7       5    1.85  0.540 0.00237  0.894 0.0000749\n 5 Yes   Male      67       6       6    2.33  0.430 0.00188  0.894 0.0000365\n 6 No    Female    85       5       4    2.37 -2.22  0.00330  0.893 0.00710  \n 7 Yes   Female    40       7       5    1.96  0.513 0.00199  0.894 0.0000561\n 8 Yes   Male      71       8       7    2.83  0.339 0.00245  0.894 0.0000292\n 9 Yes   Female    84       5       5    2.38  0.421 0.00310  0.894 0.0000577\n10 Yes   Male      24       7       5    1.71  0.576 0.00360  0.894 0.000131 \n# ℹ 1,415 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput Explanation\n\n\n\n\nvote through lrscale: This is our raw data - the actual observed values for each respondent on our survey for the variables in our model. The names of these columns, and how many there are, would naturally be different in your examples.\n.fitted: These are the “fitted’ or predicted values for each observation based on the model on a logit scale (i.e., these are not predicted probabilities but predicted log of the odds).\n.resid: Residual values from our model. More specifically, these are known as “deviance residuals”.\n.hat: The diagonal of the hat matrix, which can be ignored.\n.sigma: The estimated residual standard deviation when an observation is dropped, which can also be ignored.\n.cooksd: Cook’s D values (see below).\n.std.resid: Standardized residuals (see below).\n\n\n\nLater on we will want to investigate potential outliers and influential cases. We will thus work with the output of this command:\n\nmodel4_augmented &lt;- augment(Vote_model4, data = ESS9NL_glm)\n\n\naugment(Vote_model4, data=ESS9NL_glm)\n\nWe have added data = ESS9NL_glm to this version of the command. This creates an object with all of the columns above as well as all of the other variables in the dataset used to fit the model (ESS9NL_glm). This is useful for investigating potential outliers and influential cases in more detail. However, it requires that the dataset in question does not contain observations not in the model (i.e., observations with missing values on one or more of the variables in the model). This is why we subset our ESS9NL dataset in an earlier code chunk.\n\n\nWe assess the linearity of the logit assumption by plotting the data created by augment(). Specifically, we create a scatterplot with a loess line where the y-axis is the .fitted column (the predicted logit for each observation) and the x-axis is a continuous independent variable. We do this for each continuous variable in the model. Note: We do not need to do this for factor predictor variables.\n\n# Age\nggplot(model4_augmented, aes(x = agea, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Trust in Politicians\nggplot(model4_augmented, aes(x = trstplt, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# LR Scale\nggplot(model4_augmented, aes(x = lrscale, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe are looking to see if the loess line shows a substantial deviation from linearity. There is no evidence of this in the figures above. We can thus say that this assumption is not violated.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Logistic Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "logit_05.html#limited-impact-of-outliers-and-influential-cases",
    "href": "logit_05.html#limited-impact-of-outliers-and-influential-cases",
    "title": "13  Logistic Regression Assumptions",
    "section": "13.3 Limited impact of outliers and influential cases",
    "text": "13.3 Limited impact of outliers and influential cases\nWe used the augment() function above to create a data object that contains standardized residuals and Cook’s distance statistics for our observations as well as other variables from our original dataset that were not included in our model. We can use this data to investigate this assumption. We will first look at outliers and then at influential cases.\n\n13.3.1 Outliers\nWe begin by looking at the summary statistics for the standardized residuals:\n\nsummary(model4_augmented$.std.resid)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-2.3983  0.4104  0.5040  0.1870  0.5916  1.0319 \n\n\nThis output can help us understand whether there are any observations that cross the thresholds we use to assess this assumption (|1.96|, |2.58|, |3.29|), although it does not tell us how many might do so. Here, we do not observe any observations crossing either of the two highest thresholds (|2.58|, |3.29|). However, we do see at least one observation with an absolute value greater than 1.96 (the minimum value of the standardized residual is -2.398).\nWe can assess how many observations cross this threshold by creating a dummy variable (0 = .std.resid &lt; |1.96|, 1 = .std.resid &gt; |1.96|) and inspecting a frequency table.1 Here is an example of how to do so - see Section 7.6.1 for syntax relating to the threshold values of 2.58 and 3.29.\n\n#Create the dummy variable: \nmodel4_augmented &lt;- model4_augmented |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0\n  ))\n\n#What percentage crosses the threshold? \nfre(model4_augmented$SRE1.96)\n\n\n\n\n\nmodel4_augmented$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n1344\n94.3\n94.3\n94.3\n94.3\n\n\n 1 \n81\n5.7\n5.7\n5.7\n100.0\n\n\n #Total \n1425\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\n\n\n5.7% of observations have a standardized residual greater than |1.96|. We could examine whether these observations are substantially impacting the parameters of our model by re-running the model and subsetting the data to only include observations with a value of 0 on the dummy variable we just created (SRE1.96). For instance:\n\n\nVote_model41.96 &lt;- glm(vote ~ gndr + agea + trstplt + lrscale,\n                       data = subset(model4_augmented, SRE1.96 == 0), \n                       family = \"binomial\")\n\n\n\n13.3.2 Influential cases\nWe examine the Cook’s D values in our augmented dataset in order to investigate whether there are any concerning influential cases.\nFirst, we can look at the summary of the Cook’s D values; see Section Section 7.6.2 for the rules of thumb we use when assessing these values. Second, we can visually inspect these values using the resid_panel() command from the ggResidpanel.\n\n#Summary of the Cook's D values\nsummary(model4_augmented$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n2.331e-05 5.117e-05 8.959e-05 7.085e-04 2.442e-04 1.668e-02 \n\n#Plot\nresid_panel(Vote_model4, plots = c(\"cookd\"))\n\nWarning in helper_plotly_label(model): NAs introduced by coercion\n\nWarning in helper_plotly_label(model): NAs introduced by coercion\n\n\n\n\n\n\n\n\n\nThe Cook’s D values are very small with a maximum value of around 0.017. There is little evidence that we have a problem here. If we did find higher values, then we could further examine them by, for instance, re-running our model with them filtered out. We could also examine the influential cases themselves to see if there is an explanation for why they are so influential.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Logistic Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "logit_05.html#footnotes",
    "href": "logit_05.html#footnotes",
    "title": "13  Logistic Regression Assumptions",
    "section": "",
    "text": "Calculating the mean of this 0/1 variable would accomplish the same end.↩︎",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Logistic Regression Assumptions</span>"
    ]
  },
  {
    "objectID": "logit_06.html",
    "href": "logit_06.html",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "",
    "text": "14.1 Reports\nA correct report for a logistic model includes:\nHere is an example for the gndr (binary factor) and trstplt (continuous) variables (AME and odds ratio estimates are calculated in previous chapters).\nAdditional notes for writing up results for formal papers:",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#reports",
    "href": "logit_06.html#reports",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "",
    "text": "A discussion of the direction of the relationship on offer (i.e.: is the relationship between the variables positive or negative?) and an interpretation of what this means drawing upon the coding of the variables in the equation.\nThe use of AMEs and predicted probabilities to communicate the substance of this relationship.\n\nFor formal papers: The discussion of a logistic model should be supplemented with references to AMEs and predicted probabilities to discuss the substantive relationship between the predictor and outcome variable.\n\nA conclusion about the null hypothesis with reference to the p-value and/or confidence interval\n\nReports are typically made at 95% (p &lt; 0.05), 99% (p &lt; 0.01), and 99.9% (p &lt; 0.001) levels.1 Coefficients with p-values greater than 0.05 are generally described as not statistically significant or not statistically significant at conventional levels.\nReport at the highest level that is justified by the p-value. For instance:\n\nIf p = 0.04, then p &lt; 0.05 (significant at 95% level)\nIf p = 0.004, then p &lt; 0.01 (significant at 99% level)\nIf p = 0.0000005, then p &lt; 0.001 (significant at 99.9% level)\n\nIt is not common to go above p &lt; 0.001 (e.g., we would typically not say that p &lt; 0.000001, just p &lt; 0.001). We do not write p &lt; 0.000.\nThe confidence interval can also be used to assess statistical significance and communicate the uncertainty surrounding regression estimates although this is more commonly done when reporting AME or odds ratio estimates than for logistic coefficients. If you include the CI in your discussion, then you can place it in parentheses after the coefficient: “The average marginal effect of age is 0.004 (95% CI: -0.006, 0.013)”.\n\n\n\n\n\n\n\n\n\nReport\n\n\n\ntrstplt: The chances that a person reports turning out to vote increase alongside their trust in politicians. The probability of turning out to vote is expected to increase by 2.3 percentage points, on average, for each one unit increase in trust. The relationship between trust in politicians and turnout is statistically significant (p &lt; 0.001).\ngndr (AME example): On average, the probability of turning out to vote is expected to be 4.3 percentage points higher among male than female respondents. However, this difference is not statistically significant (p = 0.78).\ngndr (Odds Ratio Example): The odds of turning out to vote among male respondents are 1.04 times greater than the odds among female respondents. However, this difference is not statistically significant (p = 0.78).\n\n\n\n\nThe interpretations above focus on just the coefficient and one of its potential transformations (AMEs or odds ratios). A stronger discussion in an academic paper would include a discussion about predicted probabilities to help communicate the potential substantive importance of the relationship on offer. For instance, one could note the predicted probability of a person with a “low” level of trust in politicians vs. one with a “high” level of trust (“high” vs. “low”, where “high” and “low” are based on attributes of the variable under investigation). A plot of predicted probabilities may further enrich these discussions (see Section 14.5).\nIf the goal of one’s model is to assess the relationship between a particular independent variable and the dependent variable while adjusting for potential confounding influences, then discussions of the coefficients for “control” variables is generally not needed.\nDiscussions of regression results in academic papers seldom focus on the Intercept term.\nBe mindful of the use of “effect” language, e.g., the “effect of variable X”. This brings to mind causal effects (X causes Y), but causal inference requires some strong assumptions to be met. It is typically safest to discuss results as associations or as comparisons.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#sec-presentation-regression-tables-logit",
    "href": "logit_06.html#sec-presentation-regression-tables-logit",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "14.2 Presentation: Regression Tables",
    "text": "14.2 Presentation: Regression Tables\nWe use the modelsummary() command from the modelsummary library to create regression tables. The basic process and syntax is the same as with linear regression models (see Section 8.4). The primary difference comes in how we specify the goodness of fit statistics statistics that will be presented.\n\nmodelsummary(Vote_model_mp,\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constant\",\n                             \"agea\" = \"Age\",\n                             \"gndrMale\" = \"Male respondent\",\n                             \"trstplt\"= \"Trust in politicians\",\n                             \"lrscale\" = \"Left-right positioning\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Turnout in the Netherlands (ESS9)\",\n             notes = (\"Logistic regression coefficients with standard errors in parentheses\"))\n\n \n\n  \n    \n    \n    tinytable_fqfoh0w7t2jkt7bbmmrs\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Turnout in the Netherlands (ESS9)\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLogistic regression coefficients with standard errors in parentheses\n        \n                \n                  Constant              \n                  -0.284  \n                \n                \n                                        \n                  (0.380) \n                \n                \n                  Male respondent       \n                  0.043   \n                \n                \n                                        \n                  (0.154) \n                \n                \n                  Age                   \n                  0.018***\n                \n                \n                                        \n                  (0.005) \n                \n                \n                  Trust in politicians  \n                  0.195***\n                \n                \n                                        \n                  (0.039) \n                \n                \n                  Left-right positioning\n                  0.029   \n                \n                \n                                        \n                  (0.039) \n                \n                \n                  Num.Obs.              \n                  1425    \n                \n                \n                  Log.Lik.              \n                  -567.653\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nThe syntax is the same as with a linear regression except for this:\n\ngof_map = c(\"nobs\", \"logLik\")\n\nSeveral goodness-of-fit measures can be added to the table. Here we only include the model N and the log likelihood. Unfortunately, the Nagelkerke R2 is not one of the options that modelsummary() natively supports and hence it cannot be automatically added to the table. There is a workaround within the function, but one that goes beyond the scope of this document. Alternatively, we can add the Nagelkerke R2 manually to our table in our word processor (Word, Google Docs, etc.) in a row beneath ‘Log.Lik.’.\n\n\n\n14.2.1 Tables with Odds Ratios\nThe regression table above presented the coefficients from a logistic regression model. We can also have modelsummary() create a table showing the odds ratios. We can do so via two modifications to our syntax above:\n\nmodelsummary(Vote_model_mp,\n1             exponentiate = TRUE,\n2             statistic = 'conf.int',\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constant\",\n                             \"agea\" = \"Age\",\n                             \"gndrMale\" = \"Male respondent\",\n                             \"trstplt\"= \"Trust in politicians\",\n                             \"lrscale\" = \"Left-right positioning\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Turnout in the Netherlands (ESS9)\",\n             notes = (\"Odds ratios with 95% confidence intervals in brackets\"))\n\n\n1\n\nTells modelsummary() to exponetiate the logistic coefficients, thus giving us the odds ratios.\n\n2\n\nTells modelsummary() to give us the (95%) confidence intervals rather than the default standard errors. CIs are more commonly presented with odds ratios.\n\n\n\n\n \n\n  \n    \n    \n    tinytable_ptuo4l83ybp624xqztev\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Turnout in the Netherlands (ESS9)\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOdds ratios with 95% confidence intervals in brackets\n        \n                \n                  Constant              \n                  0.753         \n                \n                \n                                        \n                  [0.357, 1.588]\n                \n                \n                  Male respondent       \n                  1.044         \n                \n                \n                                        \n                  [0.772, 1.413]\n                \n                \n                  Age                   \n                  1.019***      \n                \n                \n                                        \n                  [1.010, 1.028]\n                \n                \n                  Trust in politicians  \n                  1.215***      \n                \n                \n                                        \n                  [1.126, 1.311]\n                \n                \n                  Left-right positioning\n                  1.030         \n                \n                \n                                        \n                  [0.953, 1.112]\n                \n                \n                  Num.Obs.              \n                  1425          \n                \n                \n                  Log.Lik.              \n                  -567.653      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\nexponentiate = TRUE,\n\nWith this code we ask for the exponentiated coefficients, i.e., the odds ratios.\n\nstatistic = 'conf.int'\n\nThis part of the code specifies that we want the confidence intervals and not the default standard errors in the table.\n\n\nIf we are altering the table in this way, then we should also update our notes section to notify the consumers of our table as to what they are seeing as we do in this portion: notes = (\"Odds ratios with 95% confidence intervals in brackets\").",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#presentation-coefficient-and-odds-ratio-plots",
    "href": "logit_06.html#presentation-coefficient-and-odds-ratio-plots",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "14.3 Presentation: Coefficient and Odds Ratio Plots",
    "text": "14.3 Presentation: Coefficient and Odds Ratio Plots\nWe could present the result of our model via a coefficient plot (with a full regression table in an appendix), much as with a linear regression model. The basic process is described in Section 8.5 . Here is an example based on the model above:\n\n1tidy(Vote_model_mp, conf.int = TRUE) |&gt;\n2  filter(term != \"(Intercept)\") |&gt;\n3  mutate(term = recode(term,\n                       \"gndrMale\" = \"Male Respondent\", \n                       \"agea\" = \"Respondent Age\", \n                       \"trstplt\" = \"Trust in Politicians\", \n                       \"lrscale\" = \"Left-right Positioning\")) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Turnout in the Netherlands (ESS9)\", \n       y = \"Variable\", \n       x = \"Logistic Regression Coefficient\") + \n  geom_vline(xintercept = 0, linetype = \"dashed\", color =\"red\") + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nWe are completing this process all at once by using the |&gt; operator. However, it is often simpler to break this up into steps: (1) store the results of tidy as a new object; (2) recode the term variable in that object and filter our the Intercept; and (3) produce the plot.\n\n2\n\nFilters out the Intercept term, which is not typically plotted in a coefficient plot.\n\n3\n\nInstead of using recode() on this variable, we could instead convert it into a factor variable using factor(). This would enable us to still provide informative labels for each term as well as controlling the order in which the observations are plotted. See the discussion in Tip 8.1.\n\n\n\n\n\n\n\n\n\n\n\nIf we wanted to plot the odds ratios, then the process is identical except that we would (1) ask tidy() to save the odds ratios and (2) update the reference line syntax to place a reference line at 1 rather than 0 given:\n\n1tidy(Vote_model_mp, conf.int = TRUE, exponentiate = TRUE) |&gt;\n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"gndrMale\" = \"Male Respondent\", \n                       \"agea\" = \"Respondent Age\", \n                       \"trstplt\" = \"Trust in Politicians\", \n                       \"lrscale\" = \"Left-right Positioning\")) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Turnout in the Netherlands (ESS9)\", \n       y = \"Variable\", \n       x = \"Odds Ratio\") + \n2  geom_vline(xintercept = 1, linetype = \"dashed\", color =\"red\") +\n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nexponentiate = TRUE needed to obtain the odds ratios\n\n2\n\nOdds ratios are interpreted around 1 rather rather than 0. We should thus put our reference line at 1\n\n\n\n\n\n\n\n\n\n\n\n\n14.3.1 Instructions\n\nIt is common to place the coefficient estimate on the x-axis and the variable names on the y-axis. One can reverse this (estimates on the y-axis, variable names on the x-axis) in some circumstances without a problem. However, this can lead to situations where the variable names overlap and become difficult to read. The formatting above avoids this type of issue (although very long labels can still be problematic). Other possible remedies to this type of problem are discussed in helpful blog post.\nThe default behavior of ggplot is to order the coefficients by the alphabetical order of the variable that contains the variable names (named term when one is plotting the results of a data frame created using the tidy() function as above). This is often less than ideal as the different categories of a categorical variable may be separated from one another (as in the example above). In addition, we may want to call attention to a particular variable in the model which may be harder to do if it is placed in middle of the plot. We can avoid this issue by converting the term variable into a factor variable and specifying the order of its levels; see the discussion in Tip 8.1.\nPlotting the (rounded) coefficient value or odds ratio value above or next to the marker helps readers place it on the axis and hence understand the results better.\n95% confidence intervals are the ones that are conventionally plotted.\nWhen you are placing a figure such as this in the text of a paper/report, then you should include a “Notes” section underneath the figure briefly explaining what is being presented. For instance: “Notes: Markers provide the logistic regression coefficient for each variable with 95% confidence intervals”.\nProviding a reference line at 0 (or 1 with odds ratios) is good practice as this helps readers understand whether a coefficient is statistically significant (at least, at p &lt; 0.05).",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#presentation-ame-plots",
    "href": "logit_06.html#presentation-ame-plots",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "14.4 Presentation: AME Plots",
    "text": "14.4 Presentation: AME Plots\nWe can likewise plot the average marginal effects of our logistic regression model. This may be more informative than the coefficients themselves since they are on a more intuitive scale. The process is basically the same as for coefficient plots, but instead of using tidy() as the input to the plot, we use the results of avg_slopes() from the marginaleffects package:\n\n1avg_slopes(Vote_model_mp) |&gt;\n2  mutate(term = recode(term,\n3                       \"gndr\" = \"Male Respondent\",\n                       \"agea\" = \"Respondent Age\", \n                       \"trstplt\" = \"Trust in Politicians\", \n                       \"lrscale\" = \"Left-right Positioning\")) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Turnout in the Netherlands (ESS9)\", \n       y = \"Variable\", \n       x = \"Average Marginal Effect\") + \n  geom_vline(xintercept = 0, linetype = \"dashed\", color =\"red\") + \n4  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nWe are completing this process all at once by using the |&gt; operator. However, it is often simpler to break this up into steps: (1) store the results of avg_slopes() as a new object; (2) recode the term variable in that object; and (3) produce the plot.\n\n2\n\nInstead of using recode() on this variable, we could instead convert it into a factor variable using factor(). This would enable us to still provide informative labels for each term as well as controlling the order in which the observations are plotted. See the discussion in Chapter 8, Section 8.5.\n\n3\n\navg_slopes() does not combine the variable name and label for factor variables when creating term (e.g., it shows gndr rather than gndrMale).\n\n4\n\nThe AMEs for the age and ideology variables are quite small so the rounded estimate in the plot is simply given as a 0. One way to around that is to increase the decimals to round to (e.g., round(estimate, 3).\n\n\n\n\n\n\n\n\n\n\n\nThe plot above is on the probability scale, which ranges from 0 to 1. If we wanted to display the AME as a percentage point change, then we would need to multiply the AME (estimate) and its confidence interval values (conf.low, conf.high) by 100 before plotting:\n\navg_slopes(Vote_model_mp) |&gt; \n  mutate(term = recode(term, \n                       \"gndr\" = \"Male Respondent\",  \n                       \"agea\" = \"Respondent Age\", \n                       \"trstplt\" = \"Trust in Politicians\", \n                       \"lrscale\" = \"Left-right Positioning\"), \n         estimate = estimate * 100, \n         conf.low = conf.low * 100,\n         conf.high = conf.high * 100) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Turnout in the Netherlands (ESS9)\", \n       y = \"Variable\", \n       x = \"Average Marginal Effect (Percentage Point Change)\") + \n  geom_vline(xintercept = 0, linetype = \"dashed\", color =\"red\") + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n\n\n\n\n\n\n\n14.4.1 Instructions\nThe same instructions apply as with coefficient plots for linear regression ( Section 8.5) or with coefficient/odds ratio plots (see above).",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#sec-presentation-predicted-probability-plots",
    "href": "logit_06.html#sec-presentation-predicted-probability-plots",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "14.5 Presentation: Predicted Probability Plots",
    "text": "14.5 Presentation: Predicted Probability Plots\nFinally, we could present our results via a plot of the predicted probabilities from our model. This is perhaps particularly useful with continuous predictor variables as it enables us to quickly show the degree of change in the probability of Y across the range of X. The process here is again similar to what we did with predicted values plots in linear regressions (see Section 8.6), so we will concisely show the syntax here.\n\n14.5.1 Continuous Predictor\nOur model output shows that voter turnout increases with trust in politicians. The AMEs indicate that a one unit change in trust in politicians is associated with a higher rate of turnout of around 2.3 percentage points, on average. We might wonder, however, whether this would lead us to expect a change from being unlikely to vote at all to likely to vote? Or, perhaps, from somewhat likely to vote to extremely? The predicted probabilities can help us answer such a question.\nWe begin by using the predictions() command to calculated predicted probabilities for the trust in politicians variable.\n\n#Save the predictions\nPred_conts &lt;- predictions(Vote_model_mp, \n1                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2)))\n#Let's take a look\ntibble(Pred_conts)\n\n\n1\n\nWe could also have predictions() do this in 1pt increments. But, that is unnecessary as ggplot() will naturally fill in the gaps in our predictions.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr   agea lrscale trstplt\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male   50.7    5.15       0\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male   50.7    5.15       2\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male   50.7    5.15       4\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male   50.7    5.15       6\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male   50.7    5.15       8\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male   50.7    5.15      10\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\nWe pass this data to ggplot() much as we did with a predicted values plot based on a linear regression model:\n\n1ggplot(Pred_conts, aes(x = trstplt, y = estimate)) +\n2  geom_line() +\n3  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +\n4  labs(title = \"Trust and Turnout in the Netherlands\",\n       x = \"Trust in politicians\", \n       y = \"Predicted probability to vote\") \n\n\n1\n\nTells ggplot() what data (Pred_conts) to use and what should be on the x- (trstplt) and y-axes (estimate)\n\n2\n\nTells ggplot() that we want a line connecting the predictions.\n\n3\n\nTells ggplot() that we want the confidence intervals to show up as a ribbon around the line and to lighten the shading of the ribbon (alpha = 0.2).\n\n4\n\nProvides informative labels.\n\n\n\n\n\n\n\n\n\n\n\nWe could also update the scaling of the y-axis to range from 0-1 (the theoretical range of probabilities) if we were concerned that not doing so would be misleading.\n\nggplot(Pred_conts, aes(x = trstplt, y = estimate)) +   \n  geom_line() +                                        \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +  \n  labs(title = \"Trust and Turnout in the Netherlands\", \n       x = \"Trust in politicians\", \n       y = \"Predicted probability to vote\") + \n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\n\n\n\n\n\n14.5.2 Factor Predictor\nWe can use the following code in situations where the predictor variable is a factor variable:\n\n#Obtain the predictions\nPred_cat &lt;- predictions(Vote_model_mp, by = \"gndr\", newdata = \"mean\") \n\n#Let's take a look!\ntibble(Pred_cat)\n\n# A tibble: 2 × 11\n  rowid gndr  estimate  p.value s.value conf.low conf.high  agea trstplt lrscale\n  &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Fema…    0.863 1.35e-60    199.    0.835     0.887  50.7    5.34    5.15\n2     2 Male     0.868 1.44e-64    212.    0.841     0.891  50.7    5.34    5.15\n# ℹ 1 more variable: vote &lt;fct&gt;\n\n\nWe can then feed that data into our plot:\n\nggplot(Pred_cat, aes(x = gndr, y = estimate)) +   \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +  \n  labs(title = \"Gender and Turnout in the Netherlands\", \n       x = \"Gender\",\n       y = \"Predicted probability to vote\") +\n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25) \n\n\n\n\n\n\n\n\n\n\n14.5.3 Instructions\n\nWhich values should one input into the predictions() command and hence plot?\n\nIf the variable is binary/categorical, then you should focus on all of the (relevant) categories to the discussion at hand.\nIf the variable is continuous, then one can input the minimum and maximum of the variable with reasonable increments between them to produce a plot showing changes across the range of X. However, there is an important note on this front: If your data has missing values on one or more variables in the model, then the min and max of a variable in the model may not correspond to what you would find if you simply used the summary() function to summarize the variable’s distribution in the full dataset. This can be problematic if leads you to make predictions for values of a variable that are not observed in the model as these types of extrapolations may be uncertain and faulty. You can avoid this problem by creating a dataset that only includes observations in the model and then finding the min/max (and other intermediate values). This can be done, for instance, by using the predictions() command as shown Section 5.3.1 .\n\nThe continuous variable example above plots the predicted values as a line with a ribbon showing the 95% confidence interval around the predictions. This is a conventional choice when one is plotting predictions for a continuous independent variable. If the independent variable is binary/categorical, then one would typically use something like geom_pointrange() or geom_errorbar().\nThe scale of the y-axis is something to consider when creating a plot such as this. The examples above uses scale_y_continuous() to make sure that the y-axis stretches from the min to the max value of the DV. This can help avoid situations where ggplot() shows only a truncated stretch of the y-axis thereby potentially giving a false impression of the magnitude of the change in Y across the range of X. This type of rescaling is not always needed, and can sometimes create its own problems, but it is something to reflect on before communicating statistical results. The sociologist Kieran Healy provides a further discussion of these competing considerations in his book on data visualization.",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "logit_06.html#footnotes",
    "href": "logit_06.html#footnotes",
    "title": "14  Reporting & Presenting Logistic Regressions",
    "section": "",
    "text": "Using a 90% significance test may be acceptable if the model has a small N.↩︎",
    "crumbs": [
      "Logistic Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting & Presenting Logistic Regressions</span>"
    ]
  },
  {
    "objectID": "part_interactions.html",
    "href": "part_interactions.html",
    "title": "Interactions within Linear and Logistic Models",
    "section": "",
    "text": "This section of the materials focuses on the inclusion and interpretation of interactions within linear and logistic models. You will learn how to…\n\nInclude interaction terms in your regression models\nUse marginal effect and predicted value/probability estimates to interpret them",
    "crumbs": [
      "Interactions within Linear and Logistic Models"
    ]
  },
  {
    "objectID": "interaction_01.html",
    "href": "interaction_01.html",
    "title": "15  Including an Interaction Term in a Regression Model",
    "section": "",
    "text": "15.1 Adding an Interaction Term to a Regression Model\nWe can add multiple predictor variables to both a linear (lm) and logistic (glm) regression model using the ‘+’ sign. We can include an interaction between two predictor variables by using the ‘*’ sign instead.\nFor example, in this linear regression model we predict how respondents evaluated then candidate Joe Biden on a scale ranging from 0 (‘very cold or unfavorable’) to 100 (‘very warm or favorable’) using three predictor variables: (1) pid (the respondent’s partisan identity, which is a continuous variable ranging from 1 [“Strong Democrat”] to 7 [“Strong Republican”]); (2) right_track (a binary factor variable where 0 indicates the respondent thinks the “country is on the wrong track” and 1 that the “country is heading in the right direction”); (3) and rural_urban (a categorical variable concerning where the respondent lives with “suburb” as the reference category).\n#Run the model and store results\nbiden_model &lt;- lm(biden ~ pid + right_track + rural_urban, data = anes)\n\n#Summary of results\nsummary(biden_model)\n\n\nCall:\nlm(formula = biden ~ pid + right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-83.656 -13.349   0.771  16.344  90.722 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 93.9170     0.6543 143.537  &lt; 2e-16 ***\npid                        -10.2606     0.1364 -75.245  &lt; 2e-16 ***\nright_trackRight Direction -12.8153     0.6993 -18.326  &lt; 2e-16 ***\nrural_urbanRural            -4.1666     0.8219  -5.070 4.09e-07 ***\nrural_urbanSmall Town       -2.9846     0.7011  -4.257 2.10e-05 ***\nrural_urbanCity             -0.3076     0.6713  -0.458    0.647    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.88 on 7141 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.602, Adjusted R-squared:  0.6018 \nF-statistic:  2161 on 5 and 7141 DF,  p-value: &lt; 2.2e-16\nEvaluations of Biden become more negative on average as the pid measure increases in value, that is, as we move from the Democratic end of the scale to the Republican end of the scale. Respondents who state that the country is heading in the “right direction”, meanwhile, evaluate Biden worse on average than those who say that the country is “on the wrong track”. This is because answers to the right_track question reflect one’s impressions of the performance of then President Donald Trump: people saying ‘right direction’ had positive evaluations of Trump and, conversely, negatively ones of his opponent Biden.1\nPerhaps we have some theory-driven reason to expect the relationship between partisanship and evaluations of Biden to vary based on whether people think things in the country are going well or not. Or, vice versa, we might have some reason to think that the effect of evaluations regarding how things were going in the country on evaluations of Biden depends on the person’s partisanship. We can examine these types of questions by adding an interaction between the two variables (pid and right_track) by using an asterisk (‘*’) rather than a plus sign (‘+’) to separate the two variables:\n#Run the model and store results\nbiden_int &lt;- lm(biden ~ pid * right_track + rural_urban, data = anes)\n\n#Summary of results\nsummary(biden_int)\n\n\nCall:\nlm(formula = biden ~ pid * right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-84.834 -13.186   0.166  15.166  87.299 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     95.6585     0.6730 142.146  &lt; 2e-16 ***\npid                            -10.8243     0.1468 -73.744  &lt; 2e-16 ***\nright_trackRight Direction     -33.1885     2.1600 -15.365  &lt; 2e-16 ***\nrural_urbanRural                -4.0838     0.8163  -5.003 5.79e-07 ***\nrural_urbanSmall Town           -2.8082     0.6965  -4.032 5.60e-05 ***\nrural_urbanCity                 -0.3202     0.6667  -0.480    0.631    \npid:right_trackRight Direction   3.7144     0.3729   9.961  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.73 on 7140 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.6075,    Adjusted R-squared:  0.6072 \nF-statistic:  1842 on 6 and 7140 DF,  p-value: &lt; 2.2e-16\nIncluding an interaction term follows the same principles when using a logistic model. We demonstrate that here by predicting whether the person says the US is heading in the “right direction” (1) or not (0) (right_track). We use the following predictor variables: (1) vote2016, which records who the respondent reported voting for in the 2016 Presidential election (Hillary Clinton = 0, Donald Trump = 1; vote2016); age in years (age); and place of residence (rural_urban). We add an interaction between vote2016 and age in this example:\n#Run the model and store results\nrighttrack_int &lt;- glm(right_track ~ vote2016 * age + rural_urban, \n                      family = \"binomial\", data = anes)\n\n#Summary of results\nsummary(righttrack_int)\n\n\nCall:\nglm(formula = right_track ~ vote2016 * age + rural_urban, family = \"binomial\", \n    data = anes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.3302  -0.2990  -0.2566   1.0444   2.6952  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.952141   0.344679  -8.565  &lt; 2e-16 ***\nvote2016Trump Vote      2.820292   0.373350   7.554 4.22e-14 ***\nage                    -0.009465   0.006296  -1.503   0.1328    \nrural_urbanRural        0.208129   0.111289   1.870   0.0615 .  \nrural_urbanSmall Town   0.110962   0.101173   1.097   0.2727    \nrural_urbanCity         0.160473   0.110704   1.450   0.1472    \nvote2016Trump Vote:age  0.012914   0.006823   1.893   0.0584 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5929.4  on 5132  degrees of freedom\nResidual deviance: 4033.5  on 5126  degrees of freedom\n  (3147 observations deleted due to missingness)\nAIC: 4047.5\n\nNumber of Fisher Scoring iterations: 6",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Including an Interaction Term in a Regression Model</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#adding-an-interaction-term-to-a-regression-model",
    "href": "interaction_01.html#adding-an-interaction-term-to-a-regression-model",
    "title": "15  Including an Interaction Term in a Regression Model",
    "section": "",
    "text": "Output Explanation\n\n\n\nThe structure of our output is the same as with our previous examples. However, we can see that there is now an extra term in the Coefficients box: “pid:right_trackRight Direction”.\nWhen we separate two variables by an ‘*’, R will include both variables plus an interaction term multiplying the two variables with one another in the model. The name provided to the interaction term will be the names of the two variables separated by a colon as in the example above (“pid:right_trackRight Direction”).\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nWhen estimating an interaction term, we are basically asking ourselves whether the relationship between a certain predictor (X) and the dependent variable (Y) is different when a second predictor (Z) takes on different values. The coefficient for the interaction term provides us with information about whether this is the case.\n\n\n\n\n\nIn our linear biden_int model, for instance, the interaction term is statistically significant: the relationship between pid and Biden evaluations may be different depending on whether the person says the country is on the wrong track or heading in the “right direction”.2 The interaction term in the logistic righttrack_int model, meanwhile, is not statistically significant using conventional standards of significance, which implies that the relationship between, for instance, age and beliefs about the country is the same regardless of whether we consider Clinton or Trump voters.\nThe coefficients for the variables being interacted with one another can be tricky to directly interpret. As a result, we will use R to calculate other statistical estimates to better understand the interaction effect:\n\nThe marginal effect of one variable in the interaction at different values of the other variable in the interaction ( Chapter 16).\nThe predicted values for specific value combination of the two variables in the interaction. ( Chapter 17)",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Including an Interaction Term in a Regression Model</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#regression-tables",
    "href": "interaction_01.html#regression-tables",
    "title": "15  Including an Interaction Term in a Regression Model",
    "section": "15.2 Regression Tables",
    "text": "15.2 Regression Tables\nOur next two chapters will focus on communicating the results of regression models that feature interaction terms via plots. Here we will briefly note show how to present these results as a regression table using the modelsummary() function from the modelsummary library. The basic principles are the same as discussed in prior chapters (linear regression tables: Section 8.4 ; logistic regression tables: Section 14.2 ).\nWe will provide the results of our first two models in this example. We will show both the original model and the one that adds the interaction term side by side so that readers can see how our results change the interaction is added to the model.\n\n# List of models\n1interaction_lm_models &lt;- list(\n  biden_model, biden_int\n)\n\n#Create the table\n2modelsummary(interaction_lm_models,\n3             stars = T,\n4             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"pid\" = \"Party Identification\", \n               \"right_trackRight Direction\" = \"Country Heading in Right Direction?\", \n               \"rural_urbanRural\" = \"Rural Resident\", \n               \"rural_urbanSmall Town\" = \"Small Town Resident\", \n               \"rural_urbanCity\" = \"City Resident\", \n               \"pid:right_trackRight Direction\" = \"PID x Right Direction\"), \n5             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n6             title = \"Predicting Biden Evaluations\",\n7             notes = \"OLS coefficients with standard errors in parentheses; Reference category for place of residence = Suburbs.\")\n\n\n1\n\nWe first create a new “list” object containing the models we want to include in the table\n\n2\n\nThe name of the list object we just created\n\n3\n\nThis adds “stars” to signal statistical significance\n\n4\n\nWe rename our variables for better communication via coef_rename()\n\n5\n\nWe select which model fit statistics via gof_map()\n\n6\n\nWe can give a title to the table via title =\n\n7\n\nAnd, finally, provide some notes at the bottom of the table via notes =\n\n\n\n\n \n\n  \n    \n    \n    tinytable_z3f0lvdshl63m8oi5737\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Biden Evaluations\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses; Reference category for place of residence = Suburbs.\n        \n                \n                  Intercept                          \n                  93.917*** \n                  95.659*** \n                \n                \n                                                     \n                  (0.654)   \n                  (0.673)   \n                \n                \n                  Party Identification               \n                  -10.261***\n                  -10.824***\n                \n                \n                                                     \n                  (0.136)   \n                  (0.147)   \n                \n                \n                  Country Heading in Right Direction?\n                  -12.815***\n                  -33.188***\n                \n                \n                                                     \n                  (0.699)   \n                  (2.160)   \n                \n                \n                  Rural Resident                     \n                  -4.167*** \n                  -4.084*** \n                \n                \n                                                     \n                  (0.822)   \n                  (0.816)   \n                \n                \n                  Small Town Resident                \n                  -2.985*** \n                  -2.808*** \n                \n                \n                                                     \n                  (0.701)   \n                  (0.697)   \n                \n                \n                  City Resident                      \n                  -0.308    \n                  -0.320    \n                \n                \n                                                     \n                  (0.671)   \n                  (0.667)   \n                \n                \n                  PID x Right Direction              \n                            \n                  3.714***  \n                \n                \n                                                     \n                            \n                  (0.373)   \n                \n                \n                  Num.Obs.                           \n                  7147      \n                  7147      \n                \n                \n                  R2                                 \n                  0.602     \n                  0.607     \n                \n                \n                  R2 Adj.                            \n                  0.602     \n                  0.607     \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nThe main thing we might want to change about a table like this is to change the placement of the interaction term coefficient. The default behavior is to place it at the bottom of the table. That is perfectly fine, but we might want to place it alongside the other variables within the interaction so that consumers of our table can consider these coefficients all at once. We can do this by changing coef_rename to coef_map in our syntax and moving the entry for the interaction term to where we want it to show up in the resulting table:\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n1             coef_map = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"pid\" = \"Party Identification\", \n               \"right_trackRight Direction\" = \"Country Heading in Right Direction?\", \n2               \"pid:right_trackRight Direction\" = \"PID x Right Direction\",\n               \"rural_urbanRural\" = \"Rural Resident\", \n               \"rural_urbanSmall Town\" = \"Small Town Resident\", \n               \"rural_urbanCity\" = \"City Resident\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Predicting Biden Evaluations\", \n             notes = \"OLS coefficients with standard errors in parentheses; Reference category for place of residence = Suburbs.\") \n\n\n1\n\nWe changed coef_rename to coef_map\n\n2\n\nWe moved the part where we rename the interaction up and placed it after the second term in our interaction. This changes the order in which the coefficients are displayed in our table due to the use of coef_map\n\n\n\n\n \n\n  \n    \n    \n    tinytable_w5y1rarqp61f0hw1f6zg\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Biden Evaluations\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses; Reference category for place of residence = Suburbs.\n        \n                \n                  Intercept                          \n                  93.917*** \n                  95.659*** \n                \n                \n                                                     \n                  (0.654)   \n                  (0.673)   \n                \n                \n                  Party Identification               \n                  -10.261***\n                  -10.824***\n                \n                \n                                                     \n                  (0.136)   \n                  (0.147)   \n                \n                \n                  Country Heading in Right Direction?\n                  -12.815***\n                  -33.188***\n                \n                \n                                                     \n                  (0.699)   \n                  (2.160)   \n                \n                \n                  PID x Right Direction              \n                            \n                  3.714***  \n                \n                \n                                                     \n                            \n                  (0.373)   \n                \n                \n                  Rural Resident                     \n                  -4.167*** \n                  -4.084*** \n                \n                \n                                                     \n                  (0.822)   \n                  (0.816)   \n                \n                \n                  Small Town Resident                \n                  -2.985*** \n                  -2.808*** \n                \n                \n                                                     \n                  (0.701)   \n                  (0.697)   \n                \n                \n                  City Resident                      \n                  -0.308    \n                  -0.320    \n                \n                \n                                                     \n                  (0.671)   \n                  (0.667)   \n                \n                \n                  Num.Obs.                           \n                  7147      \n                  7147      \n                \n                \n                  R2                                 \n                  0.602     \n                  0.607     \n                \n                \n                  R2 Adj.                            \n                  0.602     \n                  0.607     \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nHere, we have moved the interaction term up in the table so that it comes right after the two other variables in the interaction (pid and right_track).\n\n\n\n\n\n\nWarning!\n\n\n\nWe can use coef_map to alter the order of coefficients in our table as above. This is not usually needed but can be handy in some circumstances. But, do note that coef_map is type sensitive and will only show coefficients when you have correctly written out their underlying name. Here is an example, for instance, where we make two mistakes: we write “right_trackRight direction” rather than the correct “right_trackRight Direction” and we write “rural_urbancity” instead of “rural_urbanCity”:\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n             coef_map = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"pid\" = \"Party Identification\", \n1               \"right_trackRight direction\" = \"Country Heading in Right Direction?\",\n               \"pid:right_trackRight Direction\" = \"PID x Right Direction\",  \n               \"rural_urbanRural\" = \"Rural Resident\", \n               \"rural_urbanSmall Town\" = \"Small Town Resident\", \n2               \"rural_urbancity\" = \"City Resident\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Predicting Biden Evaluations\", \n             notes = \"OLS coefficients with standard errors in parentheses\") \n\n\n1\n\nWe changed “Direction” to “direction”\n\n2\n\nWe changed “City” to “city”\n\n\n\n\n \n\n  \n    \n    \n    tinytable_cwdal30sapsxp7piebcs\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        Predicting Biden Evaluations\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coefficients with standard errors in parentheses\n        \n                \n                  Intercept            \n                  93.917*** \n                  95.659*** \n                \n                \n                                       \n                  (0.654)   \n                  (0.673)   \n                \n                \n                  Party Identification \n                  -10.261***\n                  -10.824***\n                \n                \n                                       \n                  (0.136)   \n                  (0.147)   \n                \n                \n                  PID x Right Direction\n                            \n                  3.714***  \n                \n                \n                                       \n                            \n                  (0.373)   \n                \n                \n                  Rural Resident       \n                  -4.167*** \n                  -4.084*** \n                \n                \n                                       \n                  (0.822)   \n                  (0.816)   \n                \n                \n                  Small Town Resident  \n                  -2.985*** \n                  -2.808*** \n                \n                \n                                       \n                  (0.701)   \n                  (0.697)   \n                \n                \n                  Num.Obs.             \n                  7147      \n                  7147      \n                \n                \n                  R2                   \n                  0.602     \n                  0.607     \n                \n                \n                  R2 Adj.              \n                  0.602     \n                  0.607     \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nOh no! We no longer see coefficients for the two variables that we mis-spelled in our syntax.\nThe warning here is that if you do use coef_map in this way in your future work, then double check your spellings and your output lest you mistakenly leave something quite critical out of your table. You can learn more about the coef_map option at the modelsummary website (link)",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Including an Interaction Term in a Regression Model</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#footnotes",
    "href": "interaction_01.html#footnotes",
    "title": "15  Including an Interaction Term in a Regression Model",
    "section": "",
    "text": "Our dataset also has a measure of evaluations of Donald Trump (the variable named trump). The average evaluation of Trump among those saying the country was heading in the “right direction” was 83.2 on this 0-100pt scale, while it was 25.4 among those saying things were heading down the “wrong track”.↩︎\nBut note that interaction terms are “symmetrical”. We can also talk about whether the difference in Biden evaluations based on saying “right direction” or “wrong track” is the same for Strong Democrats (pid = 1) as for Not Strong Democrats (pid = 2) and so on. When we interpret an interaction model we must first discern what variable is supposed to be the “X” variable and which is supposed to be the “Z” (or moderator) variable as this effects how we use the model”s results.↩︎",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Including an Interaction Term in a Regression Model</span>"
    ]
  },
  {
    "objectID": "interaction_02.html",
    "href": "interaction_02.html",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "",
    "text": "16.1 Binary x Continuous",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#binary-x-continuous",
    "href": "interaction_02.html#binary-x-continuous",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "",
    "text": "16.1.1 Calculation and Interpretation\nWe will use the biden_int model in our first example. Here, we interacted a binary variable (right_track) with a continuous variable (pid).\nOne question we can ask is this: is the relationship between pid (X) and Biden evaluations (Y) the same regardless of what value right_track (Z) takes on? Stated slightly differently: if we calculate the regression slope for pid for respondents who say the country is heading in the right direction and, separately, the slope for pid for respondents who say the country is heading down the wrong track, will those slopes be the same? We will use the slopes() function to calculate the effect of pid for each category of right_track to help us answer this question.\nIn situations where the moderator (Z) is a factor variable, such as this one, we use the following code:\n\nslopes(biden_int, \n       variables = \"pid\", \n       by = \"right_track\")\n\n\n Term    Contrast     right_track Estimate Std. Error     z Pr(&gt;|z|)     S\n  pid mean(dY/dX) Wrong Track       -10.82      0.147 -73.7   &lt;0.001   Inf\n  pid mean(dY/dX) Right Direction    -7.11      0.344 -20.7   &lt;0.001 312.7\n  2.5 % 97.5 %\n -11.11 -10.54\n  -7.78  -6.44\n\nColumns: term, contrast, right_track, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\nslopes(biden_int,\n\nThe name of the command is slopes. The first thing we put in the parentheses is the name of the model, here “biden_int”.\n\nvariables = \"pid\"\n\nWe next specify the name of the variable whose marginal effect we want to know. You would change pid to the name of the variable in your example.\n\nby = \"right_track\"\n\nSpecifies the moderator variable. Can only be used if the moderator is a factor variable.\n\n\nThe slope of the regression line for pid when right_track = ‘Right Direction’” is -7.11. The slope when right_track = ‘Wrong Track’ is -10.82. We can thus say that the relationship between partisan identity and Biden evaluations is stronger (more negative) among respondents who think the country is on the wrong track than among those that thought things were heading in the right direction. We can turn to the coefficient for the interaction term to say whether the difference between these two marginal effects is statistically significant. The interaction term is statistically significant (p &lt; 0.001), which means we can reject the null hypothesis that the difference between the two marginal effects/slopes is actually 0.\nA couple of further points here. First, notice that the marginal effect estimate when right_track = “Wrong Track’ is the same value as the coefficient for pid in our model. Second, notice that the difference between the two marginal effects estimates = the value of the interaction term coefficient.\n\n#Our Results Again\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginal Effect (Right Direction) - Marginal Effect (Wrong Track) = Interaction Term Coefficient\n-7.11 - (-10.82)\n\n[1] 3.71\n\n\nWe can also investigate the effect of the factor variable right_track on the dependent variable when partisan identity takes on different values. In this case, we are using the continuous variable as the moderator variable (Z). We chose to calculate the marginal effects for all possible values of pid given that there are only 7.\n\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\n\n        Term                      Contrast pid Estimate Std. Error      z\n right_track Right Direction - Wrong Track   1   -29.47      1.811 -16.28\n right_track Right Direction - Wrong Track   2   -25.76      1.473 -17.48\n right_track Right Direction - Wrong Track   3   -22.05      1.158 -19.04\n right_track Right Direction - Wrong Track   4   -18.33      0.888 -20.64\n right_track Right Direction - Wrong Track   5   -14.62      0.718 -20.37\n right_track Right Direction - Wrong Track   6   -10.90      0.721 -15.13\n right_track Right Direction - Wrong Track   7    -7.19      0.895  -8.03\n Pr(&gt;|z|)     S  2.5 % 97.5 %\n   &lt;0.001 195.4 -33.02 -25.92\n   &lt;0.001 224.9 -28.65 -22.87\n   &lt;0.001 266.0 -24.32 -19.78\n   &lt;0.001 311.9 -20.07 -16.59\n   &lt;0.001 303.9 -16.02 -13.21\n   &lt;0.001 169.4 -12.31  -9.49\n   &lt;0.001  49.9  -8.94  -5.43\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, pid, predicted_lo, predicted_hi, predicted, right_track, rural_urban, biden \nType:  response \n\n\n\nnewdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\nWe specify the values of the moderator. These values should be changed for you own analysis purposes. We use newdata = datagrid() because pid is being treated as continuous.\n\n\nThe output above shows that the difference in Biden approval scores between those saying the country is heading in the “right direction” vs. those who say it is on the “wrong track” is approximately -29.47 points among Strong Democrats (pid=1), -25.76 points among Not Strong Democrats (pid = 2), and -7.19 points among Strong Republicans (pid=7). The effect of the right_track variable decreases by 3.71 scale points with each increase of PID. This value of 3.71 is the same as our interaction term coefficient!\n\n#Our Results Again; only showing term and estimate to keep things simple\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginal Effect (PID = 2) - Marginal Effect (PID = 1) = Interaction Term Coefficient\n-25.76 - (-29.47)\n\n[1] 3.71\n\n#Marginal Effect (PID = 7) - Marginal Effect (PID = 6) = Interaction Term Coefficient\n-7.19 - (-10.90)\n\n[1] 3.71\n\n\nThe statistically significant interaction term indicates that we can reject the null hypothesis that the change in the effect of right_track given a one unit change in pid is actually 0.\n\n\n16.1.2 Plotting\nMarginal effects are often communicated via plots. The y-axis in these plots is the estimated marginal effect while the x-axis is the value of the moderator.\nBelow is the example when the factor variable is the moderator. The ggplot code has been seen in previous classes. We use the geom_pointrange statement when our moderator is a factor (here: right_track).\n\nslopes(biden_int, \n       variables = \"pid\",  \n1       by = \"right_track\") |&gt;\n  ggplot(aes(x = right_track, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Marginal Effect of PID by Country Status Beliefs\", \n       y = \"Effect of PID\", \n       x = \"Country on Right or Wrong Track?\")  + \n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.2) \n\n\n1\n\nIn this example we directly pass the results from slopes() to ggplot() using the pipe operator. We could, of course, first save the results of the slopes() command to an object and then use that in the ggplot() command. If you try to use this syntax as a jumping off point and run into issues, then we’d recommend splitting things up to help you troubleshoot.\n\n\n\n\n\n\n\n\n\n\n\nAnd here is the example when the continuous variable is the moderator. Now we use geom_line() in combination with geom_ribbon because our moderator is a continuous variable:\n\n#Effect of right_track by pid\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7))) |&gt; \n  ggplot(aes(x=pid, y=estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Difference in Biden Evaluations due to Country Status Beliefs by PID\" ,\n       y = \"Wrong Track - Right Direction\", \n       x = \"Partisanship\") + \n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") + \n1  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))\n\n\n1\n\nIf we did not have this line, then ggplot() could have only shown ticks at 2, 4, and 6. The default behavior of ggplot() is often good enough, but providing all the values is a bit more informative in this instance given that the moderator can only take on 7 different values.",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#continuous-by-continuous-interaction",
    "href": "interaction_02.html#continuous-by-continuous-interaction",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "16.2 Continuous by Continuous Interaction",
    "text": "16.2 Continuous by Continuous Interaction\nThe code for marginal effects calculation follows the same principles in case of an interaction between 2 continuous variables. For example, here we predict Biden evaluations based on the following variables: age, socialists (a respondent’s evaluation of socialists on a 0 (“very cold or unfavorable”) to 100 (“very warm or favorable” scale), the interaction between age and socialists, and rural_urban as a control variable.\n\n#Run the model and store results\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#Summary of results\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nThe interaction term is statistically significant. We can investigate this significant interaction in two ways. We could calculate the effect (regression slope) of age at different values of the socialists predictor. Or, we can calculate the effect of evaluations of socialists on Biden evaluations at different age values. In both cases, we must specify the values for our moderator variable. We choose logical values in line with the nature of our data.\n\n#Marginal effect of age at socialists = 0, 10, 20...100\nslopes(biden_int2, \n       variables = \"age\", \n       newdata = datagrid(socialists = seq(from = 0, to = 100, by = 10))) \n\n#Marginal effect of socialists at age = 20,30,40...80\nslopes(biden_int2, \n       variables = \"socialists\", \n1       newdata = datagrid(age = seq(from = 20, to = 80, by = 10)))\n\n\n1\n\nOur age variable ranges from 18 to 80 (all respondents who are 80 years old or older are given a score of 80).\n\n\n\n\n\n Term socialists Estimate Std. Error     z Pr(&gt;|z|)     S   2.5 %   97.5 %\n  age          0  -0.0752     0.0345 -2.18   0.0295   5.1 -0.1429 -0.00751\n  age         10   0.0228     0.0292  0.78   0.4355   1.2 -0.0344  0.07997\n  age         20   0.1207     0.0247  4.90   &lt;0.001  20.0  0.0724  0.16906\n  age         30   0.2187     0.0215 10.17   &lt;0.001  78.3  0.1766  0.26084\n  age         40   0.3167     0.0204 15.56   &lt;0.001 178.9  0.2768  0.35656\n  age         50   0.4146     0.0215 19.24   &lt;0.001 271.7  0.3724  0.45687\n  age         60   0.5126     0.0247 20.72   &lt;0.001 314.4  0.4641  0.56110\n  age         70   0.6106     0.0293 20.84   &lt;0.001 318.0  0.5532  0.66799\n  age         80   0.7085     0.0346 20.45   &lt;0.001 306.5  0.6407  0.77644\n  age         90   0.8065     0.0405 19.93   &lt;0.001 291.2  0.7272  0.88582\n  age        100   0.9045     0.0467 19.38   &lt;0.001 275.5  0.8130  0.99596\n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, socialists, predicted_lo, predicted_hi, predicted, age, rural_urban, biden \nType:  response \n\n       Term age Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n socialists  20    0.393     0.0253 15.5   &lt;0.001 178.7 0.343  0.442\n socialists  30    0.491     0.0194 25.2   &lt;0.001 464.6 0.453  0.529\n socialists  40    0.589     0.0147 40.1   &lt;0.001   Inf 0.560  0.618\n socialists  50    0.687     0.0123 55.9   &lt;0.001   Inf 0.663  0.711\n socialists  60    0.785     0.0136 57.8   &lt;0.001   Inf 0.758  0.811\n socialists  70    0.883     0.0178 49.7   &lt;0.001   Inf 0.848  0.917\n socialists  80    0.981     0.0233 42.0   &lt;0.001   Inf 0.935  1.026\n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, age, predicted_lo, predicted_hi, predicted, socialists, rural_urban, biden \nType:  response \n\n\nHere, we can see that the effect of age is estimated as negative and statistically significant when the socialists variable = 0 (-0.0752 [95% CI: -0.143, -0.008]). Note how this estimate is identical to the coefficient for age in the model summary. As the socialists variable increases, however, the effect of age flips signs and becomes increasingly positive in value. This is consistent with the positively signed coefficient on the interaction term. Meanwhile, the effect of the socialists variable is positive among young people (e.g., among those aged 20 it is 0.39 [0.34, 0.44]) with this effect growing even more positive as age increases.2\nFor plotting, we use the code for when the moderator variable is continuous (see above, Section 16.1.2).",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#binary-x-binary-interaction",
    "href": "interaction_02.html#binary-x-binary-interaction",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "16.3 Binary x Binary Interaction",
    "text": "16.3 Binary x Binary Interaction\nWhen our interaction is made up of 2 binary factor variables, the same principles for the R code continue to apply. Here we predict the score for Biden based on the interaction between right_track and vote2016 (with rural_urban as a control variable).\n\n#Run the model and store results\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#Summary of results\ntidy(biden_int3)\n\n# A tibble: 7 × 5\n  term                                     estimate std.error statistic  p.value\n  &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                                78.4       0.581   135.    0       \n2 right_trackRight Direction                -25.2       2.11    -12.0   1.20e-32\n3 vote2016Trump Vote                        -51.6       0.770   -67.0   0       \n4 rural_urbanRural                           -2.77      0.907    -3.05  2.30e- 3\n5 rural_urbanSmall Town                      -1.67      0.785    -2.13  3.34e- 2\n6 rural_urbanCity                             0.452     0.753     0.601 5.48e- 1\n7 right_trackRight Direction:vote2016Trum…   13.8       2.28      6.04  1.61e- 9\n\n\nThe marginal effects can be found as follows:\n\n#right_track as moderator\nslopes(biden_int3, \n       variables = \"vote2016\", \n       by = \"right_track\")\n\n\n     Term                              Contrast     right_track Estimate\n vote2016 mean(Trump Vote) - mean(Clinton Vote) Wrong Track        -51.6\n vote2016 mean(Trump Vote) - mean(Clinton Vote) Right Direction    -37.8\n Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n       0.77 -67.0   &lt;0.001   Inf -53.1  -50.1\n       2.15 -17.6   &lt;0.001 227.0 -42.1  -33.6\n\nColumns: term, contrast, right_track, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n#vote2016 as moderator\nslopes(biden_int3, \n       variables = \"right_track\", \n       by = \"vote2016\")\n\n\n        Term                                  Contrast     vote2016 Estimate\n right_track mean(Right Direction) - mean(Wrong Track) Clinton Vote    -25.2\n right_track mean(Right Direction) - mean(Wrong Track) Trump Vote      -11.5\n Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n      2.107 -12.0   &lt;0.001 107.5 -29.4 -21.12\n      0.866 -13.2   &lt;0.001 130.7 -13.2  -9.78\n\nColumns: term, contrast, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nThe top results show that 2016 Trump voters evaluated Biden worse than 2016 Clinton voters regardless of their beliefs about the (actually sorry) state of the country in 2020. However, the difference is much larger among those that thought things in the country were heading in the wrong direction (difference = -51.6) than those that thought otherwise (-37.80). You might notice, again, that the interaction term coefficient equals the difference between these two estimates (e.g., -37.8 - (-51.6) = 13.8). The statistically significant interaction term indicates we can reject the null hypothesis that the difference between the two marginal effects estimates = 0.\nFor plotting, we use the code for when the moderator variable is a factor variable (see Section 16.1.2).",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#logistic-regression-example",
    "href": "interaction_02.html#logistic-regression-example",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "16.4 Logistic regression example",
    "text": "16.4 Logistic regression example\nOur R code remains similar when we have an interaction in a logistic regression as well. The marginal effects obtained now with the slopes() command are the changes in predicted probability that Y = 1 (see Chapter 10).\nHere are the results of the interaction model again:\n\n#Our model\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nThe interaction in this model is between age (a continuous variable) and vote2016 (a factorized binary variable). We can calculate the marginal effects as follows:\n\n# age as moderator at = 20, 30...80\nslopes(righttrack_int, \n       variables = \"vote2016\", \n       newdata = datagrid(age = seq(from = 20, to = 80, by = 10))) \n\n\n     Term                  Contrast age Estimate Std. Error    z Pr(&gt;|z|)     S\n vote2016 Trump Vote - Clinton Vote  20    0.443     0.0300 14.8   &lt;0.001 161.9\n vote2016 Trump Vote - Clinton Vote  30    0.455     0.0244 18.7   &lt;0.001 255.6\n vote2016 Trump Vote - Clinton Vote  40    0.467     0.0199 23.4   &lt;0.001 400.7\n vote2016 Trump Vote - Clinton Vote  50    0.479     0.0173 27.7   &lt;0.001 558.2\n vote2016 Trump Vote - Clinton Vote  60    0.490     0.0172 28.6   &lt;0.001 593.7\n vote2016 Trump Vote - Clinton Vote  70    0.501     0.0195 25.7   &lt;0.001 481.7\n vote2016 Trump Vote - Clinton Vote  80    0.512     0.0235 21.8   &lt;0.001 347.1\n 2.5 % 97.5 %\n 0.384  0.502\n 0.407  0.503\n 0.428  0.506\n 0.445  0.513\n 0.456  0.524\n 0.463  0.539\n 0.466  0.558\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, age, predicted_lo, predicted_hi, predicted, vote2016, rural_urban, right_track \nType:  response \n\n# vote2016 as moderator\nslopes(righttrack_int, \n       variables = \"age\", \n       by = \"vote2016\")\n\n\n Term    Contrast     vote2016  Estimate Std. Error     z Pr(&gt;|z|)   S\n  age mean(dY/dX) Clinton Vote -0.000312   0.000209 -1.49    0.136 2.9\n  age mean(dY/dX) Trump Vote    0.000854   0.000650  1.31    0.189 2.4\n     2.5 %   97.5 %\n -0.000723 9.84e-05\n -0.000421 2.13e-03\n\nColumns: term, contrast, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nWe expect that people who voted for Trump in 2016 to be more likely to say that the country is heading in the right direction than those that voted for Clinton in 2016 even among the very young with this difference expected to grow with age. For instance, we expect the probability of saying the country is heading in the right direction to be about 45.5 percentage points higher among 30 year old respondents who voted for Trump in 2016 than among 30 year old respondents who voted for Clinton in 2016. The corresponding difference among those 80 years (or older) is 51.2 percentage points.3\nSee prior sections for plotting.",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#footnotes",
    "href": "interaction_02.html#footnotes",
    "title": "16  Marginal Effects in Interaction Models",
    "section": "",
    "text": "Our pid variable ranges from 1-7 so there is no “when pid = 0” group in our data. This is an expectation or extrapolation from our data. It is not a very interesting or informative one, but that is not a problem so long as we use the tools shown in the rest of this chapter, and the next one, to properly interpret our model.↩︎\nThe examples here calculate the marginal effects in jumps of 10 units of the moderator (age = 20, 30, 40…). If we had chosen 1 unit increments of the moderator (e.g., age = 20, 21, 22 …) then we would once again see that the difference in effects = the interaction term coefficient. The marginal effect of the socialists variable when age = 20 is 0.393 while it is 0.403 when age = 21. 0.403 - 0.393 = 0.01 which is right in line with the interaction term due to using the rounded estimates displayed in our output.↩︎\nWe have an estimate here comparing people 20 years old in 2020 who either voted for Trump or Clinton in 2016. 20 year old respondents in 2020 would have been 16 in the year 2016 and hence ineligible to vote in that election given that one must be at least 18 years old to vote in US elections. This is not evidence of voter fraud, but rather a reminder that we can use statistical models to produce all sorts of estimates, even those that aren’t exactly meaningful, and we should always think hard about what we’re trying to do when fitting a model.↩︎",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginal Effects in Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html",
    "href": "interaction_03.html",
    "title": "17  Predicted Values from Interaction Models",
    "section": "",
    "text": "17.1 Binary x Continuous Interaction\nPreviously, we predicted Biden evaluations based on an interaction between a continuous variable (partisan identity, pid) and a binary variable (an evaluation of whether the country is on the right track or not, right_track).\nWe will now use predictions() to produce predicted values for each combination of the two variables in the interaction (e.g., pid = 1 & right_track = “Right Direction”, pid = 1 & right_track = “Wrong Track”, pid = 2 & right_track = “Right Direction”…). If one, or both, of the variables in the interaction can take on many values, then we would specify some subset of values from across the range of the variable (e.g., minimum, mean, and maximum). Other predictors in the model will be held at their mean (continuous variables) or modal (factor variables) values.\n#Calculates the predictions and saves them to a new object\nbiden_int_preds &lt;- predictions(biden_int, \n                               newdata = datagrid(pid = c(1,2,3,4,5,6,7), \n                               right_track = c(\"Right Direction\", \"Wrong Track\")))\nWe obtain a dataset with 14 rows of predictions : 7 (values for pid) x 2 (values for right_track):\n# print the results\nbiden_int_preds\n\n\n pid     right_track Estimate Std. Error     z Pr(&gt;|z|)      S 2.5 % 97.5 %\n   1 Right Direction     55.4      1.808  30.6   &lt;0.001  681.6  51.8   58.9\n   1 Wrong Track         84.8      0.581 146.0   &lt;0.001    Inf  83.7   86.0\n   2 Right Direction     48.3      1.493  32.3   &lt;0.001  759.2  45.3   51.2\n   2 Wrong Track         74.0      0.515 143.7   &lt;0.001    Inf  73.0   75.0\n   3 Right Direction     41.1      1.193  34.5   &lt;0.001  863.3  38.8   43.5\n   3 Wrong Track         63.2      0.486 130.1   &lt;0.001    Inf  62.2   64.1\n   4 Right Direction     34.0      0.925  36.8   &lt;0.001  982.0  32.2   35.8\n   4 Wrong Track         52.4      0.500 104.8   &lt;0.001    Inf  51.4   53.3\n   5 Right Direction     26.9      0.724  37.2   &lt;0.001 1002.1  25.5   28.3\n   5 Wrong Track         41.5      0.554  75.0   &lt;0.001    Inf  40.5   42.6\n   6 Right Direction     19.8      0.656  30.2   &lt;0.001  662.9  18.5   21.1\n   6 Wrong Track         30.7      0.638  48.2   &lt;0.001    Inf  29.5   32.0\n   7 Right Direction     12.7      0.757  16.8   &lt;0.001  207.4  11.2   14.2\n   7 Wrong Track         19.9      0.741  26.8   &lt;0.001  524.2  18.4   21.3\n rural_urban\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, pid, right_track, biden \nType:  response\nThe predictions can be visually presented in a plot. The process is similar to creating a predicted values plot from a model without an interaction (see Section 8.6). However, there is one important addition: the linetype statement. See the information below for an important note about this option.\nggplot(biden_int_preds, aes(x = pid, y = estimate, linetype = right_track)) +\n  geom_line() + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) + \n  labs(title = \"Predicted Biden Evaluation by Partisanship and Country Status Beliefs\", \n       x = \"Party Identification\", \n       y = \"Predicted Values\", \n       linetype = \"Right Track?\") + \n  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#binary-x-continuous-interaction",
    "href": "interaction_03.html#binary-x-continuous-interaction",
    "title": "17  Predicted Values from Interaction Models",
    "section": "",
    "text": "biden_int_preds &lt;- predictions(biden_int,\n\nWe apply the predictions function on the model specified in brackets. We store our results in an object (here called biden_int_preds) so that we can use it again later on.\n\nnewdata = datagrid(pid = c(1,2,…7), right_track = c(\"Right Direction\", \"Wrong Track\")))\n\nWe specify the values of our predictors for which we want predictions via the newdata = datagrid() option. Here, we specify that we want predictions for the values of pid from 1 through 7 separately based on whether the right_track variable equals “Right Direction” or “Wrong Track”.1 In your examples, you would change the names of your variables and the values you want to make predictions from.\n\n\n\n\n\n\n\nggplot(…, linetype = right_track)) + geom_line() + geom_ribbon(…) +\n\nThis portion of the syntax is nearly identical to the syntax used in previous sections to produce a predicted values plot. There is one important addition of note, however: linetype = right_track. This tells ggplot() that the predicted values for each category of “right_track” should be given a different type of line so that we can differentiate them in the plot. We could differentiate these predicted values in alternative ways, e.g., by separating them by color (color = right_track), although we should be careful to make sure that such output is still easy to read. One important note here: the linetype (and color) statement only works with factor variables. The right_track variable is already a factor in our example, so we did not need to take any further steps, but we would have to in other scenarios as seen below. See Section A.5 for more on this topic. Ultimately, this syntax could generally be kept the same in your examples.\n\nlabs(…) +\n\nHere we give informative labels to our plot, the axes, and to the legend for linetype.\n\nscale_x_continuous(breaks=c(1,2,3,4,5,6,7))\n\nThis line of syntax tells R that we want a break or tick on the x-axis at 1, 2, … 7. This helps make this plot a bit easier to read/interpret but may not be needed in your examples.",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#continuous-x-continuous-interaction",
    "href": "interaction_03.html#continuous-x-continuous-interaction",
    "title": "17  Predicted Values from Interaction Models",
    "section": "17.2 Continuous x Continuous Interaction",
    "text": "17.2 Continuous x Continuous Interaction\nThe process to get, and plot, predicted values is similar for interactions with continuous variables. Yet, things can be more complicated for predictions and plotting when we have two continuous variables, especially when they can take on many different values.\nLast chapter, we fit a model that predicted evaluations of Joe Biden and which contained an interaction between age and socialists . Here is that model again:\n\n#Run the model and store results\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#Coefficients\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nBoth of the variables in the interaction can take on many values. We could calculate predictions for specific subsets of values, e.g. from 0 to 100 with increments of 10 for socialists, and 20 to 80 with increments of 10 for age. However, this would give use too many values to reasonably plot (or understand).\nA common approach is to choose one of the two predictors, and for this one make predictions for 3 values: the variables’s mean, 1 standard deviation (SD) below the mean, and 1 standard deviation (SD) above the mean. In principle, the continuous variable is transformed into a factor variable with 3 categories: low value, medium value, and high value. This enables us to produce a plot with three lines, one for each of these values. We generally transform the moderator variable (Z).\nWe will take the socialists variable as the moderator for this example. We first need to calculate the three relevant values (mean, 1 SD below, and 1 SD above). We have to make sure we only calculate these statistics for the observations used in the model. We can accomplish by using the predictions() function from the marginaleffects package as this function enables us to create a dataset with only the observations used in fitting the model (see Chapter 5).2\n\npredictions(biden_int2) |&gt;   #creates new object with data just obs in model\n  summarise(\n    mean_below = mean(socialists) - sd(socialists), #1 SD below the mean \n    mean = mean(socialists),                        #Mean of variable\n    mean_above = mean(socialists) + sd(socialists)) #1 SD above the mean\n\n  mean_below     mean mean_above\n1   9.716161 38.33639   66.95661\n\n\nWe next calculate the predicted values using the values we just calculated. We will ask for predictions in ten year increments across the age spectrum.\n\n#predicted values\nbiden_int2_preds &lt;- predictions(biden_int2, \n            newdata = datagrid(\n              socialists = c(9.72, 38.34, 66.96), \n              age = c(20,30,40,50,60,70,80))) \n\n#Print the results\nbiden_int2_preds\n\n\n socialists age Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n       9.72  20     32.3      1.208  26.8   &lt;0.001 522.3  30.0   34.7\n       9.72  30     32.5      0.983  33.1   &lt;0.001 796.8  30.6   34.5\n       9.72  40     32.7      0.802  40.8   &lt;0.001   Inf  31.2   34.3\n       9.72  50     32.9      0.703  46.9   &lt;0.001   Inf  31.6   34.3\n       9.72  60     33.1      0.718  46.1   &lt;0.001   Inf  31.7   34.6\n       9.72  70     33.3      0.843  39.6   &lt;0.001   Inf  31.7   35.0\n       9.72  80     33.5      1.037  32.3   &lt;0.001 759.7  31.5   35.6\n      38.34  20     43.6      0.891  48.9   &lt;0.001   Inf  41.8   45.3\n      38.34  30     46.6      0.755  61.7   &lt;0.001   Inf  45.1   48.1\n      38.34  40     49.6      0.657  75.5   &lt;0.001   Inf  48.3   50.9\n      38.34  50     52.6      0.612  86.0   &lt;0.001   Inf  51.4   53.8\n      38.34  60     55.6      0.633  87.8   &lt;0.001   Inf  54.4   56.8\n      38.34  70     58.6      0.715  82.0   &lt;0.001   Inf  57.2   60.0\n      38.34  80     61.6      0.839  73.5   &lt;0.001   Inf  60.0   63.3\n      66.96  20     54.8      1.083  50.6   &lt;0.001   Inf  52.7   57.0\n      66.96  30     60.6      0.892  68.0   &lt;0.001   Inf  58.9   62.4\n      66.96  40     66.4      0.756  87.9   &lt;0.001   Inf  65.0   67.9\n      66.96  50     72.3      0.709 102.0   &lt;0.001   Inf  70.9   73.6\n      66.96  60     78.1      0.766 101.9   &lt;0.001   Inf  76.6   79.6\n      66.96  70     83.9      0.909  92.2   &lt;0.001   Inf  82.1   85.7\n      66.96  80     89.7      1.105  81.2   &lt;0.001   Inf  87.5   91.8\n rural_urban\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n      Suburb\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, socialists, age, biden \nType:  response \n\n\nOur dataset has 21 observations: 7 values for age x 3 values for socialists.\nIf we want to plot the results using the linetype argument, then we need to first convert the socialists variable in the predictions dataset that we just created into a factor variable. We use the factor() command as the socialists variable in our new dataset is numeric and not labelled.\n\n#Class of variable\nclass(biden_int2_preds$socialists)\n\n[1] \"numeric\"\n\n#No value labels\nattributes(biden_int2_preds$socialists)\n\nNULL\n\n#Conert into a factor variable\nbiden_int2_preds &lt;- biden_int2_preds |&gt; \n  mutate(socialists = factor(socialists, \n                             levels = c(9.72, 38.34, 66.96), \n                             labels = c(\"1SD &lt; Mean\", \"Mean\", \"1SD &gt; Mean\")))\n\nWe can then plot as we did before:\n\nggplot(biden_int2_preds, aes(x = age, y = estimate, linetype = socialists)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2) + \n  labs(title = \"Predicted Biden Evaluation by Socialist Thermometer and Age\", \n       y = \"Predicted Value\", \n       x = \"Age\", \n       linetype= \"Socialist Thermometer\")",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#binary-x-binary-interaction",
    "href": "interaction_03.html#binary-x-binary-interaction",
    "title": "17  Predicted Values from Interaction Models",
    "section": "17.3 Binary x Binary Interaction",
    "text": "17.3 Binary x Binary Interaction\nThe process for obtaining predicted values, and creating a predicted values plot, from an interaction between two binary variables follows similar principles as above.\nHere is the model we will use for this example. It includes an interaction between two binary factor variables: one concerning whether the respondent thinks the country is heading in the right or wrong direction (right_track) and one concerning whether the respondent reported voting for Hillary Clinton or Donald Trump in 2016 (vote2016).\n\n#Run the model and store results\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#Summary of results\ntidy(biden_int3)\n\n# A tibble: 7 × 5\n  term                                     estimate std.error statistic  p.value\n  &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                                78.4       0.581   135.    0       \n2 right_trackRight Direction                -25.2       2.11    -12.0   1.20e-32\n3 vote2016Trump Vote                        -51.6       0.770   -67.0   0       \n4 rural_urbanRural                           -2.77      0.907    -3.05  2.30e- 3\n5 rural_urbanSmall Town                      -1.67      0.785    -2.13  3.34e- 2\n6 rural_urbanCity                             0.452     0.753     0.601 5.48e- 1\n7 right_trackRight Direction:vote2016Trum…   13.8       2.28      6.04  1.61e- 9\n\n\nWe will use predictions() function to calculate predicted values for all combinations of the two variables, yielding four predictions in total: Clinton voter & “right direction”, Clinton voter & “wrong track”, Trump voter & “right direction”, and Trump voter and “wrong track”.\n\npredictions(\n  biden_int3, \n  by = c(\"right_track\", \"vote2016\"), \n  newdata = \"mean\")\n\n\n     right_track     vote2016 Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 %\n Right Direction Trump Vote       15.3      0.737  20.7   &lt;0.001 314.8  13.8\n Right Direction Clinton Vote     53.1      2.119  25.1   &lt;0.001 458.6  49.0\n Wrong Track     Trump Vote       26.8      0.775  34.5   &lt;0.001 864.8  25.2\n Wrong Track     Clinton Vote     78.4      0.581 134.9   &lt;0.001   Inf  77.2\n 97.5 %\n   16.7\n   57.3\n   28.3\n   79.5\n\nColumns: rowid, right_track, vote2016, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rural_urban, rowid_dedup \nType:  response \n\n\n\nby = c(\"right_track\", \"vote2016\")\n\nWe have previously seen that we can obtain predicted values for all levels of a categorical variable using the by = \"variable name\" option. If both predictors in the interaction term are binary/factor in nature, then we can include them both in this line to obtain predictions for all combinations of the two variables.\n\nnewdata = \"mean\")\n\nWe need this option in the present case to tell predictions() to hold the other control variable(s) in the equation constant at their mean or mode. In the present case, this ensures that rural_urban will be held constant at its modal category (“suburb”) when the predictions are being calculated.\n\n\nWe can communicate these results via a predicted values plot. The basic syntax for this plot is similar to the syntax used to create a plot of predicted values for a single binary/factor variable from earlier sections (see, for instance, Section 8.6). As in earlier examples, we will need to tell ggplot() to separate the graphed values by value of the moderator. We do this here via the shape = option, which tells ggplot() to use different shapes for the plotted predictions.3\n\npredictions(biden_int3, \n            by = c(\"right_track\", \"vote2016\"), \n1            newdata = \"mean\") |&gt;\n  ggplot(aes(x = right_track, y=estimate, shape = vote2016)) + \n2  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +\n  geom_text(aes(label = round(estimate, 2), hjust=-0.2)) + \n  labs(title = \"Predicted Biden Evaluation by Right/Wrong Track and 2016 Vote Choice\", \n       x = \"Right Track?\", \n       y = \"Predicted Biden Evaluation\", \n       shape = \"2016 vote choice\") + \n3  scale_y_continuous(limits = c(0 , 100))\n\n\n1\n\nWe did this all in one go. Of course, you could separate matters into chunks - store the predictions as an object first and then use that object in a separate ggplot() call.\n\n2\n\nThe markers in a plot like this could overlap if the predicted values are very similar within categories (e.g,. if it were 26.76 and 27.50 that we were plotting for Wrong Track). One solution (if that were a problem) would be to add , position = position_dodge(width = 0.2) in the geom_pointrange() portion, after the aes() bit. This would offset the points from one another. You could control by how much by changing the number.\n\n3\n\nPuts the y-axis on a 0-100 point scale. As in prior examples, this may not be necessary in all situations, but we thought it made the interaction a bit easier to follow here.",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#logistic-regression-example",
    "href": "interaction_03.html#logistic-regression-example",
    "title": "17  Predicted Values from Interaction Models",
    "section": "17.4 Logistic Regression Example",
    "text": "17.4 Logistic Regression Example\nThe foregoing all applies to interactions in logistic regression models as well with the specifics depending on the type of interaction being investigated. For instance, the model rightrack_int featured an interaction between the binary variable vote2016 and the continuous variable age in a model predicting whether a respondent thinks the country is heading in the right direction or not.\n\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nWe can follow the same steps as seen earlier when we had a binary x continuous interaction with a linear model. Here, for instance, we obtain the predicted probability of a respondent saying the country is heading in the right direction for a combination of age values (from 20 to 80 years old in 10 year increments) for each category for the vote2016 variable. We also plot these values using the same basic syntax as above.\n\npredictions(righttrack_int, \n            newdata = datagrid(age = seq(from = 20,to = 80, by = 10), \n                               vote2016 = c(\"Trump Vote\", \"Clinton Vote\"))) |&gt; \n  ggplot(aes(x=age, y=estimate, linetype=vote2016)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Predicted Prob. of 'Right Direction' Belief by 2016 Vote and Age\", \n       y = \"Predicted Probability: Country Heading in Right Direction\", \n       x = \"Resondent Age\", \n       linetype = \"2016 Vote\") + \n  scale_y_continuous(limits=c(0,1))",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#footnotes",
    "href": "interaction_03.html#footnotes",
    "title": "17  Predicted Values from Interaction Models",
    "section": "",
    "text": "An alternative way of writing out the pid portion would be: “pid = c(1:7)”. This would tell R we want predictions for each whole number between 1 and 7.↩︎\nThe alternative would be to start with our original dataset (anes), select all of the variables in the model, filter out all missing values, and then produce the summary statistics. For instance: anes |&gt; filter(complete.cases(biden, socialists, age, rural_urban)) |&gt; select(socialists) |&gt; summarize(). predictions() is thus a bit simpler since it accomplishes the middle steps all at once for us.↩︎\nAn alternative would be color = vote2016, which would differentiate the markers by color rather than shape. Using color can be a wonderful way of conveying information in a plot such as this. However, we recommend thinking hard about your potential audience when doing so. On the one hand, it is possible that your plot could be illegible to color-blind consumers of your plot. There are color-bind palettes available for use with R-graphics if this is a concern. On the other hand, plots that require color for their legibility may prove problematic for you if the consumer of your plot consumes it not via color monitor but after printing it out via a black and white printer. Give consideration to these points before using color in your graphics.↩︎",
    "crumbs": [
      "Interactions within Linear and Logistic Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Predicted Values from Interaction Models</span>"
    ]
  },
  {
    "objectID": "common_errors.html",
    "href": "common_errors.html",
    "title": "Appendix A — Common Errors",
    "section": "",
    "text": "A.1 Your R assignment file (.rmd) won’t knit to an html file\nThe scenario: you have been successfully working through an R assignment in the .rmd file that was provided to you. However, you receive an error message such as “No such file or directory” when you try and “knit” the file to an html (i.e., ask R to convert the .rmd file into an html file). More generally, everything works while working in R Studio until you try to knit the final file.\nThere are a variety of potential causes for this problem. They perhaps share a common root though: when you ask R to “knit” a file, R will essentially from a blank slate and begin working downwards through your .rmd file. By blank slate, we mean that R will act as if you have not loaded any libraries or imported data or stored regression results (etc.) in the Environment and start running all the syntax that you have created to do these things. Here we’ll discuss three ways this could short circuit the ‘knitting’ process. First, though, we’ll note a general piece of advice:\nIf you have had difficulties knitting a document before, we suggest “knitting as you go”. Specifically, knit your .rmd file (convert it into an html) after every major section (e.g., after loading packages and your data, after question 1, after question 2…). Doing so may enable you to more quickly find, and troubleshoot, the specific problem affecting your file. For instance, if you can successfully knit your document after the first three questions of an assignment but have a problem after the fourth, then this implies that it is something specifically about the fourth question that is derailing the process. This can help you avoid spending unnecessary time and effort working through the earlier portions of the file.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "href": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "title": "Appendix A — Common Errors",
    "section": "",
    "text": "The Problem\n\n\n\nYou are trying to knit your assignment and you receive an error such as “No such file or directory”; more generally, you cannot knit to an html\n\n\n\n\n\n\n\n\n\n\nAdvice\n\n\n\nKnit as you go!\n\n\n\n\nA.1.1 Incorrectly Specifying the “yaml”\n\n\n\n\n\n\nThe Cause\n\n\n\nThe “yaml” has been incorrectly specified\n\n\nAll .rmd documents begin with something called the “yaml”. This is the portion of the document that lays out the basic attributes of the file you are trying to create: its title, author information, and other basic formatting details. Here is an example:\n\nThe “yaml” is the first thing that R deals with when knitting your file, so if there is a mistake here then the file won’t be produced. We have seen three types of error in student submissions on this front:\n\nRemoving quotation marks: the title, author, and date information should all be enclosed within quotation marks. Removing them will lead to an error.\nAdding information in the “sys.date()” area: “r sys.date()” is a specific snippet of syntax that tells R to use the date on your computer as the date in the html that is being produced. This general syntax is nice because it means we do not need to constantly update this line if we are working with a file over time. However, if you add information here (e.g., “r sys.date(27-09-2023”), then R will grind to a halt because this is not how the syntax works. In fact, we had to take special care formatting this bullet point because a mistake with writing out the “sys.date” information initially prevented this file from knitting to an html!\nAdding additional options: For instance, we have seen students add something like “pdf: default” to the format area. R can knit to pdf files, but this requires some additional packages be installed to handle the conversion from an .rmd file to a .pdf file. Creating .pdf files can also be a little finicky as well. Adding this information can thus produce errors.\n\n\n\n\n\n\n\nThe Solution\n\n\n\nUh…don’t do those things!\n\n\nMore specifically, you should only make one change to the “yaml” area - you should update the author information to include your name and your student number while making sure that this information is provided in quotation marks. Everything else should be left as is.\nAs an example:\n\n\n\nA.1.2 Not Properly Importing Your Data\n\n\n\n\n\n\nThe Cause\n\n\n\nYou are manually loading data via the Files window rather than using syntax\n\n\nWe load data into the R Environment, thereby enabling us to work with it, via syntax. Specifically, we use the import() function from the rio package:\n\nlibrary(rio)\ness &lt;- import(\"ess_nl.sav\")\n\nWe have seen some students take a different, and worse, route to this same end. Specifically, there is a “Files” window in R Studio that is typically presented in the bottom/right of the R Studio window, as so:\n\nHere we can see that there are some data files within the working directory containing this .rmd file (e.g., “ess_nl.sav” or “demdata.rds”). We may be able to load this data by double clicking on the file and using the “Import Dataset” option that pops up. However, this is a bad idea. Remember that R begins working downwards within your .rmd file as it tries to knit it to an html. If you take this route to loading the data, then R will move through the yaml and fail to find the necessary syntax to load the rio package or to load your data via import(). It won’t know that you have loaded the file manually because it is, per above, working in a type of blank slate environment. This is will almost certainly lead to lots of errors as R works through your file because you will be asking it to do things with data that it doesn’t know exists since you are not including the necessary information within the .rmd file itself.\n\n\n\n\n\n\nThe Solution\n\n\n\nProperly load your data.\n\n\nThe solution is simple: use the appropriate syntax to load your data.\n\n\nA.1.3 Not loading libraries within the .rmd file\n\n\n\n\n\n\nThe Problem\n\n\n\nPerforming operations outside of the .rmd file that are required for your analyses\n\n\nThis is a more general version of the previous issue. For instance, perhaps you have loaded the rio library and correctly imported your data via syntax … just not in the .rmd file (e.g., you may have entered these commands directly in the Console portion of R Studio or perhaps have run them from within an R Script that is separate from your .rmd file). The same problem would emerge: you would have access to the libraries and functions in question to work with while completing your assignment, but R wouldn’t when it started to knit your document because it’s not in the set of commands you’re directly sending it.\nOne tip off here may be in the error message that R provides you. Consider the following error message taken from a student’s error-prone .rmd file last year:\n\nIn this instance, the student is running into an issue with knitting. R provides us with information about the specific input that is causing a problem (“Error in import(….)”) and the specific problem (“could not find function ‘import’”). One way this error could emerge is if rio were loaded outside of the .rmd file (that is: the .rmd file does not contain library(rio) to load the library for use) such that R will have no idea where to find this command. (Another potential explanation for this error is below.)\n\n\n\n\n\n\nThe Solution\n\n\n\nKeep all your steps in the same .rmd file\n\n\nThis is a type of problem that can readily emerge, but also one that can be readily fixed: make sure you have included all of the relevant syntax in the .rmd file.\n\n\nA.1.4 Library/Package Conflicts\n\n\n\n\n\n\nThe Cause\n\n\n\nTwo or more R libraries conflict with one another and have been loaded in such a way that this grinds R to a halt; packages loaded in an order that creates issues\n\n\nR libraries may sometimes feature identically named commands (e.g., both the tidyverse/dplyr and car libraries contain a function named recode()). In such instances, R will use the function from the library loaded most recently/last. This can create problems down the line; see Chapter 7 for more on this particular conflict.\nAnother way this could emerge is if the syntax for loading the library and syntax for using it are mis-ordered. This, for instance, would lead to an error:\n\ndemdata &lt;- import(\"demdata.rds\")\n\nError in import(\"demdata.rds\"): could not find function \"import\"\n\nlibrary(rio)\n\nWarning: package 'rio' was built under R version 4.2.3\n\n\nR would try and use the import function here, but an error would emerge because the library from which this command originates has not been loaded at that point and, hence, R will not know how to act.\n\n\n\n\n\n\nThe Solution\n\n\n\nLoad relevant libraries at the start of the R document and pay attention to potential conflicts\n\n\nWe recommend you begin your assignment by reading it in full to understand all of the steps that you will need to accomplish and then loading all of the relevant libraries at the start of the document so that R will know what it has accessible to use in later portions. This should be done in a way that does not introduce conflicts. Here we note two particular sources of conflict, both with the tidyverse library:\n\nexpss\ncar\n\nWe recommend loading these libraries before loading the tidyverse library to avoid conflicts (or, if necessary, taking one of the other strategies for avoiding conflict discussed in Chapter 7 ).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "href": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "title": "Appendix A — Common Errors",
    "section": "A.2 Not seeing the right number of categories for factor variables in regression models",
    "text": "A.2 Not seeing the right number of categories for factor variables in regression models\n\n\n\n\n\n\nThe Problem\n\n\n\nYou tried to convert a categorical variable into a factor variable but only one coefficient is present in the regression output\n\n\nWe include categorical variables in a regression model by first converting the variable into a factor variable. R will then include the appropriate number of indicators in the model for us. For instance, if we have a categorical variable with four levels, then R will include three indicators in the model if we successfully convert the variable into a factor variable.\nSuppose we have a numeric variable in our dataset corresponding to the gross domestic product in a country where countries are sorted into one of three groups: “low” GDP (value of 1), medium GDP (value of 2), and “high” GDP (value of 3). We would include this variable in our model by converting it into a factor variable. We should then see two indicators for this variable in the model (with the left out group acting as the reference category). For instance:\n\n#Distribution of Variable\ntable(dta$gdp_3cat)\n\n\n 1  2  3 \n40 78 40 \n\n#Convert to factor variable\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_factor = factorize(gdp_3cat))\n\n#Run and summarize the regression\nmodel1 &lt;- lm(v2x_polyarchy ~ gdp_3cat_factor, data=dta)\nsummary(model1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_factor, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67320 -0.15257  0.04909  0.17964  0.36359 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.24184    0.05264   4.594 8.91e-06 ***\ngdp_3cat_factor  0.14879    0.02480   6.000 1.33e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2218 on 156 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.1875,    Adjusted R-squared:  0.1823 \nF-statistic:    36 on 1 and 156 DF,  p-value: 1.329e-08\n\n\nWe only have one indicator in our model for the factor variable. Why?1\n\n\n\n\n\n\nThe Cause\n\n\n\nYou used factorize() with non-labelled data.\n\n\nWe can convert a variable into a factor variable in either of two ways in R:\n\nfactor(): This is a built in function that will work with any type of data.\nfactorize(): This function comes from the rio package.\n\nfactorize() is a handy tool but it only works with variables that have value labels stored within the dataset. In these instances, factorize() will automatically attach each numeric value with its corresponding value. While labelled data is common (but not universal) when the dataset in question is either a .dta or .sav file format, it is not common with .csv for .xlsx file formats. Note that by labelled data we mean situations where the labels are included within the datset itself rather than only being found in a separate codebook.\nWe can use the following function to obtain information as to whether a variable has value labels associated with it in the dataset that we are using: attr(dataset$varname, \"labels\").2 Here is an example with two variables: one labelled and one unlabelled:\n\n#Unlabelled\nattr(dta$gdp_3cat, \"labels\")\n\nNULL\n\n#Labelled\nattr(dta$Fragile2006, \"labels\")\n\n     Fragile Intermediate       Stable \n           1            2            3 \n\n\nIn the former case, we observe the value of “NULL” meaning that no value labels are stored in the metadata for this variable. factorize() works by applying stored labels to numeric values, but there is nothing here to apply.\nOn the other hand, we see values reported in the latter case. The variable in question is a numeric variable with three values: 1 (associated with the label “Fragile”), 2 (associated with the label “Intermediate”), and 3 (associated with the label “Stable”). We can use factorize() in this instance with the resulting model reporting the correct number of terms in the model.3\n\ndta &lt;- dta |&gt; \n  mutate(fragile = factorize(Fragile2006))\n\nmodel2 &lt;- lm(v2x_polyarchy ~ fragile, data=dta)\nsummary(model2)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ fragile, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.64836 -0.14467  0.03116  0.15945  0.43393 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          0.36907    0.02915  12.662  &lt; 2e-16 ***\nfragileIntermediate  0.14954    0.03975   3.762 0.000236 ***\nfragileStable        0.36028    0.04345   8.291  4.2e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2162 on 161 degrees of freedom\n  (15 observations deleted due to missingness)\nMultiple R-squared:  0.2996,    Adjusted R-squared:  0.2909 \nF-statistic: 34.44 on 2 and 161 DF,  p-value: 3.539e-13\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUsing factor() instead of factorize()\n\n\nThe built in factor() command will be more useful in this type of situation. Here we specify the levels of the factor variable (with the reference group being the first category provided in levels=c()) and its associated labels.\n\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_correct = factor(gdp_3cat, \n                                   levels=c(1,2,3), \n                                   labels=c(\"Low\", \"Medium\", \"High\")))\n\nmodel3 &lt;- lm(v2x_polyarchy ~ gdp_3cat_correct, data=dta)\nsummary(model3)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_correct, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70362 -0.13534  0.06887  0.15537  0.39479 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.42105    0.03484  12.086  &lt; 2e-16 ***\ngdp_3cat_correctMedium  0.08716    0.04285   2.034   0.0437 *  \ngdp_3cat_correctHigh    0.29757    0.04927   6.040  1.1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2203 on 155 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.2034,    Adjusted R-squared:  0.1931 \nF-statistic: 19.79 on 2 and 155 DF,  p-value: 2.224e-08",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-glm-factor",
    "href": "common_errors.html#sec-glm-factor",
    "title": "Appendix A — Common Errors",
    "section": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”",
    "text": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to perform a logistic model where our DV is a factor variable but are running into a message saying “Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in ‘y’” and “In Ops.factor(y, mu) : ‘-’ not meaningful for factors”\n\n\nSuppose that we wish to predict a binary outcome for whether a person reports being close to a political party or not based on their age. We would use create a factor variable of the binary outcome variable and then use the glm() function, rather than lm() to do so. However, if we ran the following syntax, we would run into an error:\n\n#Factorize the variable\ness &lt;- ess |&gt; \n  mutate(close_party = factor(clsprty, \n                              levels = c(2, 1), \n                              labels = c(\"Not Close\", \"Close to Party\")))\n\n#Run the model\nglm(close_party ~ agea, data = ess)\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nWarning in Ops.factor(eta, offset): '-' not meaningful for factors\n\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nError in glm.fit(x = structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in 'y'\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nWe haven’t specified a “family” for the model.\n\n\nThe glm() function can be used to fit a variety of different models depending on the nature of the dependent variable. We specify the type of model (and hence the nature of the DV) via a family= option. If we do not specify a family option, then glm() will default to attempting to perform a linear model, which creates an error when the DV is a factor variable.4\n\n\n\n\n\n\nSolution\n\n\n\nSpecify the correct family, here: “family =”binomial”\n\n\n\nglm(close_party ~ agea, data = ess, family = 'binomial')\n\n\nCall:  glm(formula = close_party ~ agea, family = \"binomial\", data = ess)\n\nCoefficients:\n(Intercept)         agea  \n   -0.64393      0.01825  \n\nDegrees of Freedom: 1646 Total (i.e. Null);  1645 Residual\n  (26 observations deleted due to missingness)\nNull Deviance:      2260 \nResidual Deviance: 2214     AIC: 2218",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-slopes-error",
    "href": "common_errors.html#sec-slopes-error",
    "title": "Appendix A — Common Errors",
    "section": "A.4 “Unable to compute predicted values with this model”",
    "text": "A.4 “Unable to compute predicted values with this model”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re using avg_slopes() to try and find the slope for a variable but are running into an error: “Unable to compute predicted values with this model”\n\n\nSuppose we have a binary dependent variable that we wish to predict with a binary or category independent variable. For instance, we might want to know if the chances of voting are higher/lower among men versus women. We would convert both variables to factor variables and perform a logistic model. The syntax below walks through this process by first investigating the variables (e.g., what labels are associated with each category); converting both variables to factors; and then running the model and reporting the results.\n\n#Value Values\nattr(ess$vote,\"labels\") \n\n                 Yes                   No Not eligible to vote \n                   1                    2                    3 \n             Refusal           Don't know            No answer \n                   7                    8                    9 \n\nattr(ess$gndr, \"labels\")\n\n     Male    Female No answer \n        1         2         9 \n\n#Distribution\ntable(ess$vote)\n\n\n   1    2    3 \n1291  247  130 \n\ntable(ess$gndr)\n\n\n  1   2 \n833 840 \n\n#Convert into factor\n  #Vote: 0 = did not vote, 1 = voted\n  #Gender: 0 = male, 1 = female\n\ness &lt;- ess |&gt; \n  mutate(voted = factor(vote, levels=c(2,1), \n                        labels=c(\"Did Not Vote\", \"Voted\")), \n         gender = factorize(gndr))\n\n#Model and Summary\name_example &lt;- glm(voted ~ gender, data=ess, family=\"binomial\")\nsummary(ame_example)\n\n\nCall:\nglm(formula = voted ~ gender, family = \"binomial\", data = ess)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.9539   0.5665   0.5665   0.6163   0.6163  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.7484     0.1015  17.229   &lt;2e-16 ***\ngenderFemale  -0.1836     0.1392  -1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe coefficient for our IV is negative, which indicates that female respondents have a lower chance of reporting that they turned out to vote than men (although this difference is not statistically significant). This coefficient is on the log of the odds (logit) scale, which is hard to interpret. We may want to look at the average difference in the probability of turning out between women and men to more clearly communicate the difference between the two groups. We can do this by using the avg_slopes() function from the marginaleffects package. However, in this instance we receive an error message:\n\navg_slopes(ame_example)\n\nError: Unable to compute predicted values with this model. This error can arise\n  when `insight::get_data()` is unable to extract the dataset from the\n  model object, or when the data frame was modified since fitting the\n  model. You can try to supply a different dataset to the `newdata`\n  argument.\n  \n  In addition, this error message was raised:\n  \n  Error in model.frame.default(Terms, newdata, na.action = na.action, xlev\n  = object$xlevels): factor gender has new levels No answer\n\n  \n  Bug Tracker:\n  https://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThere is a category/label with no observations.\n\n\nLet’s take a look at the gender variable we created earlier compared with its original form:\n\n#Original Variable\nattr(ess$gndr, \"labels\")\n\n     Male    Female No answer \n        1         2         9 \n\ntable(ess$gndr)\n\n\n  1   2 \n833 840 \n\n#Recoded\nlevels(ess$gender)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\ntable(ess$gender)\n\n\n     Male    Female No answer \n      833       840         0 \n\n\nThe gndr variable has three labels associated with it: Male (=1), Female (=2), and No Answer (=9). However, no observations have a value of 9 on this original variable. Regardless, factorize() will still port over the label for “No Answer”. The issue is that avg_slopes() is expecting there to be observations with a label of “No Answer” - when it finds none, it crashes.\n\n\n\n\n\n\nSolution\n\n\n\nUse droplevels() to removing categories with no observations or use factor() to create the variable to begin with\n\n\nWe can avoid this issue in either of two ways. First, we could use droplevels() to drop levels (and their associated labels) that have no observations. Second, we can preempt the problem by simply using factor() and only including the categories we care about.\n\n#Recoding Using the Two Options\ness &lt;- ess |&gt; \n  mutate(\n    #Option 1: droplevels()\n    gender_opt1 = factorize(gndr), \n    gender_opt1 = droplevels(gender_opt1), \n    #Option 2: factor() from the beginning\n    gender_opt2 = factor(gndr,\n                         levels=c(1,2), \n                         labels=c(\"Male\", \"Female\")))\n\n#Levels\nlevels(ess$gender_opt1)\n\n[1] \"Male\"   \"Female\"\n\nlevels(ess$gender_opt2)\n\n[1] \"Male\"   \"Female\"\n\n#Option 1: \name_example_opt1 &lt;- glm(voted ~ gender_opt1, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt1)\n\n\n        Term      Contrast Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n gender_opt1 Female - Male  -0.0247     0.0187 -1.32    0.187 2.4 -0.0614\n 97.5 %\n  0.012\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n#Option 2\name_example_opt2 &lt;- glm(voted ~ gender_opt2, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt2)\n\n\n        Term      Contrast Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n gender_opt2 Female - Male  -0.0247     0.0187 -1.32    0.187 2.4 -0.0614\n 97.5 %\n  0.012\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-linetype-error",
    "href": "common_errors.html#sec-linetype-error",
    "title": "Appendix A — Common Errors",
    "section": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”",
    "text": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to create a predicted values plot from a model with an interaction involving a continuous variable and see the error “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\nSuppose we predict a country’s democracy score with a continuous measure of gross domestic product (gdp_ppp), a continuous measure of corruption (cpi), and their interaction:\n\ninter_model &lt;- lm(v2x_polyarchy ~ gdp_ppp*cpi, data=dta)\nsummary(inter_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_ppp * cpi, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.58552 -0.09686  0.02947  0.13111  0.30958 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.250e-02  5.643e-02   1.462    0.146    \ngdp_ppp     -1.902e-06  3.092e-06  -0.615    0.539    \ncpi          1.203e-02  1.463e-03   8.220 8.34e-14 ***\ngdp_ppp:cpi -2.524e-08  4.370e-08  -0.578    0.564    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1833 on 152 degrees of freedom\n  (23 observations deleted due to missingness)\nMultiple R-squared:  0.4538,    Adjusted R-squared:  0.443 \nF-statistic: 42.09 on 3 and 152 DF,  p-value: &lt; 2.2e-16\n\n\nInterpreting coefficients in a model with an interaction can be tricky and especially so when both variables are continuous variables. One solution is to use predictions() function to obtain predicted values across the range of our main variable for different values of our moderator (e.g., “low”, “medium”, and “high”). For instance:\n\ninter_preds &lt;- predictions(inter_model, \n                           newdata = datagrid(\n                             cpi = c(12,30,40,43.94,56,88), \n                             gdp_ppp = c(711.4, 20309.8, 111751.3)))\n\ninter_preds\n\n\n  cpi gdp_ppp Estimate Std. Error       z Pr(&gt;|z|)     S   2.5 % 97.5 %\n 12.0     711   0.2253     0.0405  5.5659   &lt;0.001  25.2  0.1459  0.305\n 12.0   20310   0.1821     0.0479  3.8040   &lt;0.001  12.8  0.0883  0.276\n 12.0  111751  -0.0196     0.2732 -0.0717   0.9429   0.1 -0.5550  0.516\n 30.0     711   0.4415     0.0248 17.8188   &lt;0.001 233.5  0.3929  0.490\n 30.0   20310   0.3893     0.0282 13.7902   &lt;0.001 141.3  0.3340  0.445\n 30.0  111751   0.1462     0.1995  0.7325   0.4639   1.1 -0.2449  0.537\n 40.0     711   0.5616     0.0251 22.3295   &lt;0.001 364.5  0.5123  0.611\n 40.0   20310   0.5045     0.0210 23.9895   &lt;0.001 420.0  0.4633  0.546\n 40.0  111751   0.2382     0.1608  1.4820   0.1383   2.9 -0.0768  0.553\n 43.9     711   0.6089     0.0275 22.1578   &lt;0.001 359.0  0.5550  0.663\n 43.9   20310   0.5499     0.0199 27.6463   &lt;0.001 556.5  0.5109  0.589\n 43.9  111751   0.2745     0.1463  1.8768   0.0605   4.0 -0.0122  0.561\n 56.0     711   0.7537     0.0392 19.2345   &lt;0.001 271.5  0.6769  0.831\n 56.0   20310   0.6887     0.0241 28.5995   &lt;0.001 595.2  0.6415  0.736\n 56.0  111751   0.3856     0.1071  3.5986   &lt;0.001  11.6  0.1756  0.596\n 88.0     711   1.1380     0.0810 14.0449   &lt;0.001 146.4  0.9792  1.297\n 88.0   20310   1.0572     0.0588 17.9733   &lt;0.001 237.5  0.9419  1.173\n 88.0  111751   0.6802     0.1107  6.1456   &lt;0.001  30.2  0.4633  0.897\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cpi, gdp_ppp, v2x_polyarchy \nType:  response \n\n\nThere is a lot of data here to try and read/interpret. However, we can create a nice plot to summarize the predictions. Unfortunately, we run into the following error when running this syntax:\n\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)\n\nError in `geom_line()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error in `scale_f()`:\n! A continuous variable cannot be mapped to the linetype aesthetic.\nℹ Choose a different aesthetic or use `scale_linetype_binned()`.\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThe variable being used to specify linetype (or color, etc.) is numeric in value.\n\n\nWe created three sets of predictions above: one where gdp_ppp = 711.4 and cpi took on one of five values from across its range; one where gdp_ppp = 20309.8 and cpi took on one of those five values; and one where cpi = 111751.3 and cpitook on one of those values. We can visually differentiate between these different predictions by telling ggplot() to use a different type of line for each set (or, perhaps, a different color). But, the linetype function requires the variable in question to be a factor.\n\n\n\n\n\n\nSolution\n\n\n\nConvert the problematic numeric variable to a factor and then run the ggplot() command.\n\n\nWe can avoid this issue by converting the offending variable to a factor variable using the factor() function.\n\n#Convert to factor\ninter_preds &lt;- inter_preds |&gt; \n  mutate(\n    gdp_ppp = factor(gdp_ppp, \n                     levels=c( 711.4, 20309.8, 111751.3), \n                     labels=c(\"Low\", \"Medium\", \"High\")))\n\n#Create the plot\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "common_errors.html#footnotes",
    "href": "common_errors.html#footnotes",
    "title": "Appendix A — Common Errors",
    "section": "",
    "text": "There could an additional culprit: missing data. Suppose that you have 1 DV and two IVs, one of which is a categorical variable with three levels (low, middle, and high) and the other a continuous variable. R will automatically drop observations from the model that have missing data on at least one of the variables in the model (DV and IV). Suppose that all of the observations with a classification of “high” on the categorical variable have missing (NA) values on the continuous variable - in that instance, R would not have the necessary data to estimate a coefficient for the “high” category and, as a result, you would likely only get indicators for one category of the categorical variable (comparing it to the reference group) and one for the continuous variable.↩︎\nWe could also use attributes(dta$gdp_3cat) to the same end. The main difference is that this command will also provide other information about the variable.↩︎\nOf course, in practice we might want to follow the factorize() step with a subsequent step where we relevel the variable, i.e., change the reference group. Alternatively we could simply use factor() in this instance as well and handle the levelling and labelling all at once.↩︎\nWhat if the DV was simply coded 0/1 and not converted to a factor? The syntax in this example would run but a different problem would emerge: the glm() command would fit a linear model (i.e., a linear regression model) to the data rather than a logistic model. This is another reason to explicitly specify the family to be used when using the glm() function.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common Errors</span>"
    ]
  },
  {
    "objectID": "package_overview.html",
    "href": "package_overview.html",
    "title": "Appendix B — Overview of R Packages",
    "section": "",
    "text": "B.1 Installing Them All in One Go\nWe will use a variety of new packages/libraries in class. A document listing these packages, when they will be first introduced, and their purpose is provided elsewhere on Brightspace.\nYou can use the code below to install all of the relevant R packages for this course in one go: Copy the following syntax using the “Copy to Clipboard” icon in the upper right corner of the code block; paste it into an R script file on your computer; and then execute the syntax.\npackage_list &lt;- c(\"tidyverse\", \"rio\", \"summarytools\", \"DescTools\", \"skimr\",\n                  \"correlation\", \"parameters\", \"performance\", \"effectsize\",\n                  \"see\", \"marginaleffects\", \" bromo\", \"ggResidpanel\", \"rms\",\n                  \"car\", \"modelsummary\", \"gt\", \"gtsummary\", \"kableExtra\",\n                  \"knitr\", \"rmarkdown\",\"huxtable\", \"flextable\", \"lmtest\" ,\n                  \"openintro\", \"statsr\", \"tidymodels\", \"tinytex\",\n                  \"visdat\", \"patchwork\", \"ggpubr\", \"cowplot\", \"expss\",\n                  \"effsize\", \"foreign\", \"haven\",\n                  \"ggstance\", \"ggrepel\", \"ggsignif\", \"naniar\", \"openxlsx\",\n                  \"sjmisc\", \"crosstable\", \"sjlabelled\", \"psych\", \"dice\",\n                  \"pwr\", \"visualize\", \"infer\" , \"sandwich\", \"sjPlot\",\n                  \"scales\")\n\ninstall.packages(package_list)\nIt should be possible to install the marginaleffects package via the syntax above. However, if you run into an error, then try this syntax:\ninstall.packages(\"marginaleffects\", type=\"binary\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Overview of R Packages</span>"
    ]
  },
  {
    "objectID": "Formulas.html",
    "href": "Formulas.html",
    "title": "Appendix C — Formulas",
    "section": "",
    "text": "C.1 Covariance and Correlation\n(Sample) Covariance\n\\[cov(x,y) = \\frac{\\sum (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{n-1}\\]\nPearson Correlation\n\\[r = \\frac{cov(x,y)}{SD(x) * SD(y)}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "Formulas.html#linear-regression",
    "href": "Formulas.html#linear-regression",
    "title": "Appendix C — Formulas",
    "section": "C.2 Linear Regression",
    "text": "C.2 Linear Regression\nLinear Regression Equation\n\\[y_{i} = b_{0} + b_{1}x_{1i} + b_{2}x_{2i} + ... + b_{k}x_{ki} + \\epsilon_{i}\\]\nSimple Linear Regression: Slope\n\\[b_{1} = \\frac{\\sum(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum(x_{i} - \\bar{x})^2}\\]\nSimple Linear Regression: Intercept/Constant\n\\[b_{0} = \\bar{y} - b_{1}\\bar{x}\\]\nRegression Model with Interaction\n\\[y = b_{0} + b_{1}x_{1} + b_{2}x_{2} + b_{3}(x_{1}x_{2}) + \\epsilon\\]\nMarginal Effects in Interaction Model\n\\[b_{1} + (x2 * b_{3})\\] \\[b_{2} + (x1 * b_{3})\\]\nt-test for regression coefficients\n\\[t = \\frac{b}{SE_{b}}\\]\nConfidence Interval: Coefficient\n\\[CI = b \\pm (t_{df} * SE)\\]\nRegression Sum of Squares (Also called: Model Sum of Squares)\n\\[SS_{Regression} = \\sum(\\hat{y} - \\bar{y})^2\\]\nResidual Sum of Squares\n\\[SS_{Residual} = \\sum(y_{i} - \\hat{y})^2\\]\nTotal Sum of Squares\n\\[SS_{Total} = \\sum(y_{i} - \\bar{y})^2\\]\nR2\n\\[R^2 = \\frac{SS_{Regression}}{SS_{Total}}\\]\n\\[R^2 = 1 - \\frac{SS_{Residual}}{SS_{Total}} \\]\nMean Squares: Residual\n\\[MS_{Residual} = \\frac{SS_{Residual}}{\\textrm{df}_{Residual}}\\] \\[\\textrm{df}_{Residual} = n-k\\] Mean Squares: Regression Model\n\\[MS_{Model} = \\frac{SS_{Regression}}{df_{Model}}\\]\n\\[df_{Model} = k\\] F\n\\[F = \\frac{MS_{Model}}{MS_{Residual}}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "Formulas.html#logistic-regression",
    "href": "Formulas.html#logistic-regression",
    "title": "Appendix C — Formulas",
    "section": "C.3 Logistic Regression",
    "text": "C.3 Logistic Regression\nLogistic Regression Model with Single Explanatory Variable\n\\[\\textrm{log(Odds)} = b_0 + b_1x_{1i} + b_2x_{2i}...\\]\n\\[P(Y_{i} = 1) = \\frac{1}{1 + e^{-(b_{0} + b_{1}x_{1i})}}\\]\nOdds and Probabiilty\n\\[odds = \\frac{p}{1 - p}\\]\n\\[p = \\frac{odds}{1 + odds}\\]\nOdds Ratio\n\\[e^{b}\\]\nz statistic\n\\[z = \\frac{b}{se}\\]\nLikelihood Ratio\n\\[\\chi^2 = (-2LL_{baseline}) - (-2LL_{new})\\]\n\\[\\textrm{df} = k_{new} - k_{baseline}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formulas</span>"
    ]
  },
  {
    "objectID": "Formulas.html#appendix-critical-values-of-t-distribution",
    "href": "Formulas.html#appendix-critical-values-of-t-distribution",
    "title": "Appendix C — Formulas",
    "section": "C.4 Appendix: Critical Values of t-distribution",
    "text": "C.4 Appendix: Critical Values of t-distribution\n\n\n\n\nCritical Values of the t-distribution (Two-Tailed Test)\n\n\ndf\n0.05\n0.01\n\n\n\n\n1\n12.71\n63.66\n\n\n2\n4.30\n9.92\n\n\n3\n3.18\n5.84\n\n\n4\n2.78\n4.60\n\n\n5\n2.57\n4.03\n\n\n6\n2.45\n3.71\n\n\n7\n2.36\n3.50\n\n\n8\n2.31\n3.36\n\n\n9\n2.26\n3.25\n\n\n10\n2.23\n3.17\n\n\n11\n2.20\n3.11\n\n\n12\n2.18\n3.05\n\n\n13\n2.16\n3.01\n\n\n14\n2.14\n2.98\n\n\n15\n2.13\n2.95\n\n\n16\n2.12\n2.92\n\n\n17\n2.11\n2.90\n\n\n18\n2.10\n2.88\n\n\n19\n2.09\n2.86\n\n\n20\n2.09\n2.85\n\n\n21\n2.08\n2.83\n\n\n22\n2.07\n2.82\n\n\n23\n2.07\n2.81\n\n\n24\n2.06\n2.80\n\n\n25\n2.06\n2.79\n\n\n26\n2.06\n2.78\n\n\n27\n2.05\n2.77\n\n\n28\n2.05\n2.76\n\n\n29\n2.05\n2.76\n\n\n30\n2.04\n2.75\n\n\n35\n2.03\n2.72\n\n\n40\n2.02\n2.70\n\n\n45\n2.01\n2.69\n\n\n50\n2.01\n2.68\n\n\n60\n2.00\n2.66\n\n\n70\n1.99\n2.65\n\n\n80\n1.99\n2.64\n\n\n90\n1.99\n2.63\n\n\n100\n1.98\n2.63\n\n\n∞\n1.96\n2.58",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formulas</span>"
    ]
  }
]